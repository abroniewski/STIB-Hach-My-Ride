{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Assignment 1\n",
    "## Calculating and Analyzing Vehicle Speed"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## What are we looking to accomplish?\n",
    "\n",
    "Here we will be loading in files available from STIB API that provides timestamped locations of all vehicles on the STIB network. The data is provided in several reference files:\n",
    "- calendars and bus route data (.txt)\n",
    "- timestamp locations (.json)\n",
    "- bus stop and route locations are in shapefiles (.shp)\n",
    "\n",
    " > #### The most significant challenge in the data is that there is no unique identifier for each vehicle moving through the system.\n",
    " The data provided shows what line a bus is on, which direction it is heading (towards or away from the terminus), and which stop it is heading towards. A single snapshot in time provides all this info for every vehicle on the STIB network.\n",
    "\n",
    "We will need to:\n",
    "1. Load files in and manipulate them into a convenient working format (e.g. unpack the .json files)\n",
    "2. Merge columns from different reference tables\n",
    "3. Find a way to artificially \"track\" a vehicle along it's route\n",
    "4. Calculate the vehicle speed using some segment of distance\n",
    "\n",
    "Let's go!"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import datetime\n",
    "import json\n",
    "import os\n",
    "from enum import Enum\n",
    "from functools import reduce\n",
    "from itertools import count\n",
    "from operator import add\n",
    "\n",
    "import pandas as pd\n",
    "import shapefile\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "from scripts.helpers import *"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Raw JSON to CSV\n",
    "\n",
    "Converts raw JSON files containing the vehiclePositions from STIB to a single CSV file\n",
    "**Reads from**: raw JSON files in `data/raw` folder (`data/raw/vehiclePosition*.json`)\n",
    "**Writes to**: Single CSV file containing all the vehicle positions in `data` folder (`data/processed/assignment1/vehiclePositions.csv`)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "raw_json_files = [\n",
    "    '../data/raw/vehicleTimestamp/vehiclePosition01.json',\n",
    "    '../data/raw/vehicleTimestamp/vehiclePosition02.json',\n",
    "    '../data/raw/vehicleTimestamp/vehiclePosition03.json',\n",
    "    '../data/raw/vehicleTimestamp/vehiclePosition04.json',\n",
    "    '../data/raw/vehicleTimestamp/vehiclePosition05.json',\n",
    "    '../data/raw/vehicleTimestamp/vehiclePosition06.json',\n",
    "    '../data/raw/vehicleTimestamp/vehiclePosition07.json',\n",
    "    '../data/raw/vehicleTimestamp/vehiclePosition08.json',\n",
    "    '../data/raw/vehicleTimestamp/vehiclePosition09.json',\n",
    "    '../data/raw/vehicleTimestamp/vehiclePosition10.json',\n",
    "    '../data/raw/vehicleTimestamp/vehiclePosition11.json',\n",
    "    '../data/raw/vehicleTimestamp/vehiclePosition12.json',\n",
    "    '../data/raw/vehicleTimestamp/vehiclePosition13.json'\n",
    "]\n",
    "vehicle_positions_csv = '../data/processed/assignment1/vehiclePositions.csv'\n",
    "csv_header = ['Timestamp', 'LineId', 'DirectionId', 'DistanceFromPoint', 'PointId']"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "data": {
      "text/plain": "  0%|          | 0/13 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "14ac395d92aa479893bf1b5d9aa6a407"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "with write_csv(vehicle_positions_csv) as writer:\n",
    "    writer.writerow(csv_header)\n",
    "    for raw_json_path in tqdm(raw_json_files):\n",
    "        file = open(raw_json_path, 'r', encoding='utf8')\n",
    "        data = json.load(file)['data']\n",
    "        file.close()\n",
    "        for time in data:\n",
    "            timestamp = time['time']\n",
    "            for response in time['Responses']:\n",
    "                if response is None:\n",
    "                    # Skip if response is empty\n",
    "                    continue\n",
    "                for line in response['lines']:\n",
    "                    line_id = line['lineId']\n",
    "                    for vehiclePosition in line['vehiclePositions']:\n",
    "                        writer.writerow([\n",
    "                            timestamp,\n",
    "                            line_id,\n",
    "                            vehiclePosition['directionId'],\n",
    "                            vehiclePosition['distanceFromPoint'],\n",
    "                            vehiclePosition['pointId'],\n",
    "                        ])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "data": {
      "text/plain": "       Timestamp  LineId  DirectionId  DistanceFromPoint  PointId\n0  1630914886924       1         8161                  1     8012\n1  1630914886924       1         8162                  0     8142\n2  1630914886924       1         8162                  0     8282\n3  1630914886924       1         8731                  0     8111\n4  1630914886924       1         8162                  1     8062",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Timestamp</th>\n      <th>LineId</th>\n      <th>DirectionId</th>\n      <th>DistanceFromPoint</th>\n      <th>PointId</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1630914886924</td>\n      <td>1</td>\n      <td>8161</td>\n      <td>1</td>\n      <td>8012</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1630914886924</td>\n      <td>1</td>\n      <td>8162</td>\n      <td>0</td>\n      <td>8142</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1630914886924</td>\n      <td>1</td>\n      <td>8162</td>\n      <td>0</td>\n      <td>8282</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1630914886924</td>\n      <td>1</td>\n      <td>8731</td>\n      <td>0</td>\n      <td>8111</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1630914886924</td>\n      <td>1</td>\n      <td>8162</td>\n      <td>1</td>\n      <td>8062</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vehicle_positions_df = pd.read_csv(vehicle_positions_csv)\n",
    "vehicle_positions_df.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Shapefile to routes\n",
    "\n",
    "Converts raw Stops Shapefiles from STIB to a single CSV file containing line routes\n",
    "**Reads from**:\n",
    " - Shapefiles in `data/raw/shapefiles` folder (`data/raw/shapefiles/ACTU_STOPS.*`)\n",
    " - `stops.txt` GTFS file in `data/raw/gtfs` folder\n",
    "\n",
    "**Writes to**: Single CSV file containing all the line routes in `data` folder (`data/line_stops.csv`)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "csv_header = ['lineId', 'direction', 'stop_id', 'stop_id_int', 'name', 'name_ascii', 'lat', 'long', 'lambert_x',\n",
    "              'lambert_y', 'order']\n",
    "stops_shapefile_path = '../data/raw/shapefiles/ACTU_STOPS.shp'\n",
    "stops_gtfs_path = '../data/raw/gtfs/stops.csv'\n",
    "merged_stops_csv_path = '../data/processed/assignment1/line_stops.csv'"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "data": {
      "text/plain": "  Code_Ligne  Variante  succession stop_id          descr_fr  \\\n0       012b         1           1   9600B  BRUSSELS AIRPORT   \n1       012b         1           2    3017           BOURGET   \n2       012b         1           3    5048          DA VINCI   \n3       012b         1           4    2695            GENEVE   \n4       012b         1           5    2250            MEISER   \n\n           descr_nl          alpha_fr          alpha_nl   coord_x   coord_y  \\\n0  BRUSSELS AIRPORT  Brussels Airport  Brussels Airport  157950.0  176429.0   \n1           BOURGET           Bourget           Bourget  154334.0  174200.0   \n2          DA VINCI          Da Vinci          Da Vinci  152934.0  173976.0   \n3            GENEVE            Genève            Genève  152428.0  172606.0   \n4            MEISER            Meiser            Meiser  152045.0  171508.0   \n\n  mode  numero_lig       terminus  \n0    B          12  BRUSSELS CITY  \n1    B          12  BRUSSELS CITY  \n2    B          12  BRUSSELS CITY  \n3    B          12  BRUSSELS CITY  \n4    B          12  BRUSSELS CITY  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Code_Ligne</th>\n      <th>Variante</th>\n      <th>succession</th>\n      <th>stop_id</th>\n      <th>descr_fr</th>\n      <th>descr_nl</th>\n      <th>alpha_fr</th>\n      <th>alpha_nl</th>\n      <th>coord_x</th>\n      <th>coord_y</th>\n      <th>mode</th>\n      <th>numero_lig</th>\n      <th>terminus</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>012b</td>\n      <td>1</td>\n      <td>1</td>\n      <td>9600B</td>\n      <td>BRUSSELS AIRPORT</td>\n      <td>BRUSSELS AIRPORT</td>\n      <td>Brussels Airport</td>\n      <td>Brussels Airport</td>\n      <td>157950.0</td>\n      <td>176429.0</td>\n      <td>B</td>\n      <td>12</td>\n      <td>BRUSSELS CITY</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>012b</td>\n      <td>1</td>\n      <td>2</td>\n      <td>3017</td>\n      <td>BOURGET</td>\n      <td>BOURGET</td>\n      <td>Bourget</td>\n      <td>Bourget</td>\n      <td>154334.0</td>\n      <td>174200.0</td>\n      <td>B</td>\n      <td>12</td>\n      <td>BRUSSELS CITY</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>012b</td>\n      <td>1</td>\n      <td>3</td>\n      <td>5048</td>\n      <td>DA VINCI</td>\n      <td>DA VINCI</td>\n      <td>Da Vinci</td>\n      <td>Da Vinci</td>\n      <td>152934.0</td>\n      <td>173976.0</td>\n      <td>B</td>\n      <td>12</td>\n      <td>BRUSSELS CITY</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>012b</td>\n      <td>1</td>\n      <td>4</td>\n      <td>2695</td>\n      <td>GENEVE</td>\n      <td>GENEVE</td>\n      <td>Genève</td>\n      <td>Genève</td>\n      <td>152428.0</td>\n      <td>172606.0</td>\n      <td>B</td>\n      <td>12</td>\n      <td>BRUSSELS CITY</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>012b</td>\n      <td>1</td>\n      <td>5</td>\n      <td>2250</td>\n      <td>MEISER</td>\n      <td>MEISER</td>\n      <td>Meiser</td>\n      <td>Meiser</td>\n      <td>152045.0</td>\n      <td>171508.0</td>\n      <td>B</td>\n      <td>12</td>\n      <td>BRUSSELS CITY</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stops_shapefile = shapefile.Reader(stops_shapefile_path)\n",
    "# We take the first value of each field tuple (it's name), and skip the first field (DeletionFlag field, not relevant)\n",
    "stop_fields = [field[0] for field in stops_shapefile.fields][1:]\n",
    "shapefile_df = pd.DataFrame(stops_shapefile.records(), columns=stop_fields)\n",
    "shapefile_df.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "data": {
      "text/plain": "     lineId  direction  order stop_id        name_ascii              name  \\\n2987   001m          1      1    8733   GARE DE L'OUEST   Gare de l'Ouest   \n2988   001m          1      2    8742          BEEKKANT          Beekkant   \n2989   001m          1      3    8292      ETANGS NOIRS      Étangs Noirs   \n2990   001m          1      4    8282  COMTE DE FLANDRE  Comte de Flandre   \n2991   001m          1      5    8272  SAINTE-CATHERINE  Sainte-Catherine   \n\n      lambert_x  lambert_y  stop_id_int  \n2987   146633.5   170956.4         8733  \n2988   146776.5   171444.3         8742  \n2989   147492.7   171859.9         8292  \n2990   148013.6   171590.4         8282  \n2991   148539.5   171278.2         8272  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>lineId</th>\n      <th>direction</th>\n      <th>order</th>\n      <th>stop_id</th>\n      <th>name_ascii</th>\n      <th>name</th>\n      <th>lambert_x</th>\n      <th>lambert_y</th>\n      <th>stop_id_int</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>2987</th>\n      <td>001m</td>\n      <td>1</td>\n      <td>1</td>\n      <td>8733</td>\n      <td>GARE DE L'OUEST</td>\n      <td>Gare de l'Ouest</td>\n      <td>146633.5</td>\n      <td>170956.4</td>\n      <td>8733</td>\n    </tr>\n    <tr>\n      <th>2988</th>\n      <td>001m</td>\n      <td>1</td>\n      <td>2</td>\n      <td>8742</td>\n      <td>BEEKKANT</td>\n      <td>Beekkant</td>\n      <td>146776.5</td>\n      <td>171444.3</td>\n      <td>8742</td>\n    </tr>\n    <tr>\n      <th>2989</th>\n      <td>001m</td>\n      <td>1</td>\n      <td>3</td>\n      <td>8292</td>\n      <td>ETANGS NOIRS</td>\n      <td>Étangs Noirs</td>\n      <td>147492.7</td>\n      <td>171859.9</td>\n      <td>8292</td>\n    </tr>\n    <tr>\n      <th>2990</th>\n      <td>001m</td>\n      <td>1</td>\n      <td>4</td>\n      <td>8282</td>\n      <td>COMTE DE FLANDRE</td>\n      <td>Comte de Flandre</td>\n      <td>148013.6</td>\n      <td>171590.4</td>\n      <td>8282</td>\n    </tr>\n    <tr>\n      <th>2991</th>\n      <td>001m</td>\n      <td>1</td>\n      <td>5</td>\n      <td>8272</td>\n      <td>SAINTE-CATHERINE</td>\n      <td>Sainte-Catherine</td>\n      <td>148539.5</td>\n      <td>171278.2</td>\n      <td>8272</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shapefile_df.drop(columns=['descr_nl', 'alpha_nl', 'mode', 'numero_lig', 'terminus'], inplace=True)\n",
    "renames = {'Code_Ligne': 'lineId',\n",
    "           'Variante': 'direction',\n",
    "           'succession': 'order',\n",
    "           'descr_fr': 'name_ascii',\n",
    "           'alpha_fr': 'name',\n",
    "           'coord_x': 'lambert_x',\n",
    "           'coord_y': 'lambert_y'}\n",
    "shapefile_df.rename(columns=renames, inplace=True)\n",
    "shapefile_df.sort_values(['lineId', 'direction', 'order'], inplace=True)\n",
    "shapefile_df['stop_id_int'] = shapefile_df['stop_id'].apply(lambda stop_id: int(stop_id[:4]))\n",
    "shapefile_df.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "data": {
      "text/plain": "              stop_lat  stop_lon\nstop_id_int                     \n89           50.838006  4.408970\n470          50.863666  4.329612\n471          50.863732  4.329236\n472          50.863543  4.329023\n473          50.863418  4.330031",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>stop_lat</th>\n      <th>stop_lon</th>\n    </tr>\n    <tr>\n      <th>stop_id_int</th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>89</th>\n      <td>50.838006</td>\n      <td>4.408970</td>\n    </tr>\n    <tr>\n      <th>470</th>\n      <td>50.863666</td>\n      <td>4.329612</td>\n    </tr>\n    <tr>\n      <th>471</th>\n      <td>50.863732</td>\n      <td>4.329236</td>\n    </tr>\n    <tr>\n      <th>472</th>\n      <td>50.863543</td>\n      <td>4.329023</td>\n    </tr>\n    <tr>\n      <th>473</th>\n      <td>50.863418</td>\n      <td>4.330031</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gtfs_stops_df = pd.read_csv(stops_gtfs_path)\n",
    "gtfs_stops_df.dropna(axis=1, inplace=True)\n",
    "gtfs_stops_df['stop_id_int'] = gtfs_stops_df['stop_id'].apply(lambda stop_id: int(stop_id[:4]))\n",
    "gtfs_stops_df.drop(columns=['stop_id', 'location_type', 'stop_name'], inplace=True)\n",
    "gtfs_stops_df.set_index('stop_id_int', inplace=True)\n",
    "gtfs_stops_df.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "data": {
      "text/plain": "     lineId  direction  order stop_id        name_ascii              name  \\\n2987   001m          1      1    8733   GARE DE L'OUEST   Gare de l'Ouest   \n2988   001m          1      2    8742          BEEKKANT          Beekkant   \n2989   001m          1      3    8292      ETANGS NOIRS      Étangs Noirs   \n2990   001m          1      4    8282  COMTE DE FLANDRE  Comte de Flandre   \n2991   001m          1      5    8272  SAINTE-CATHERINE  Sainte-Catherine   \n\n      lambert_x  lambert_y  stop_id_int   stop_lat  stop_lon  \n2987   146633.5   170956.4         8733  50.848999  4.320948  \n2988   146776.5   171444.3         8742  50.853386  4.322974  \n2989   147492.7   171859.9         8292  50.857125  4.333143  \n2990   148013.6   171590.4         8282  50.854705  4.340542  \n2991   148539.5   171278.2         8272  50.851900  4.348012  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>lineId</th>\n      <th>direction</th>\n      <th>order</th>\n      <th>stop_id</th>\n      <th>name_ascii</th>\n      <th>name</th>\n      <th>lambert_x</th>\n      <th>lambert_y</th>\n      <th>stop_id_int</th>\n      <th>stop_lat</th>\n      <th>stop_lon</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>2987</th>\n      <td>001m</td>\n      <td>1</td>\n      <td>1</td>\n      <td>8733</td>\n      <td>GARE DE L'OUEST</td>\n      <td>Gare de l'Ouest</td>\n      <td>146633.5</td>\n      <td>170956.4</td>\n      <td>8733</td>\n      <td>50.848999</td>\n      <td>4.320948</td>\n    </tr>\n    <tr>\n      <th>2988</th>\n      <td>001m</td>\n      <td>1</td>\n      <td>2</td>\n      <td>8742</td>\n      <td>BEEKKANT</td>\n      <td>Beekkant</td>\n      <td>146776.5</td>\n      <td>171444.3</td>\n      <td>8742</td>\n      <td>50.853386</td>\n      <td>4.322974</td>\n    </tr>\n    <tr>\n      <th>2989</th>\n      <td>001m</td>\n      <td>1</td>\n      <td>3</td>\n      <td>8292</td>\n      <td>ETANGS NOIRS</td>\n      <td>Étangs Noirs</td>\n      <td>147492.7</td>\n      <td>171859.9</td>\n      <td>8292</td>\n      <td>50.857125</td>\n      <td>4.333143</td>\n    </tr>\n    <tr>\n      <th>2990</th>\n      <td>001m</td>\n      <td>1</td>\n      <td>4</td>\n      <td>8282</td>\n      <td>COMTE DE FLANDRE</td>\n      <td>Comte de Flandre</td>\n      <td>148013.6</td>\n      <td>171590.4</td>\n      <td>8282</td>\n      <td>50.854705</td>\n      <td>4.340542</td>\n    </tr>\n    <tr>\n      <th>2991</th>\n      <td>001m</td>\n      <td>1</td>\n      <td>5</td>\n      <td>8272</td>\n      <td>SAINTE-CATHERINE</td>\n      <td>Sainte-Catherine</td>\n      <td>148539.5</td>\n      <td>171278.2</td>\n      <td>8272</td>\n      <td>50.851900</td>\n      <td>4.348012</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joined_stops_df = shapefile_df.join(gtfs_stops_df, on='stop_id_int')\n",
    "joined_stops_df.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "data": {
      "text/plain": "     lineId  direction  order stop_id        name_ascii              name  \\\n3424   019t          1      1   5104F  GROOT-BIJGAARDEN  Groot-Bijgaarden   \n3467   019t          2     22   5169F  GROOT-BIJGAARDEN  Groot-Bijgaarden   \n\n      lambert_x  lambert_y  stop_id_int  stop_lat  stop_lon  \n3424   143429.4   172979.7         5104       NaN       NaN  \n3467   143385.5   172978.7         5169       NaN       NaN  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>lineId</th>\n      <th>direction</th>\n      <th>order</th>\n      <th>stop_id</th>\n      <th>name_ascii</th>\n      <th>name</th>\n      <th>lambert_x</th>\n      <th>lambert_y</th>\n      <th>stop_id_int</th>\n      <th>stop_lat</th>\n      <th>stop_lon</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>3424</th>\n      <td>019t</td>\n      <td>1</td>\n      <td>1</td>\n      <td>5104F</td>\n      <td>GROOT-BIJGAARDEN</td>\n      <td>Groot-Bijgaarden</td>\n      <td>143429.4</td>\n      <td>172979.7</td>\n      <td>5104</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>3467</th>\n      <td>019t</td>\n      <td>2</td>\n      <td>22</td>\n      <td>5169F</td>\n      <td>GROOT-BIJGAARDEN</td>\n      <td>Groot-Bijgaarden</td>\n      <td>143385.5</td>\n      <td>172978.7</td>\n      <td>5169</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joined_stops_df[joined_stops_df['stop_lat'].isna()]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [],
   "source": [
    "file = open(merged_stops_csv_path, 'w', encoding='utf8')\n",
    "joined_stops_df.to_csv(file, index=False)\n",
    "file.close()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Drop incomplete data from CSV\n",
    "\n",
    "Cleans `vehiclePositions.csv` file created in previous section\n",
    "**Reads from**: CSV file containing all the vehicle positions in `data` folder (`data/processed/assignment1/vehiclePositions.csv`)\n",
    "**Writes to**: CSV file containing filtered vehicle positions in `data` folder (`data/processed/assignment1/vehiclePositionsClean.csv`)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "stops_csv_path = '../data/processed/assignment1/line_stops.csv'\n",
    "positions_csv_path = '../data/processed/assignment1/vehiclePositions.csv'\n",
    "cleaned_positions_csv_path = '../data/processed/assignment1/vehiclePositionsClean.csv'"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "data": {
      "text/plain": "  lineId  direction  order stop_id        name_ascii              name  \\\n0   001m          1      1    8733   GARE DE L'OUEST   Gare de l'Ouest   \n1   001m          1      2    8742          BEEKKANT          Beekkant   \n2   001m          1      3    8292      ETANGS NOIRS      Étangs Noirs   \n3   001m          1      4    8282  COMTE DE FLANDRE  Comte de Flandre   \n4   001m          1      5    8272  SAINTE-CATHERINE  Sainte-Catherine   \n\n   lambert_x  lambert_y  stop_id_int   stop_lat  stop_lon  \n0   146633.5   170956.4         8733  50.848999  4.320948  \n1   146776.5   171444.3         8742  50.853386  4.322974  \n2   147492.7   171859.9         8292  50.857125  4.333143  \n3   148013.6   171590.4         8282  50.854705  4.340542  \n4   148539.5   171278.2         8272  50.851900  4.348012  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>lineId</th>\n      <th>direction</th>\n      <th>order</th>\n      <th>stop_id</th>\n      <th>name_ascii</th>\n      <th>name</th>\n      <th>lambert_x</th>\n      <th>lambert_y</th>\n      <th>stop_id_int</th>\n      <th>stop_lat</th>\n      <th>stop_lon</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>001m</td>\n      <td>1</td>\n      <td>1</td>\n      <td>8733</td>\n      <td>GARE DE L'OUEST</td>\n      <td>Gare de l'Ouest</td>\n      <td>146633.5</td>\n      <td>170956.4</td>\n      <td>8733</td>\n      <td>50.848999</td>\n      <td>4.320948</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>001m</td>\n      <td>1</td>\n      <td>2</td>\n      <td>8742</td>\n      <td>BEEKKANT</td>\n      <td>Beekkant</td>\n      <td>146776.5</td>\n      <td>171444.3</td>\n      <td>8742</td>\n      <td>50.853386</td>\n      <td>4.322974</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>001m</td>\n      <td>1</td>\n      <td>3</td>\n      <td>8292</td>\n      <td>ETANGS NOIRS</td>\n      <td>Étangs Noirs</td>\n      <td>147492.7</td>\n      <td>171859.9</td>\n      <td>8292</td>\n      <td>50.857125</td>\n      <td>4.333143</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>001m</td>\n      <td>1</td>\n      <td>4</td>\n      <td>8282</td>\n      <td>COMTE DE FLANDRE</td>\n      <td>Comte de Flandre</td>\n      <td>148013.6</td>\n      <td>171590.4</td>\n      <td>8282</td>\n      <td>50.854705</td>\n      <td>4.340542</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>001m</td>\n      <td>1</td>\n      <td>5</td>\n      <td>8272</td>\n      <td>SAINTE-CATHERINE</td>\n      <td>Sainte-Catherine</td>\n      <td>148539.5</td>\n      <td>171278.2</td>\n      <td>8272</td>\n      <td>50.851900</td>\n      <td>4.348012</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stops_df = pd.read_csv(stops_csv_path)\n",
    "stop_ids = stops_df['stop_id_int']\n",
    "stops_df.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "data": {
      "text/plain": "Timestamp            19421883\nLineId               19421883\nDirectionId          19421883\nDistanceFromPoint    19421883\nPointId              19421883\ndtype: int64"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "positions_df = pd.read_csv(positions_csv_path)\n",
    "positions_df.count()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "data": {
      "text/plain": "Timestamp            17153015\nLineId               17153015\nDirectionId          17153015\nDistanceFromPoint    17153015\nPointId              17153015\ndtype: int64"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaned_positions_df = positions_df[positions_df['DirectionId'].isin(stop_ids) & positions_df['PointId'].isin(stop_ids)]\n",
    "cleaned_positions_df.count()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "data": {
      "text/plain": "    original_counts  new_counts\n95           531447      240516\n7            529144      526086\n82           515924      506619\n81           504996      256610\n51           500110      483565",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>original_counts</th>\n      <th>new_counts</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>95</th>\n      <td>531447</td>\n      <td>240516</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>529144</td>\n      <td>526086</td>\n    </tr>\n    <tr>\n      <th>82</th>\n      <td>515924</td>\n      <td>506619</td>\n    </tr>\n    <tr>\n      <th>81</th>\n      <td>504996</td>\n      <td>256610</td>\n    </tr>\n    <tr>\n      <th>51</th>\n      <td>500110</td>\n      <td>483565</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "original_counts = positions_df['LineId'].value_counts()\n",
    "new_counts = cleaned_positions_df['LineId'].value_counts()\n",
    "counts_df = original_counts.to_frame('original_counts').join(new_counts.to_frame('new_counts'))\n",
    "counts_df.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [
    {
     "data": {
      "text/plain": "    original_counts  new_counts  positions_dropped  percentage_dropped\n1            305454      246596              58858           19.269023\n2            215114      214341                773            0.359344\n3            383543      373963               9580            2.497764\n4            282947      281293               1654            0.584562\n5            405897      405853                 44            0.010840\n..              ...         ...                ...                 ...\n92           486408      475895              10513            2.161354\n93           402974      223230             179744           44.604367\n95           531447      240516             290931           54.743182\n97           276705      276501                204            0.073725\n98            98755       98755                  0            0.000000\n\n[74 rows x 4 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>original_counts</th>\n      <th>new_counts</th>\n      <th>positions_dropped</th>\n      <th>percentage_dropped</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>1</th>\n      <td>305454</td>\n      <td>246596</td>\n      <td>58858</td>\n      <td>19.269023</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>215114</td>\n      <td>214341</td>\n      <td>773</td>\n      <td>0.359344</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>383543</td>\n      <td>373963</td>\n      <td>9580</td>\n      <td>2.497764</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>282947</td>\n      <td>281293</td>\n      <td>1654</td>\n      <td>0.584562</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>405897</td>\n      <td>405853</td>\n      <td>44</td>\n      <td>0.010840</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>92</th>\n      <td>486408</td>\n      <td>475895</td>\n      <td>10513</td>\n      <td>2.161354</td>\n    </tr>\n    <tr>\n      <th>93</th>\n      <td>402974</td>\n      <td>223230</td>\n      <td>179744</td>\n      <td>44.604367</td>\n    </tr>\n    <tr>\n      <th>95</th>\n      <td>531447</td>\n      <td>240516</td>\n      <td>290931</td>\n      <td>54.743182</td>\n    </tr>\n    <tr>\n      <th>97</th>\n      <td>276705</td>\n      <td>276501</td>\n      <td>204</td>\n      <td>0.073725</td>\n    </tr>\n    <tr>\n      <th>98</th>\n      <td>98755</td>\n      <td>98755</td>\n      <td>0</td>\n      <td>0.000000</td>\n    </tr>\n  </tbody>\n</table>\n<p>74 rows × 4 columns</p>\n</div>"
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counts_df['positions_dropped'] = counts_df['original_counts'] - counts_df['new_counts']\n",
    "counts_df['percentage_dropped'] = counts_df['positions_dropped'] * 100 / counts_df['original_counts']\n",
    "counts_df.sort_index(inplace=True)\n",
    "counts_df"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [],
   "source": [
    "cleaned_positions_df.to_csv(cleaned_positions_csv_path, index=False)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Add direction to CSV\n",
    "\n",
    "Adds direction to `vehiclePositionsClean.csv` file created in previous section\n",
    "**Reads from**: CSV file containing filtered vehicle positions in `data` folder (`data/processed/assignment1/vehiclePositionsClean.csv`)\n",
    "**Writes to**: CSV file containing filtered vehicle positions with direction in `data` folder (`data/processed/assignment1/vehiclePositionsCleanDirected.csv`)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "outputs": [],
   "source": [
    "def get_direction_from_line_stop_and_destination(line: Tuple[List[List[str]], List[List[str]]], stop_id: str,\n",
    "                                                 destination_id: str) -> int:\n",
    "    # Simple case 1 -> destination_id is in one direction but not in the other:\n",
    "    stops = ({stop[3] for stop in line[0]}, {stop[3] for stop in line[1]})\n",
    "    if destination_id in stops[0] and destination_id not in stops[1]:\n",
    "        return 0\n",
    "    if destination_id not in stops[0] and destination_id in stops[1]:\n",
    "        return 1\n",
    "\n",
    "    # Simple case 2 -> destination_id is the last stop of a direction:\n",
    "    if destination_id == line[0][-1][3]:\n",
    "        return 0\n",
    "    if destination_id == line[1][-1][3]:\n",
    "        return 1\n",
    "\n",
    "    # Simple case 3 -> stop_id is in one direction but not in the other:\n",
    "    if stop_id in stops[0] and stop_id not in stops[1]:\n",
    "        return 0\n",
    "    if stop_id not in stops[0] and stop_id in stops[1]:\n",
    "        return 1\n",
    "\n",
    "    # Complex case 1 -> if stop_id != destination_id, return the direction in which the stop with\n",
    "    # id destination_id is after the stop with id stop_id\n",
    "    if stop_id != destination_id:\n",
    "        index_of_destination_0 = next(int(stop[8]) for stop in line[0] if stop[3] == destination_id)\n",
    "        index_of_stop_0 = next(int(stop[8]) for stop in line[0] if stop[3] == stop_id)\n",
    "        return 0 if index_of_stop_0 < index_of_destination_0 else 1\n",
    "    # Complex case 2 -> if stop_id == destination_id, return the direction in which the stop with\n",
    "    # id destination_id is further down the direction\n",
    "    else:\n",
    "        index_of_destination_0 = next(int(stop[8]) for stop in line[0] if stop[3] == destination_id)\n",
    "        index_of_destination_1 = next(int(stop[8]) for stop in line[1] if stop[3] == destination_id)\n",
    "        return 0 if index_of_destination_0 > index_of_destination_1 else 1"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "outputs": [],
   "source": [
    "def add_direction_to_csv():\n",
    "    positions = read_csv_stream('../data/processed/assignment1/vehiclePositionsClean.csv', skip_first=False)\n",
    "    directed_positions, output_file = get_csv_writer('../data/processed/assignment1/vehiclePositionsCleanDirected.csv')\n",
    "    directed_positions.writerow([*next(positions), 'Direction'])\n",
    "    grouped_lines = group_line_stops(read_csv_stream('../data/processed/assignment1/line_stops.csv'))\n",
    "    memory = {}\n",
    "    for position in tqdm(positions):\n",
    "        line_id = position[1]\n",
    "        stop_id = position[4]\n",
    "        destination_id = position[2]\n",
    "        tuple_id = f'{line_id}-{stop_id}-{destination_id}'\n",
    "        if tuple_id not in memory:\n",
    "            memory[tuple_id] = get_direction_from_line_stop_and_destination(grouped_lines[line_id], stop_id,\n",
    "                                                                            destination_id)\n",
    "        directed_positions.writerow([*position, memory[tuple_id]])\n",
    "    output_file.close()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "outputs": [
    {
     "data": {
      "text/plain": "0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "faed921878bd4e2781e985a844ee1c72"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "add_direction_to_csv()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Split CSV into lines\n",
    "\n",
    "Splits `vehiclePositionsCleanDirected.csv` file created in previous section into separate CSV (one per line)\n",
    "**Reads from**: CSV file containing filtered vehicle positions with direction in `data` folder (`data/processed/assignment1/vehiclePositionsCleanDirected.csv`)\n",
    "**Writes to**: CSV file per line containing filtered vehicle positions with direction in `data/processed/assignment1/vehiclePositionsPerLine` folder (`data/processed/assignment1/vehiclePositionsPerLine/vehiclePositions*.csv`)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "outputs": [],
   "source": [
    "def split_csv_by_lines():\n",
    "    files = {}\n",
    "    positions = read_csv_stream('../data/processed/assignment1/vehiclePositionsCleanDirected.csv', skip_first=False)\n",
    "    output_dir = '../data/processed/assignment1/vehiclePositionsPerLine'\n",
    "    if not os.path.exists(output_dir):\n",
    "        os.mkdir(output_dir)\n",
    "    header = next(positions)\n",
    "    for line in tqdm(positions):\n",
    "        line_id = line[1]\n",
    "        if line_id not in files:\n",
    "            files[line_id] = get_csv_writer(\n",
    "                f'{output_dir}/vehiclePositions{line_id}.csv')\n",
    "            files[line_id][0].writerow(header)\n",
    "        files[line_id][0].writerow(line)\n",
    "    for _, file in files.values():\n",
    "        file.close()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "outputs": [
    {
     "data": {
      "text/plain": "0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "438e84fdea244a59b095e808bfd972c8"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "split_csv_by_lines()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Vehicle Matching\n",
    "\n",
    "Tries to link several vehicle positions belonging to same physical vehicle\n",
    "**Reads from**: CSV file per line containing filtered vehicle positions with direction in `data/processed/assignment1/vehiclePositionsPerLine` folder (`data/processed/assignment1/vehiclePositionsPerLine/vehiclePositions*.csv`)\n",
    "**Writes to**: CSV file per line containing vehicle positions with `bus_id` in `data/processed/assignment1/csv_lines_linked` folder (`data/processed/assignment1/csv_lines_linked/vehiclePositions*.csv`)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "outputs": [],
   "source": [
    "def split_positions_by_direction(positions: Iterable[List[str]]) -> Tuple[List[List[str]], List[List[str]]]:\n",
    "    line = ([], [])\n",
    "    for position in positions:\n",
    "        line[int(position[-1])].append(position)\n",
    "    return line"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "outputs": [],
   "source": [
    "def get_index_of_stop_in_line(line, direction, stop_id):\n",
    "    return get_index_of_stop_in_line_direction(line[direction], stop_id)\n",
    "\n",
    "\n",
    "def get_index_of_stop_in_line_direction(line, stop_id):\n",
    "    return next((int(stop[-1]) for stop in line if stop[3] == stop_id), -1)\n",
    "\n",
    "\n",
    "class Match(Enum):\n",
    "    WRONG = 1\n",
    "    OK = 2\n",
    "    TOO_FAR = 3"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "outputs": [],
   "source": [
    "def group_positions_by_timestamp(positions: Iterable[List[str]]) -> List[Tuple[int, List[List[str]]]]:\n",
    "    grouped_positions = []\n",
    "    old_timestamp = -1\n",
    "    current_timestamp_positions = []\n",
    "    for position in positions:\n",
    "        current_timestamp = int(position[0])\n",
    "        if current_timestamp != old_timestamp:\n",
    "            assert current_timestamp > old_timestamp\n",
    "            grouped_positions.append((old_timestamp, current_timestamp_positions))\n",
    "            old_timestamp = current_timestamp\n",
    "            current_timestamp_positions = []\n",
    "        current_timestamp_positions.append(position)\n",
    "    grouped_positions.append((old_timestamp, current_timestamp_positions))\n",
    "    return grouped_positions[1:]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "outputs": [],
   "source": [
    "def possible_match(first_position: List[str], second_position: List[str],\n",
    "                   line: List[List[str]]) -> Match:\n",
    "    first_stop_id = first_position[4]\n",
    "    second_stop_id = second_position[4]\n",
    "    # Both positions are in the same stop -> Compare using distance from that stop\n",
    "    if first_stop_id == second_stop_id:\n",
    "        first_distance = int(first_position[3])\n",
    "        second_distance = int(second_position[3])\n",
    "        return Match.OK if first_distance <= second_distance else Match.WRONG\n",
    "    # Positions are in different stops -> Compare using order of stops in direction\n",
    "    else:\n",
    "        # Assert both positions have the same direction\n",
    "        first_stop_index = get_index_of_stop_in_line_direction(line, first_stop_id)\n",
    "        second_stop_index = get_index_of_stop_in_line_direction(line, second_stop_id)\n",
    "        if second_stop_index - first_stop_index > 3:\n",
    "            return Match.TOO_FAR\n",
    "        return Match.OK if first_stop_index < second_stop_index else Match.WRONG"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "outputs": [],
   "source": [
    "def find_bus_matched_of_line_direction(positions: Iterable[List[str]], line: List[List[str]], line_id: str,\n",
    "                                       direction: int, writer):\n",
    "    grouped_positions = group_positions_by_timestamp(positions)\n",
    "    previous_positions = []\n",
    "    bus_id = (f'{line_id}-{direction}-{i:06d}' for i in count())\n",
    "    sorting_key = lambda vehicle_position: get_index_of_stop_in_line_direction(line, vehicle_position[-2])\n",
    "\n",
    "    for timestamp, current_positions in grouped_positions:\n",
    "        sorted_positions = sorted(current_positions, key=sorting_key)\n",
    "        while len(sorted_positions) > 0 and get_index_of_stop_in_line_direction(line, sorted_positions[0][-2]) == -1:\n",
    "            sorted_positions.pop(0)\n",
    "        current_previous_position_index = 0\n",
    "        current_position_index = 0\n",
    "        while current_position_index < len(sorted_positions) and current_previous_position_index < len(\n",
    "                previous_positions):\n",
    "            previous_position = previous_positions[current_previous_position_index]\n",
    "            current_position = sorted_positions[current_position_index]\n",
    "            result = possible_match(previous_position, current_position, line)\n",
    "            if result == Match.OK:\n",
    "                current_position.append(previous_position[-1])\n",
    "                current_previous_position_index += 1\n",
    "                current_position_index += 1\n",
    "            elif result == Match.WRONG:\n",
    "                current_position.append(next(bus_id))\n",
    "                current_position_index += 1\n",
    "            elif result == Match.TOO_FAR:\n",
    "                current_previous_position_index += 1\n",
    "        for position in sorted_positions:\n",
    "            if len(position) == 6:\n",
    "                position.append(next(bus_id))\n",
    "            writer.writerow(position)\n",
    "        previous_positions = sorted_positions"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "outputs": [],
   "source": [
    "def find_bus_matches_of_line(file_path: str, output_path: str, line_id: str,\n",
    "                             line: Tuple[List[List[str]], List[List[str]]]) -> None:\n",
    "    positions = read_csv_stream(file_path, skip_first=False)\n",
    "    with write_csv(output_path) as linked_positions:\n",
    "        linked_positions.writerow([*next(positions), 'BusId'])\n",
    "        direction1, direction2 = split_positions_by_direction(positions)\n",
    "        find_bus_matched_of_line_direction(direction1, line[0], line_id, 0, linked_positions)\n",
    "        find_bus_matched_of_line_direction(direction2, line[1], line_id, 1, linked_positions)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "outputs": [],
   "source": [
    "def find_bus_matches_of_lines():\n",
    "    path = '../data/processed/assignment1/vehiclePositionsPerLine'\n",
    "    output_path = '../data/processed/assignment1/csv_lines_linked'\n",
    "    if not os.path.exists(output_path):\n",
    "        os.mkdir(output_path)\n",
    "    lines = group_line_stops(read_csv_stream('../data/processed/assignment1/line_stops.csv'))\n",
    "    for file in tqdm(os.listdir(path)):\n",
    "        line_id = file[16:-4]\n",
    "        line = lines[line_id]\n",
    "        find_bus_matches_of_line(f'{path}/{file}', f'{output_path}/{file}', line_id, line)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "outputs": [
    {
     "data": {
      "text/plain": "  0%|          | 0/74 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "39561da5ff734247a896752555b99406"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "find_bus_matches_of_lines()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Calculate average time between stops"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "outputs": [],
   "source": [
    "def group_positions_by_vehicle(positions: List[List[str]]) -> Dict[str, List[List[List[str]]]]:\n",
    "    grouped_positions = {}\n",
    "    for position in positions:\n",
    "        bus_id = position[-1]\n",
    "        if bus_id not in grouped_positions:\n",
    "            grouped_positions[bus_id] = []\n",
    "        grouped_positions[bus_id].append(position)\n",
    "    return grouped_positions"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "outputs": [],
   "source": [
    "def get_hour_from_timestamp(timestamp: int) -> int:\n",
    "    return datetime.datetime.fromtimestamp(timestamp // 1000).hour"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "outputs": [],
   "source": [
    "def get_vehicle_times_between_stops(vehicle_positions: List[List[str]],\n",
    "                                    line: Tuple[List[List[str]], List[List[str]]]) -> List:\n",
    "    times = []\n",
    "    previous_timestamp = int(vehicle_positions[0][0])\n",
    "    previous_stop = vehicle_positions[0][4]\n",
    "    for position in vehicle_positions:\n",
    "        current_timestamp = int(position[0])\n",
    "        current_stop = position[4]\n",
    "        if current_stop != previous_stop:\n",
    "            time_difference = (current_timestamp - previous_timestamp) // 1000\n",
    "            first_hour = get_hour_from_timestamp(previous_timestamp)\n",
    "            last_hour = get_hour_from_timestamp(current_timestamp)\n",
    "            times.append([first_hour, previous_stop, current_stop, time_difference])\n",
    "            if first_hour != last_hour:\n",
    "                times.append([last_hour, previous_stop, current_stop, time_difference])\n",
    "            previous_stop = current_stop\n",
    "            previous_timestamp = current_timestamp\n",
    "    return times"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "outputs": [],
   "source": [
    "def calculate_average_time_between_stops_of_line(positions: List[List[str]], line_id: str,\n",
    "                                                 line: Tuple[List[List[str]], List[List[str]]], output):\n",
    "    grouped_positions = group_positions_by_vehicle(positions)\n",
    "    times = []\n",
    "    for vehicle_id, vehicle_positions in grouped_positions.items():\n",
    "        times += get_vehicle_times_between_stops(vehicle_positions, line)\n",
    "    for direction in [0, 1]:\n",
    "        for fromStop, toStop in zip(line[direction][:-1], line[direction][1:]):\n",
    "            time_sum = [0 for _ in range(24)]\n",
    "            time_sum_filtered = [0 for _ in range(24)]\n",
    "            time_count = [0 for _ in range(24)]\n",
    "            time_count_filtered = [0 for _ in range(24)]\n",
    "            for time in times:\n",
    "                if time[1] == fromStop[3] and time[2] == toStop[3]:\n",
    "                    time_sum[time[0]] += time[3]\n",
    "                    time_count[time[0]] += 1\n",
    "                    if time[3] < 6000:  # Times larger than 10 minutes are likely anomalies that shouldn't be counted\n",
    "                        time_sum_filtered[time[0]] += time[3]\n",
    "                        time_count_filtered[time[0]] += 1\n",
    "            output[0].writerow(\n",
    "                [line_id, fromStop[3], toStop[3],\n",
    "                 *[f'{total / amount:.2f}' if amount > 0 else 0 for total, amount in zip(time_sum, time_count)]])\n",
    "            output[1].writerow([line_id, fromStop[3], toStop[3], *time_count])\n",
    "            output[2].writerow(\n",
    "                [line_id, fromStop[3], toStop[3], *[f'{total / amount:.2f}' if amount > 0 else 0 for total, amount in\n",
    "                                                    zip(time_sum_filtered, time_count_filtered)]])\n",
    "            output[3].writerow([line_id, fromStop[3], toStop[3], *time_count_filtered])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "outputs": [],
   "source": [
    "def calculate_average_time_between_stops():\n",
    "    source_path = '../data/processed/assignment1/csv_lines_linked'\n",
    "    output_path = '../data/processed/assignment1/average_time_between_stops.csv'\n",
    "    output_path_filtered = '../data/processed/assignment1/average_time_between_stops_filtered.csv'\n",
    "    output_path_count = '../data/processed/assignment1/average_time_between_stops_count.csv'\n",
    "    output_path_filtered_count = '../data/processed/assignment1/average_time_between_stops_filtered_count.csv'\n",
    "    lines = group_line_stops(read_csv_stream('../data/processed/assignment1/line_stops.csv'))\n",
    "    with write_csv(output_path) as output, write_csv(output_path_filtered) as output_filtered, write_csv(\n",
    "            output_path_count) as output_count, write_csv(output_path_filtered_count) as output_filtered_count:\n",
    "        header = ['LineId', 'FromStop', 'ToStop', *[f'{i}' for i in range(24)], 'Day']\n",
    "        output.writerow(header)\n",
    "        output_filtered.writerow(header)\n",
    "        output_count.writerow(header)\n",
    "        output_filtered_count.writerow(header)\n",
    "        for file in tqdm(os.listdir(source_path)):\n",
    "            line_id = file[16:-4]\n",
    "            line = lines[line_id]\n",
    "            positions = read_csv_list(f'{source_path}/{file}')[1:]\n",
    "            calculate_average_time_between_stops_of_line(positions, line_id, line,\n",
    "                                                         (output, output_count, output_filtered, output_filtered_count))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "outputs": [
    {
     "data": {
      "text/plain": "  0%|          | 0/74 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "6864e6acc839472581cff702b0c8f1d2"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "calculate_average_time_between_stops()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "outputs": [],
   "source": [
    "def calculate_daily_average_time_between_stops():\n",
    "    source_path = '../data/processed/assignment1/csv_lines_linked'\n",
    "    output_path = '../data/processed/assignment1/daily_average_time_between_stops_filtered'\n",
    "    lines = group_line_stops(read_csv_stream('../data/processed/assignment1/line_stops.csv'))\n",
    "    header = ['LineId', 'FromStop', 'ToStop', *[f'{i}' for i in range(24)]]\n",
    "\n",
    "    class Dummy:\n",
    "        def writerow(self, *args):\n",
    "            pass\n",
    "\n",
    "    dummy = Dummy()\n",
    "    day_files = {}\n",
    "    for file in tqdm(os.listdir(source_path)):\n",
    "        line_id = file[16:-4]\n",
    "        line = lines[line_id]\n",
    "        positions = read_csv_list(f'{source_path}/{file}')[1:]\n",
    "        day_positions = {}\n",
    "        for position in positions:\n",
    "            day = datetime.datetime.fromtimestamp(int(position[0]) / 1000).date().strftime('%Y-%m-%d')\n",
    "            if day not in day_positions:\n",
    "                day_positions[day] = []\n",
    "            day_positions[day].append(position)\n",
    "        for day in day_positions:\n",
    "            if day not in day_files:\n",
    "                day_files[day] = get_csv_writer(f'{output_path}/{day}.csv')\n",
    "                day_files[day][0].writerow(header)\n",
    "            calculate_average_time_between_stops_of_line(day_positions[day], line_id, line,\n",
    "                                                         (dummy, dummy, day_files[day][0], dummy))\n",
    "    for writer, file in day_files.values():\n",
    "        file.close()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "outputs": [
    {
     "data": {
      "text/plain": "  0%|          | 0/74 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "a961a5135fa54b219b30d9417b67b9e2"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "calculate_daily_average_time_between_stops()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Import Libraries\n",
    "\n",
    "**Shapefile:** This is the pyshp library that is used to manipulate shapefiles.\n",
    "**Math:** This library is used for basic math functions to calculate distance between points"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "outputs": [],
   "source": [
    "line_stops = pd.read_csv('../data/processed/assignment1/line_stops.csv')\n",
    "sf_actu_lines = shapefile.Reader('../data/raw/shapefiles/ACTU_LINES.shp')\n",
    "# here we initialize shape_records, which includes a combination of the shapes and records from the shapefile. This combination will allow us to pull the lambert coordinates from the shapes as while also accessing the record information like line_id.\n",
    "shape_records = sf_actu_lines.shapeRecords()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Shapefile Distance Calculation Function\n",
    "\n",
    "Now that we have our libraries loaded and files imported, we will create a function that can calculate the distance between two points on a polyline. The start_point and end_point are indexes to tell us where we should start and stop calculating distance in the polyline. the line_segment is one of the shape elements that will be pulled from the shapefile. This calculation will be called later in an iterative for loop for each shape element withing shape_records.shape.\n",
    "\n",
    "We will calculate the distance between each point in the shapefile using Pythagoreas' theorem, since the units in both line_stops and the shapefile are already provided in Belgium Lambert 1972 format, which projects the points onto a flat surface."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "outputs": [],
   "source": [
    "def calculate_distance_between_polyline_points(start_point: int, stop_point: int,\n",
    "                                               line_segment: shapefile.Shape) -> float:\n",
    "    # initializing our total distance to 0\n",
    "    total_distance = 0\n",
    "    # we'll need to calculate the distance between each consecutive pair of coordinates, and will iterate\n",
    "    # from the start_point to the end_point. Each newly caluclated distance between points will be added\n",
    "    # to the sum total_distance and then returned.\n",
    "    for index in range(start_point, stop_point - 1):\n",
    "        current = index\n",
    "        next = index + 1\n",
    "        total_distance += sqrt(pow((line_segment.points[current][0] - line_segment.points[next][0]), 2) + pow(\n",
    "            (line_segment.points[current][1] - line_segment.points[next][1]), 2))\n",
    "    return total_distance\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Calculate Distance Between Stops\n",
    "\n",
    "Time to get to work! Here we several nested for loops that are used to compare match up the line in the shapefile to the line in the line_stops. For each matching line, we will cycle through to project the stop location ONTO the polyline. This is required because a bus stop can be imagined to be on a sidewalk, while the polyline is moving along the road.\n",
    "\n",
    "Once we have matched up our bus stop with the nearest polyline point, we move to the next stop and do the same. Having 2 stop locations projected, we can call the previously defined calculate_distance_between_polyline_points function to find the distance between these 2 stops.\n",
    "\n",
    "The first iteration of the loop will result in a dummy value, as it does not have a real stop to pair with. All of these dummy values are dropped once the dictionary that stores all values is transformed into a dataframe.\n",
    "\n",
    "The data frame will be accessed latter with the unique combination of [LineID + fromStopID + toStopID]. This combination will be different depending on which direction a vehicle is moving, as the stop id's are not the same on each side of a street.\n",
    "\n",
    "We will also hold onto the index value for the polyline location in case we need it later on for future predictions.\n",
    "\n",
    "**integration**: This is how things were integerated\n",
    "parameters: Here we dropped all stops before 4am because..."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "outputs": [],
   "source": [
    "# initialize a dictionary that will be used to make a dataframe and csv file with the following format:\n",
    "# |    LineId    |   FromStop  |   ToStop  |   distance    |    fromIndex   |    toIndex   |\n",
    "stop_distance = {'LineId': [], 'LineIdFormatted': [], 'LineId_GeoMerge': [], 'Type': [], 'Direction': [],\n",
    "                 'FromStop': [], 'ToStop': [], 'distance': [], 'fromIndex': [], 'toIndex': [],\n",
    "                 'FromStop_lat': [], 'FromStop_lon': [], 'ToStop_lat': [], 'ToStop_lon': []}\n",
    "\n",
    "# Initializing variables that will be used in loops\n",
    "last_pointID = 0\n",
    "last_stop_id = 0\n",
    "last_stop_lat = 0\n",
    "last_stop_lon = 0\n",
    "adjusted_stop_lat_GPS = 0\n",
    "adjusted_stop_lon_GPS = 0\n",
    "\n",
    "# look through each shape/record combo in the shape_records file. Each element of shape_records represents a single line (metro, bus or tram)\n",
    "for shape_record in shape_records:\n",
    "    record = shape_record.record\n",
    "    shape = shape_record.shape\n",
    "    # look through each of the stops that exist in the line_stops csv. Here we are going to only cycle through a subset of the line_stops where there is a match on LineId and the direction to reduce computation time.\n",
    "    for index, stop in line_stops[\n",
    "        (line_stops['lineId'] == record['LIGNE']) & (line_stops['direction'] == record['VARIANTE'])].sort_values(\n",
    "        by=['order']).iterrows():\n",
    "        # Initializing variables that will be used in loops\n",
    "        min_distance = 50\n",
    "        adjusted_stop_lat = 50\n",
    "        adjusted_stop_lon = 50\n",
    "        current_pointID = 0\n",
    "        current_stop_id = stop['stop_id_int']\n",
    "        stop_lat = stop['lambert_x']\n",
    "        stop_lon = stop['lambert_y']\n",
    "        #After choosing a single stop from the line_stops file, we will compare that stops lambert GPS position to each coordinate that makes up the polyline in the current shape_records shape. We are finding the closest location in the shape file to our bus stop location. This can be done using euclidean distance calculation because the coordinates are in lambert notation. Whichever location on the polyline is the closest becomes the projected location of the bus stop using the if statement.\n",
    "        for pointID in range(len(shape.points)):\n",
    "            point_lat = shape.points[pointID][0]\n",
    "            point_lon = shape.points[pointID][1]\n",
    "            distance = sqrt(pow((point_lat - stop_lat), 2) + pow((point_lon - stop_lon), 2))\n",
    "            # if statement to compare distances and updated if shorter. It also saves the polyline info for future use in predicting\n",
    "            # which method of transport is being used.\n",
    "            if distance < min_distance:\n",
    "                min_distance = distance\n",
    "                adjusted_stop_lat = point_lat\n",
    "                adjusted_stop_lon = point_lon\n",
    "                current_pointID = pointID\n",
    "                adjusted_stop_lat_GPS = stop['lat']\n",
    "                adjusted_stop_lon_GPS = stop['long']\n",
    "        # now we call a previously defined function to calculate the total distance between the location projected during the previous for loop iteration and the current loop iteration. We are able to do this because the stops have been sorted by descending order from first to last. The first row in the array will always be a dummy row and needs to be dropped afterwards.\n",
    "        distance_between_stops = calculate_distance_between_polyline_points(last_pointID, current_pointID, shape)\n",
    "        # we update our dictionary with all the values needed for distance between stops.\n",
    "        # we will also strip out the leading zeros and the trailing text characters indicating (b,t,m for bus, tram and metro)\n",
    "        stripped_line_id = stop['lineId'][:-1].strip(\"0\")\n",
    "        stop_distance['LineId'].append(stripped_line_id)\n",
    "        stop_distance['LineIdFormatted'].append(f\"line{stripped_line_id}\")\n",
    "        stop_distance['LineId_GeoMerge'].append(f\"{stop['lineId']}-{stop['direction']}\")\n",
    "        stop_distance['Type'].append(str(stop['lineId'][-1]))\n",
    "        stop_distance['Direction'].append(stop['direction'])\n",
    "        stop_distance['FromStop'].append(last_stop_id)\n",
    "        stop_distance['ToStop'].append(current_stop_id)\n",
    "        stop_distance['distance'].append(distance_between_stops)\n",
    "        stop_distance['fromIndex'].append(last_pointID)\n",
    "        stop_distance['toIndex'].append(current_pointID)\n",
    "        stop_distance['FromStop_lat'].append(last_stop_lat)\n",
    "        stop_distance['FromStop_lon'].append(last_stop_lon)\n",
    "        stop_distance['ToStop_lat'].append(adjusted_stop_lat_GPS)\n",
    "        stop_distance['ToStop_lon'].append(adjusted_stop_lon_GPS)\n",
    "        # after calculating the distance, we update the last stop id, point, and lat/lon to the currently being used before iterating through to the next bus stop. The current point becomes the last point for the next calculation.\n",
    "        last_stop_id = current_stop_id\n",
    "        last_pointID = current_pointID\n",
    "        last_stop_lat = adjusted_stop_lat_GPS\n",
    "        last_stop_lon = adjusted_stop_lon_GPS\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "outputs": [],
   "source": [
    "\n",
    "#stop_distance is a dictionary we can use to merge with GeoJSON\n",
    "\n",
    "# Opening JSON file\n",
    "json_shapes_path = '../data/raw/shapes_lat_long.json'\n",
    "with open(json_shapes_path, 'r') as file:\n",
    "    line_shapes_geojson = json.load(file)\n",
    "\n",
    "df_line_shapes_geojson = pd.json_normalize(line_shapes_geojson)\n",
    "df_stop_distance = pd.DataFrame.from_dict(stop_distance)\n",
    "\n",
    "sorted_geo_json = []\n",
    "for line_id, polyline in df_line_shapes_geojson.iteritems():\n",
    "    for stop_index, value in df_stop_distance.iterrows():\n",
    "        if line_id == value['LineId_GeoMerge']:\n",
    "            sorted_geo_json.append(polyline.values.__array__())  #df_line_shapes_geojson[line_id]\n",
    "\n",
    "#\n",
    "# add_geojson_to_distance_dictionary(stop_distance, line_shapes)\n",
    "# polyline_list = []\n",
    "# WKT_list = []\n",
    "#\n",
    "#\n",
    "# for stop_segment in df_stop_distance:\n",
    "#\n",
    "# for pointID in range(last_pointID, current_pointID+1):\n",
    "#     point_lat = shape.points[pointID][0]\n",
    "#     point_lon = shape.points[pointID][1]\n",
    "#     polyline_list.append([point_lat, point_lon])\n",
    "#     WKT_list.append(f\"{point_lat} {point_lon}\")\n",
    "#\n",
    "# geo_json_test[\"geojson\"].append(f'{{\"type\": \"FeatureCollection\", \"features\": [{{\"type\": \"Feature\", properties: {{}}, \"geometry\": {{\"type\": \"LineString\", \"coordinates\": {polyline_list}}}}}]}}')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     LineId LineIdFormatted LineId_GeoMerge Type  Direction  FromStop  ToStop  \\\n",
      "0         1           line1          001m-1    m          1         0    8733   \n",
      "1         1           line1          001m-1    m          1      8733    8742   \n",
      "2         1           line1          001m-1    m          1      8742    8292   \n",
      "3         1           line1          001m-1    m          1      8292    8282   \n",
      "4         1           line1          001m-1    m          1      8282    8272   \n",
      "...     ...             ...             ...  ...        ...       ...     ...   \n",
      "4171    218         line218          218b-2    b          2      9025    2209   \n",
      "4172    218         line218          218b-2    b          2      2209    2835   \n",
      "4173    218         line218          218b-2    b          2      2835    1901   \n",
      "4174    218         line218          218b-2    b          2      1901    2221   \n",
      "4175    218         line218          218b-2    b          2      2221    3347   \n",
      "\n",
      "        distance  fromIndex  toIndex  FromStop_lat  FromStop_lon  ToStop_lat  \\\n",
      "0       0.000000          0        0      0.000000      0.000000   50.848999   \n",
      "1     436.974259          0       21     50.848999      4.320948   50.853386   \n",
      "2     938.450685         21       74     50.853386      4.322974   50.857125   \n",
      "3     400.370796         74      109     50.857125      4.333143   50.854705   \n",
      "4     525.003844        109      151     50.854705      4.340542   50.851900   \n",
      "...          ...        ...      ...           ...           ...         ...   \n",
      "4171  290.633506        241      261     50.861751      4.356097   50.858919   \n",
      "4172  218.832815        261      269     50.858919      4.354478   50.857103   \n",
      "4173  698.633391        269      321     50.857103      4.353201   50.854210   \n",
      "4174  585.084436        321      349     50.854210      4.361510   50.849859   \n",
      "4175  662.986066        349      391     50.849859      4.360204   50.846595   \n",
      "\n",
      "      ToStop_lon                                            geojson  \n",
      "0       4.320948  {'type': 'FeatureCollection', 'features': [{'t...  \n",
      "1       4.322974  {'type': 'FeatureCollection', 'features': [{'t...  \n",
      "2       4.333143  {'type': 'FeatureCollection', 'features': [{'t...  \n",
      "3       4.340542  {'type': 'FeatureCollection', 'features': [{'t...  \n",
      "4       4.348012  {'type': 'FeatureCollection', 'features': [{'t...  \n",
      "...          ...                                                ...  \n",
      "4171    4.354478  {'type': 'FeatureCollection', 'features': [{'t...  \n",
      "4172    4.353201  {'type': 'FeatureCollection', 'features': [{'t...  \n",
      "4173    4.361510  {'type': 'FeatureCollection', 'features': [{'t...  \n",
      "4174    4.360204  {'type': 'FeatureCollection', 'features': [{'t...  \n",
      "4175    4.357038  {'type': 'FeatureCollection', 'features': [{'t...  \n",
      "\n",
      "[4176 rows x 15 columns]\n"
     ]
    }
   ],
   "source": [
    "df_line_shapes_geojson_transformed = df_line_shapes_geojson.transpose()[0].apply(lambda x: {\"type\": \"FeatureCollection\",\n",
    "                                                                                            \"features\": [\n",
    "                                                                                                {\"type\": \"Feature\",\n",
    "                                                                                                 \"properties\": {},\n",
    "                                                                                                 \"geometry\": {\n",
    "                                                                                                     \"type\": \"LineString\",\n",
    "                                                                                                     \"coordinates\": x}\n",
    "                                                                                                 }]\n",
    "                                                                                            })\n",
    "\n",
    "df_stop_distance_merged = df_stop_distance.merge(df_line_shapes_geojson_transformed, left_on='LineId_GeoMerge',\n",
    "                                                 right_index=True).rename(columns={0: 'geojson'})\n",
    "print(df_stop_distance_merged)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "outputs": [],
   "source": [
    "# now we convert the dictionary to a Pandas DataFrame for easier manipulation\n",
    "df_stop_distance_merged.drop(df_stop_distance_merged[df_stop_distance_merged['toIndex'] == 0].index, inplace=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Export to CSV\n",
    "\n",
    "We can now export the dataframe to a csv file for use in other parts of the cleaning and predicitons."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "outputs": [],
   "source": [
    "# finally, we export the distance to a csv file named stop_distance.csv\n",
    "df_stop_distance_merged.to_csv(r'../data/processed/assignment1/stop_distance.csv', index=False, header=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Calculate Speed"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "outputs": [],
   "source": [
    "stop_distance_path = '../data/processed/assignment1/stop_distance.csv'\n",
    "stop_time_path = '../data/processed/assignment1/average_time_between_stops_filtered.csv'\n",
    "\n",
    "# initialize a dictionary that will be used to make a dataframe and csv file with the following format:\n",
    "# |  LineID      | FromStop      |   ToStop   |   0    |   1   | ... |  23   |\n",
    "stop_time = pd.read_csv(stop_time_path)\n",
    "\n",
    "# |    LineID    |   FromStop    |   ToStop   |   distance    |    fromIndex   |    toIndex   |\n",
    "stop_distance = pd.read_csv(stop_distance_path)\n",
    "stop_distance['FromStop'].astype('float_', copy=True, errors='raise')\n",
    "stop_distance['ToStop'].astype('float_', copy=True, errors='raise')\n",
    "\n",
    "\n",
    "def calculate_speed(time: pd.DataFrame, distance: pd.DataFrame) -> pd.DataFrame:\n",
    "    merged_time_distance = time.merge(distance, how='left', on=['LineId', 'FromStop', 'ToStop'])\n",
    "    for hour in range(0, 24):\n",
    "        merged_time_distance[f\"speed{hour}\"] = (merged_time_distance['distance'] / merged_time_distance[\n",
    "            f\"{hour}\"]) * 3.6\n",
    "    merged_time_distance.drop(columns=['distance', *[f'{i}' for i in range(24)]], inplace=True)\n",
    "    return merged_time_distance\n",
    "\n",
    "\n",
    "df_speed = calculate_speed(stop_time, stop_distance)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "outputs": [],
   "source": [
    "df_speed.to_csv(r'../data/processed/assignment1/vehicleSpeed.csv', index=False, header=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Reformat data for use in visualization"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "outputs": [],
   "source": [
    "# LineId,FromStop,ToStop,FromStop_lat,FromStop_lon,ToStop_lat,ToStop_lon,speed0,speed1,speed2\n",
    "\n",
    "new_header = ['LineId', 'FromStop', 'ToStop', 'Day', 'LineIdFormatted', 'LineId_GeoMerge', 'Type', 'Direction',\n",
    "              'fromIndex', 'toIndex', 'FromStop_lat', 'FromStop_lon', 'ToStop_lat', 'ToStop_lon', 'geojson', 'hour',\n",
    "              'speed']\n",
    "\n",
    "with write_csv('../data/processed/assignment1/vehicleSpeedReformatted.csv') as output:\n",
    "    output.writerow(new_header)\n",
    "    speeds = read_csv_stream('../data/processed/assignment1/vehicleSpeed.csv', skip_first=True)\n",
    "    for speed_line in speeds:\n",
    "        output.writerows([[*speed_line[:15], f'{hour:02d}:00', speed_line[15 + hour]] for hour in range(24)])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Merge Delays with Speed"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "outputs": [],
   "source": [
    "vehicle_speed = '../data/processed/assignment1/vehicleSpeedReformatted.csv'\n",
    "stop_delays = '../data/processed/assignment2/grouped_visual_data_ass2.csv'\n",
    "\n",
    "df_vehicle_speed = pd.read_csv(vehicle_speed)\n",
    "df_stop_delays = pd.read_csv(stop_delays)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   LineId  FromStop  ToStop  Day LineIdFormatted LineId_GeoMerge Type  \\\n",
      "0      37      2957    5810  NaN          line37          037b-1    b   \n",
      "1      37      2957    5810  NaN          line37          037b-1    b   \n",
      "2      37      2957    5810  NaN          line37          037b-1    b   \n",
      "3      37      2957    5810  NaN          line37          037b-1    b   \n",
      "4      37      2957    5810  NaN          line37          037b-1    b   \n",
      "\n",
      "   Direction  fromIndex  toIndex  FromStop_lat  FromStop_lon  ToStop_lat  \\\n",
      "0        1.0       49.0     57.0     50.821413      4.341859   50.818572   \n",
      "1        1.0       49.0     57.0     50.821413      4.341859   50.818572   \n",
      "2        1.0       49.0     57.0     50.821413      4.341859   50.818572   \n",
      "3        1.0       49.0     57.0     50.821413      4.341859   50.818572   \n",
      "4        1.0       49.0     57.0     50.821413      4.341859   50.818572   \n",
      "\n",
      "   ToStop_lon                                            geojson   hour  \\\n",
      "0    4.340952  {'type': 'FeatureCollection', 'features': [{'t...  00:00   \n",
      "1    4.340952  {'type': 'FeatureCollection', 'features': [{'t...  01:00   \n",
      "2    4.340952  {'type': 'FeatureCollection', 'features': [{'t...  02:00   \n",
      "3    4.340952  {'type': 'FeatureCollection', 'features': [{'t...  03:00   \n",
      "4    4.340952  {'type': 'FeatureCollection', 'features': [{'t...  04:00   \n",
      "\n",
      "       speed  \n",
      "0  14.936818  \n",
      "1        inf  \n",
      "2        inf  \n",
      "3        inf  \n",
      "4        inf  \n",
      "   Unnamed: 0 LineId Type  CurrentStop  Direction   Time  Day  Delay  \\\n",
      "0           0  line1    m         8011          2  05:00    0   -321   \n",
      "1           1  line1    m         8011          2  05:00    1   -411   \n",
      "2           2  line1    m         8011          2  06:00    0    -76   \n",
      "3           3  line1    m         8011          2  06:00    1   -237   \n",
      "4           4  line1    m         8011          2  07:00    0    -67   \n",
      "\n",
      "      stop_name   stop_lat  stop_lon  \n",
      "0  DE BROUCKERE  50.850095  4.352165  \n",
      "1  DE BROUCKERE  50.850095  4.352165  \n",
      "2  DE BROUCKERE  50.850095  4.352165  \n",
      "3  DE BROUCKERE  50.850095  4.352165  \n",
      "4  DE BROUCKERE  50.850095  4.352165  \n"
     ]
    }
   ],
   "source": [
    "print(df_vehicle_speed.head())\n",
    "print(df_stop_delays.head())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}