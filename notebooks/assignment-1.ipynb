{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Assignment 1"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "import datetime\n",
    "import json\n",
    "import os\n",
    "from enum import Enum\n",
    "from functools import reduce\n",
    "from itertools import count\n",
    "from operator import add\n",
    "\n",
    "import pandas as pd\n",
    "import shapefile\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "from scripts.helpers import *"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Raw JSON to CSV\n",
    "\n",
    "Converts raw JSON files containing the vehiclePositions from STIB to a single CSV file\n",
    "**Reads from**: raw JSON files in `data/raw` folder (`data/raw/vehiclePosition*.json`)\n",
    "**Writes to**: Single CSV file containing all the vehicle positions in `data` folder (`data/processed/assignment1/vehiclePositions.csv`)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "raw_json_files = [\n",
    "    '../data/raw/vehicleTimestamp/vehiclePosition01.json',\n",
    "    '../data/raw/vehicleTimestamp/vehiclePosition02.json',\n",
    "    '../data/raw/vehicleTimestamp/vehiclePosition03.json',\n",
    "    '../data/raw/vehicleTimestamp/vehiclePosition04.json',\n",
    "    '../data/raw/vehicleTimestamp/vehiclePosition05.json',\n",
    "    '../data/raw/vehicleTimestamp/vehiclePosition06.json',\n",
    "    '../data/raw/vehicleTimestamp/vehiclePosition07.json',\n",
    "    '../data/raw/vehicleTimestamp/vehiclePosition08.json',\n",
    "    '../data/raw/vehicleTimestamp/vehiclePosition09.json',\n",
    "    '../data/raw/vehicleTimestamp/vehiclePosition10.json',\n",
    "    '../data/raw/vehicleTimestamp/vehiclePosition11.json',\n",
    "    '../data/raw/vehicleTimestamp/vehiclePosition12.json',\n",
    "    '../data/raw/vehicleTimestamp/vehiclePosition13.json'\n",
    "]\n",
    "vehicle_positions_csv = '../data/processed/assignment1/vehiclePositions.csv'\n",
    "csv_header = ['Timestamp', 'LineId', 'DirectionId', 'DistanceFromPoint', 'PointId']"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "data": {
      "text/plain": "  0%|          | 0/13 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "14ac395d92aa479893bf1b5d9aa6a407"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "with write_csv(vehicle_positions_csv) as writer:\n",
    "    writer.writerow(csv_header)\n",
    "    for raw_json_path in tqdm(raw_json_files):\n",
    "        file = open(raw_json_path, 'r', encoding='utf8')\n",
    "        data = json.load(file)['data']\n",
    "        file.close()\n",
    "        for time in data:\n",
    "            timestamp = time['time']\n",
    "            for response in time['Responses']:\n",
    "                if response is None:\n",
    "                    # Skip if response is empty\n",
    "                    continue\n",
    "                for line in response['lines']:\n",
    "                    line_id = line['lineId']\n",
    "                    for vehiclePosition in line['vehiclePositions']:\n",
    "                        writer.writerow([\n",
    "                            timestamp,\n",
    "                            line_id,\n",
    "                            vehiclePosition['directionId'],\n",
    "                            vehiclePosition['distanceFromPoint'],\n",
    "                            vehiclePosition['pointId'],\n",
    "                        ])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "data": {
      "text/plain": "       Timestamp  LineId  DirectionId  DistanceFromPoint  PointId\n0  1630914886924       1         8161                  1     8012\n1  1630914886924       1         8162                  0     8142\n2  1630914886924       1         8162                  0     8282\n3  1630914886924       1         8731                  0     8111\n4  1630914886924       1         8162                  1     8062",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Timestamp</th>\n      <th>LineId</th>\n      <th>DirectionId</th>\n      <th>DistanceFromPoint</th>\n      <th>PointId</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1630914886924</td>\n      <td>1</td>\n      <td>8161</td>\n      <td>1</td>\n      <td>8012</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1630914886924</td>\n      <td>1</td>\n      <td>8162</td>\n      <td>0</td>\n      <td>8142</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1630914886924</td>\n      <td>1</td>\n      <td>8162</td>\n      <td>0</td>\n      <td>8282</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1630914886924</td>\n      <td>1</td>\n      <td>8731</td>\n      <td>0</td>\n      <td>8111</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1630914886924</td>\n      <td>1</td>\n      <td>8162</td>\n      <td>1</td>\n      <td>8062</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vehicle_positions_df = pd.read_csv(vehicle_positions_csv)\n",
    "vehicle_positions_df.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Shapefile to routes\n",
    "\n",
    "Converts raw Stops Shapefiles from STIB to a single CSV file containing line routes\n",
    "**Reads from**:\n",
    " - Shapefiles in `data/raw/shapefiles` folder (`data/raw/shapefiles/ACTU_STOPS.*`)\n",
    " - `stops.txt` GTFS file in `data/raw/gtfs` folder\n",
    "\n",
    "**Writes to**: Single CSV file containing all the line routes in `data` folder (`data/line_stops.csv`)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [],
   "source": [
    "csv_header = ['lineId', 'direction', 'stop_id', 'stop_id_int', 'name', 'name_ascii', 'lat', 'long', 'lambert_x',\n",
    "              'lambert_y', 'order']\n",
    "stops_shapefile_path = '../data/raw/shapefiles/ACTU_STOPS.shp'\n",
    "stops_gtfs_path = '../data/raw/gtfs/stops.csv'\n",
    "merged_stops_csv_path = '../data/processed/assignment1/line_stops.csv'"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "data": {
      "text/plain": "  Code_Ligne  Variante  succession stop_id          descr_fr  \\\n0       012b         1           1   9600B  BRUSSELS AIRPORT   \n1       012b         1           2    3017           BOURGET   \n2       012b         1           3    5048          DA VINCI   \n3       012b         1           4    2695            GENEVE   \n4       012b         1           5    2250            MEISER   \n\n           descr_nl          alpha_fr          alpha_nl   coord_x   coord_y  \\\n0  BRUSSELS AIRPORT  Brussels Airport  Brussels Airport  157950.0  176429.0   \n1           BOURGET           Bourget           Bourget  154334.0  174200.0   \n2          DA VINCI          Da Vinci          Da Vinci  152934.0  173976.0   \n3            GENEVE            Genève            Genève  152428.0  172606.0   \n4            MEISER            Meiser            Meiser  152045.0  171508.0   \n\n  mode  numero_lig       terminus  \n0    B          12  BRUSSELS CITY  \n1    B          12  BRUSSELS CITY  \n2    B          12  BRUSSELS CITY  \n3    B          12  BRUSSELS CITY  \n4    B          12  BRUSSELS CITY  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Code_Ligne</th>\n      <th>Variante</th>\n      <th>succession</th>\n      <th>stop_id</th>\n      <th>descr_fr</th>\n      <th>descr_nl</th>\n      <th>alpha_fr</th>\n      <th>alpha_nl</th>\n      <th>coord_x</th>\n      <th>coord_y</th>\n      <th>mode</th>\n      <th>numero_lig</th>\n      <th>terminus</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>012b</td>\n      <td>1</td>\n      <td>1</td>\n      <td>9600B</td>\n      <td>BRUSSELS AIRPORT</td>\n      <td>BRUSSELS AIRPORT</td>\n      <td>Brussels Airport</td>\n      <td>Brussels Airport</td>\n      <td>157950.0</td>\n      <td>176429.0</td>\n      <td>B</td>\n      <td>12</td>\n      <td>BRUSSELS CITY</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>012b</td>\n      <td>1</td>\n      <td>2</td>\n      <td>3017</td>\n      <td>BOURGET</td>\n      <td>BOURGET</td>\n      <td>Bourget</td>\n      <td>Bourget</td>\n      <td>154334.0</td>\n      <td>174200.0</td>\n      <td>B</td>\n      <td>12</td>\n      <td>BRUSSELS CITY</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>012b</td>\n      <td>1</td>\n      <td>3</td>\n      <td>5048</td>\n      <td>DA VINCI</td>\n      <td>DA VINCI</td>\n      <td>Da Vinci</td>\n      <td>Da Vinci</td>\n      <td>152934.0</td>\n      <td>173976.0</td>\n      <td>B</td>\n      <td>12</td>\n      <td>BRUSSELS CITY</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>012b</td>\n      <td>1</td>\n      <td>4</td>\n      <td>2695</td>\n      <td>GENEVE</td>\n      <td>GENEVE</td>\n      <td>Genève</td>\n      <td>Genève</td>\n      <td>152428.0</td>\n      <td>172606.0</td>\n      <td>B</td>\n      <td>12</td>\n      <td>BRUSSELS CITY</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>012b</td>\n      <td>1</td>\n      <td>5</td>\n      <td>2250</td>\n      <td>MEISER</td>\n      <td>MEISER</td>\n      <td>Meiser</td>\n      <td>Meiser</td>\n      <td>152045.0</td>\n      <td>171508.0</td>\n      <td>B</td>\n      <td>12</td>\n      <td>BRUSSELS CITY</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stops_shapefile = shapefile.Reader(stops_shapefile_path)\n",
    "# We take the first value of each field tuple (it's name), and skip the first field (DeletionFlag field, not relevant)\n",
    "stop_fields = [field[0] for field in stops_shapefile.fields][1:]\n",
    "shapefile_df = pd.DataFrame(stops_shapefile.records(), columns=stop_fields)\n",
    "shapefile_df.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "data": {
      "text/plain": "     lineId  direction  order stop_id        name_ascii              name  \\\n2987   001m          1      1    8733   GARE DE L'OUEST   Gare de l'Ouest   \n2988   001m          1      2    8742          BEEKKANT          Beekkant   \n2989   001m          1      3    8292      ETANGS NOIRS      Étangs Noirs   \n2990   001m          1      4    8282  COMTE DE FLANDRE  Comte de Flandre   \n2991   001m          1      5    8272  SAINTE-CATHERINE  Sainte-Catherine   \n\n      lambert_x  lambert_y  stop_id_int  \n2987   146633.5   170956.4         8733  \n2988   146776.5   171444.3         8742  \n2989   147492.7   171859.9         8292  \n2990   148013.6   171590.4         8282  \n2991   148539.5   171278.2         8272  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>lineId</th>\n      <th>direction</th>\n      <th>order</th>\n      <th>stop_id</th>\n      <th>name_ascii</th>\n      <th>name</th>\n      <th>lambert_x</th>\n      <th>lambert_y</th>\n      <th>stop_id_int</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>2987</th>\n      <td>001m</td>\n      <td>1</td>\n      <td>1</td>\n      <td>8733</td>\n      <td>GARE DE L'OUEST</td>\n      <td>Gare de l'Ouest</td>\n      <td>146633.5</td>\n      <td>170956.4</td>\n      <td>8733</td>\n    </tr>\n    <tr>\n      <th>2988</th>\n      <td>001m</td>\n      <td>1</td>\n      <td>2</td>\n      <td>8742</td>\n      <td>BEEKKANT</td>\n      <td>Beekkant</td>\n      <td>146776.5</td>\n      <td>171444.3</td>\n      <td>8742</td>\n    </tr>\n    <tr>\n      <th>2989</th>\n      <td>001m</td>\n      <td>1</td>\n      <td>3</td>\n      <td>8292</td>\n      <td>ETANGS NOIRS</td>\n      <td>Étangs Noirs</td>\n      <td>147492.7</td>\n      <td>171859.9</td>\n      <td>8292</td>\n    </tr>\n    <tr>\n      <th>2990</th>\n      <td>001m</td>\n      <td>1</td>\n      <td>4</td>\n      <td>8282</td>\n      <td>COMTE DE FLANDRE</td>\n      <td>Comte de Flandre</td>\n      <td>148013.6</td>\n      <td>171590.4</td>\n      <td>8282</td>\n    </tr>\n    <tr>\n      <th>2991</th>\n      <td>001m</td>\n      <td>1</td>\n      <td>5</td>\n      <td>8272</td>\n      <td>SAINTE-CATHERINE</td>\n      <td>Sainte-Catherine</td>\n      <td>148539.5</td>\n      <td>171278.2</td>\n      <td>8272</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shapefile_df.drop(columns=['descr_nl', 'alpha_nl', 'mode', 'numero_lig', 'terminus'], inplace=True)\n",
    "renames = {'Code_Ligne': 'lineId',\n",
    "           'Variante': 'direction',\n",
    "           'succession': 'order',\n",
    "           'descr_fr': 'name_ascii',\n",
    "           'alpha_fr': 'name',\n",
    "           'coord_x': 'lambert_x',\n",
    "           'coord_y': 'lambert_y'}\n",
    "shapefile_df.rename(columns=renames, inplace=True)\n",
    "shapefile_df.sort_values(['lineId', 'direction', 'order'], inplace=True)\n",
    "shapefile_df['stop_id_int'] = shapefile_df['stop_id'].apply(lambda stop_id: int(stop_id[:4]))\n",
    "shapefile_df.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "data": {
      "text/plain": "    stop_lat  stop_lon  stop_id_int\n0  50.838006  4.408970           89\n1  50.863666  4.329612          470\n2  50.863732  4.329236          471\n3  50.863543  4.329023          472\n4  50.863418  4.330031          473",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>stop_lat</th>\n      <th>stop_lon</th>\n      <th>stop_id_int</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>50.838006</td>\n      <td>4.408970</td>\n      <td>89</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>50.863666</td>\n      <td>4.329612</td>\n      <td>470</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>50.863732</td>\n      <td>4.329236</td>\n      <td>471</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>50.863543</td>\n      <td>4.329023</td>\n      <td>472</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>50.863418</td>\n      <td>4.330031</td>\n      <td>473</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gtfs_stops_df = pd.read_csv(stops_gtfs_path)\n",
    "gtfs_stops_df.dropna(axis=1, inplace=True)\n",
    "gtfs_stops_df.drop(columns=['stop_id', 'location_type', 'stop_name'], inplace=True)\n",
    "gtfs_stops_df['stop_id_int'] = gtfs_stops_df['stop_id'].apply(lambda stop_id: int(stop_id[:4]))\n",
    "gtfs_stops_df.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [
    {
     "data": {
      "text/plain": "     lineId  direction  order stop_id        name_ascii              name  \\\n2987   001m          1      1    8733   GARE DE L'OUEST   Gare de l'Ouest   \n2988   001m          1      2    8742          BEEKKANT          Beekkant   \n2989   001m          1      3    8292      ETANGS NOIRS      Étangs Noirs   \n2990   001m          1      4    8282  COMTE DE FLANDRE  Comte de Flandre   \n2991   001m          1      5    8272  SAINTE-CATHERINE  Sainte-Catherine   \n\n      lambert_x  lambert_y  stop_id_int   stop_lat  stop_lon  \n2987   146633.5   170956.4         8733  50.848999  4.320948  \n2988   146776.5   171444.3         8742  50.853386  4.322974  \n2989   147492.7   171859.9         8292  50.857125  4.333143  \n2990   148013.6   171590.4         8282  50.854705  4.340542  \n2991   148539.5   171278.2         8272  50.851900  4.348012  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>lineId</th>\n      <th>direction</th>\n      <th>order</th>\n      <th>stop_id</th>\n      <th>name_ascii</th>\n      <th>name</th>\n      <th>lambert_x</th>\n      <th>lambert_y</th>\n      <th>stop_id_int</th>\n      <th>stop_lat</th>\n      <th>stop_lon</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>2987</th>\n      <td>001m</td>\n      <td>1</td>\n      <td>1</td>\n      <td>8733</td>\n      <td>GARE DE L'OUEST</td>\n      <td>Gare de l'Ouest</td>\n      <td>146633.5</td>\n      <td>170956.4</td>\n      <td>8733</td>\n      <td>50.848999</td>\n      <td>4.320948</td>\n    </tr>\n    <tr>\n      <th>2988</th>\n      <td>001m</td>\n      <td>1</td>\n      <td>2</td>\n      <td>8742</td>\n      <td>BEEKKANT</td>\n      <td>Beekkant</td>\n      <td>146776.5</td>\n      <td>171444.3</td>\n      <td>8742</td>\n      <td>50.853386</td>\n      <td>4.322974</td>\n    </tr>\n    <tr>\n      <th>2989</th>\n      <td>001m</td>\n      <td>1</td>\n      <td>3</td>\n      <td>8292</td>\n      <td>ETANGS NOIRS</td>\n      <td>Étangs Noirs</td>\n      <td>147492.7</td>\n      <td>171859.9</td>\n      <td>8292</td>\n      <td>50.857125</td>\n      <td>4.333143</td>\n    </tr>\n    <tr>\n      <th>2990</th>\n      <td>001m</td>\n      <td>1</td>\n      <td>4</td>\n      <td>8282</td>\n      <td>COMTE DE FLANDRE</td>\n      <td>Comte de Flandre</td>\n      <td>148013.6</td>\n      <td>171590.4</td>\n      <td>8282</td>\n      <td>50.854705</td>\n      <td>4.340542</td>\n    </tr>\n    <tr>\n      <th>2991</th>\n      <td>001m</td>\n      <td>1</td>\n      <td>5</td>\n      <td>8272</td>\n      <td>SAINTE-CATHERINE</td>\n      <td>Sainte-Catherine</td>\n      <td>148539.5</td>\n      <td>171278.2</td>\n      <td>8272</td>\n      <td>50.851900</td>\n      <td>4.348012</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joined_stops_df = shapefile_df.join(gtfs_stops_df.set_index('stop_id_int'), on='stop_id_int')\n",
    "joined_stops_df.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [
    {
     "data": {
      "text/plain": "     lineId  direction  order stop_id        name_ascii              name  \\\n3424   019t          1      1   5104F  GROOT-BIJGAARDEN  Groot-Bijgaarden   \n3467   019t          2     22   5169F  GROOT-BIJGAARDEN  Groot-Bijgaarden   \n\n      lambert_x  lambert_y  stop_id_int  stop_lat  stop_lon  \n3424   143429.4   172979.7         5104       NaN       NaN  \n3467   143385.5   172978.7         5169       NaN       NaN  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>lineId</th>\n      <th>direction</th>\n      <th>order</th>\n      <th>stop_id</th>\n      <th>name_ascii</th>\n      <th>name</th>\n      <th>lambert_x</th>\n      <th>lambert_y</th>\n      <th>stop_id_int</th>\n      <th>stop_lat</th>\n      <th>stop_lon</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>3424</th>\n      <td>019t</td>\n      <td>1</td>\n      <td>1</td>\n      <td>5104F</td>\n      <td>GROOT-BIJGAARDEN</td>\n      <td>Groot-Bijgaarden</td>\n      <td>143429.4</td>\n      <td>172979.7</td>\n      <td>5104</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>3467</th>\n      <td>019t</td>\n      <td>2</td>\n      <td>22</td>\n      <td>5169F</td>\n      <td>GROOT-BIJGAARDEN</td>\n      <td>Groot-Bijgaarden</td>\n      <td>143385.5</td>\n      <td>172978.7</td>\n      <td>5169</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joined_stops_df[joined_stops_df['stop_lat'].isna()]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [],
   "source": [
    "file = open(merged_stops_csv_path, 'w', encoding='utf8')\n",
    "joined_stops_df.to_csv(file)\n",
    "file.close()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Drop incomplete data from CSV\n",
    "\n",
    "Cleans `vehiclePositions.csv` file created in previous section\n",
    "**Reads from**: CSV file containing all the vehicle positions in `data` folder (`data/processed/assignment1/vehiclePositions.csv`)\n",
    "**Writes to**: CSV file containing filtered vehicle positions in `data` folder (`data/processed/assignment1/vehiclePositionsClean.csv`)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "outputs": [],
   "source": [
    "def drop_positions_with_unknown_stop_or_direction():\n",
    "    total_count = {}\n",
    "    deletion_count = {}\n",
    "    stops = {f'{int(stop[0][:-1])}-{stop[3]}' for stop in\n",
    "             read_csv_stream('../data/processed/assignment1/line_stops.csv')}\n",
    "    positions = read_csv_stream('../data/processed/assignment1/vehiclePositions.csv', skip_first=False)\n",
    "    with write_csv('../data/processed/assignment1/vehiclePositionsClean.csv') as writer:\n",
    "        writer.writerow(next(positions))\n",
    "        for position in tqdm(positions):\n",
    "            line_id = position[1]\n",
    "            if line_id not in total_count:\n",
    "                total_count[line_id] = 0\n",
    "            if line_id not in deletion_count:\n",
    "                deletion_count[line_id] = 0\n",
    "            direction_id = position[2]\n",
    "            stop_id = position[4]\n",
    "            total_count[line_id] += 1\n",
    "            if f'{line_id}-{direction_id}' not in stops or f'{line_id}-{stop_id}' not in stops:\n",
    "                deletion_count[line_id] += 1\n",
    "            else:\n",
    "                writer.writerow(position)\n",
    "    for line in sorted(total_count):\n",
    "        deleted = deletion_count[line]\n",
    "        total = total_count[line]\n",
    "        print(f'\\tLine {line}: {deleted} rows deleted out of {total} ({(deleted / total) * 100:.2f}%)')\n",
    "    total_rows = reduce(add, total_count.values())\n",
    "    total_deletions = reduce(add, deletion_count.values())\n",
    "    print(f'\\tTotal: {total_deletions} rows deleted out of {total_rows} ({(total_deletions / total_rows) * 100:.2f}%)')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "outputs": [
    {
     "data": {
      "text/plain": "0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "91a9dd006ce7415b9c5262e33cf93be6"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLine 1: 63100 rows deleted out of 305454 (20.66%)\n",
      "\tLine 12: 2091 rows deleted out of 238655 (0.88%)\n",
      "\tLine 13: 12387 rows deleted out of 231422 (5.35%)\n",
      "\tLine 14: 26554 rows deleted out of 272554 (9.74%)\n",
      "\tLine 17: 393 rows deleted out of 93979 (0.42%)\n",
      "\tLine 19: 9177 rows deleted out of 374100 (2.45%)\n",
      "\tLine 2: 4129 rows deleted out of 215114 (1.92%)\n",
      "\tLine 20: 12947 rows deleted out of 240316 (5.39%)\n",
      "\tLine 21: 5420 rows deleted out of 196146 (2.76%)\n",
      "\tLine 25: 349123 rows deleted out of 387235 (90.16%)\n",
      "\tLine 27: 34005 rows deleted out of 222168 (15.31%)\n",
      "\tLine 28: 13419 rows deleted out of 188596 (7.12%)\n",
      "\tLine 29: 37447 rows deleted out of 352595 (10.62%)\n",
      "\tLine 3: 162263 rows deleted out of 383543 (42.31%)\n",
      "\tLine 33: 0 rows deleted out of 69363 (0.00%)\n",
      "\tLine 34: 77757 rows deleted out of 271519 (28.64%)\n",
      "\tLine 36: 8227 rows deleted out of 243214 (3.38%)\n",
      "\tLine 37: 33673 rows deleted out of 163857 (20.55%)\n",
      "\tLine 38: 8697 rows deleted out of 346695 (2.51%)\n",
      "\tLine 39: 8136 rows deleted out of 211299 (3.85%)\n",
      "\tLine 4: 1654 rows deleted out of 282947 (0.58%)\n",
      "\tLine 41: 25810 rows deleted out of 234265 (11.02%)\n",
      "\tLine 42: 10005 rows deleted out of 124988 (8.00%)\n",
      "\tLine 43: 29489 rows deleted out of 205633 (14.34%)\n",
      "\tLine 44: 4044 rows deleted out of 186908 (2.16%)\n",
      "\tLine 45: 1191 rows deleted out of 224191 (0.53%)\n",
      "\tLine 46: 33120 rows deleted out of 374030 (8.85%)\n",
      "\tLine 47: 58642 rows deleted out of 201958 (29.04%)\n",
      "\tLine 48: 77304 rows deleted out of 343800 (22.49%)\n",
      "\tLine 49: 8151 rows deleted out of 326486 (2.50%)\n",
      "\tLine 5: 2715 rows deleted out of 405897 (0.67%)\n",
      "\tLine 50: 0 rows deleted out of 179314 (0.00%)\n",
      "\tLine 51: 16545 rows deleted out of 500110 (3.31%)\n",
      "\tLine 53: 689 rows deleted out of 367269 (0.19%)\n",
      "\tLine 54: 1682 rows deleted out of 276552 (0.61%)\n",
      "\tLine 55: 177269 rows deleted out of 295709 (59.95%)\n",
      "\tLine 56: 2236 rows deleted out of 238414 (0.94%)\n",
      "\tLine 57: 2990 rows deleted out of 107511 (2.78%)\n",
      "\tLine 58: 0 rows deleted out of 215717 (0.00%)\n",
      "\tLine 59: 182414 rows deleted out of 296514 (61.52%)\n",
      "\tLine 6: 31746 rows deleted out of 332930 (9.54%)\n",
      "\tLine 60: 7388 rows deleted out of 278309 (2.65%)\n",
      "\tLine 61: 60794 rows deleted out of 174369 (34.87%)\n",
      "\tLine 62: 6563 rows deleted out of 120972 (5.43%)\n",
      "\tLine 63: 706 rows deleted out of 231204 (0.31%)\n",
      "\tLine 64: 141228 rows deleted out of 259764 (54.37%)\n",
      "\tLine 65: 130539 rows deleted out of 423811 (30.80%)\n",
      "\tLine 66: 87465 rows deleted out of 266702 (32.80%)\n",
      "\tLine 69: 242 rows deleted out of 33083 (0.73%)\n",
      "\tLine 7: 45760 rows deleted out of 529144 (8.65%)\n",
      "\tLine 70: 27456 rows deleted out of 114793 (23.92%)\n",
      "\tLine 71: 1946 rows deleted out of 435665 (0.45%)\n",
      "\tLine 72: 311 rows deleted out of 42247 (0.74%)\n",
      "\tLine 74: 25615 rows deleted out of 211740 (12.10%)\n",
      "\tLine 75: 21 rows deleted out of 112767 (0.02%)\n",
      "\tLine 76: 13864 rows deleted out of 63121 (21.96%)\n",
      "\tLine 77: 0 rows deleted out of 19044 (0.00%)\n",
      "\tLine 78: 50653 rows deleted out of 107803 (46.99%)\n",
      "\tLine 79: 1948 rows deleted out of 183275 (1.06%)\n",
      "\tLine 8: 18272 rows deleted out of 386756 (4.72%)\n",
      "\tLine 80: 19903 rows deleted out of 390862 (5.09%)\n",
      "\tLine 81: 248386 rows deleted out of 504996 (49.19%)\n",
      "\tLine 82: 12882 rows deleted out of 515924 (2.50%)\n",
      "\tLine 83: 59460 rows deleted out of 292515 (20.33%)\n",
      "\tLine 86: 25904 rows deleted out of 250698 (10.33%)\n",
      "\tLine 87: 16449 rows deleted out of 308770 (5.33%)\n",
      "\tLine 88: 2854 rows deleted out of 273299 (1.04%)\n",
      "\tLine 89: 31427 rows deleted out of 233720 (13.45%)\n",
      "\tLine 9: 0 rows deleted out of 131274 (0.00%)\n",
      "\tLine 92: 130082 rows deleted out of 486408 (26.74%)\n",
      "\tLine 93: 180014 rows deleted out of 402974 (44.67%)\n",
      "\tLine 95: 293305 rows deleted out of 531447 (55.19%)\n",
      "\tLine 97: 6376 rows deleted out of 276705 (2.30%)\n",
      "\tLine 98: 0 rows deleted out of 98755 (0.00%)\n",
      "\tTotal: 3184454 rows deleted out of 19421883 (16.40%)\n"
     ]
    }
   ],
   "source": [
    "drop_positions_with_unknown_stop_or_direction()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Add direction to CSV\n",
    "\n",
    "Adds direction to `vehiclePositionsClean.csv` file created in previous section\n",
    "**Reads from**: CSV file containing filtered vehicle positions in `data` folder (`data/processed/assignment1/vehiclePositionsClean.csv`)\n",
    "**Writes to**: CSV file containing filtered vehicle positions with direction in `data` folder (`data/processed/assignment1/vehiclePositionsCleanDirected.csv`)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "outputs": [],
   "source": [
    "def get_direction_from_line_stop_and_destination(line: Tuple[List[List[str]], List[List[str]]], stop_id: str,\n",
    "                                                 destination_id: str) -> int:\n",
    "    # Simple case 1 -> destination_id is in one direction but not in the other:\n",
    "    stops = ({stop[3] for stop in line[0]}, {stop[3] for stop in line[1]})\n",
    "    if destination_id in stops[0] and destination_id not in stops[1]:\n",
    "        return 0\n",
    "    if destination_id not in stops[0] and destination_id in stops[1]:\n",
    "        return 1\n",
    "\n",
    "    # Simple case 2 -> destination_id is the last stop of a direction:\n",
    "    if destination_id == line[0][-1][3]:\n",
    "        return 0\n",
    "    if destination_id == line[1][-1][3]:\n",
    "        return 1\n",
    "\n",
    "    # Simple case 3 -> stop_id is in one direction but not in the other:\n",
    "    if stop_id in stops[0] and stop_id not in stops[1]:\n",
    "        return 0\n",
    "    if stop_id not in stops[0] and stop_id in stops[1]:\n",
    "        return 1\n",
    "\n",
    "    # Complex case 1 -> if stop_id != destination_id, return the direction in which the stop with\n",
    "    # id destination_id is after the stop with id stop_id\n",
    "    if stop_id != destination_id:\n",
    "        index_of_destination_0 = next(int(stop[8]) for stop in line[0] if stop[3] == destination_id)\n",
    "        index_of_stop_0 = next(int(stop[8]) for stop in line[0] if stop[3] == stop_id)\n",
    "        return 0 if index_of_stop_0 < index_of_destination_0 else 1\n",
    "    # Complex case 2 -> if stop_id == destination_id, return the direction in which the stop with\n",
    "    # id destination_id is further down the direction\n",
    "    else:\n",
    "        index_of_destination_0 = next(int(stop[8]) for stop in line[0] if stop[3] == destination_id)\n",
    "        index_of_destination_1 = next(int(stop[8]) for stop in line[1] if stop[3] == destination_id)\n",
    "        return 0 if index_of_destination_0 > index_of_destination_1 else 1"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "outputs": [],
   "source": [
    "def add_direction_to_csv():\n",
    "    positions = read_csv_stream('../data/processed/assignment1/vehiclePositionsClean.csv', skip_first=False)\n",
    "    directed_positions, output_file = get_csv_writer('../data/processed/assignment1/vehiclePositionsCleanDirected.csv')\n",
    "    directed_positions.writerow([*next(positions), 'Direction'])\n",
    "    grouped_lines = group_line_stops(read_csv_stream('../data/processed/assignment1/line_stops.csv'))\n",
    "    memory = {}\n",
    "    for position in tqdm(positions):\n",
    "        line_id = position[1]\n",
    "        stop_id = position[4]\n",
    "        destination_id = position[2]\n",
    "        tuple_id = f'{line_id}-{stop_id}-{destination_id}'\n",
    "        if tuple_id not in memory:\n",
    "            memory[tuple_id] = get_direction_from_line_stop_and_destination(grouped_lines[line_id], stop_id,\n",
    "                                                                            destination_id)\n",
    "        directed_positions.writerow([*position, memory[tuple_id]])\n",
    "    output_file.close()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "outputs": [
    {
     "data": {
      "text/plain": "0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "faed921878bd4e2781e985a844ee1c72"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "add_direction_to_csv()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Split CSV into lines\n",
    "\n",
    "Splits `vehiclePositionsCleanDirected.csv` file created in previous section into separate CSV (one per line)\n",
    "**Reads from**: CSV file containing filtered vehicle positions with direction in `data` folder (`data/processed/assignment1/vehiclePositionsCleanDirected.csv`)\n",
    "**Writes to**: CSV file per line containing filtered vehicle positions with direction in `data/processed/assignment1/vehiclePositionsPerLine` folder (`data/processed/assignment1/vehiclePositionsPerLine/vehiclePositions*.csv`)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "outputs": [],
   "source": [
    "def split_csv_by_lines():\n",
    "    files = {}\n",
    "    positions = read_csv_stream('../data/processed/assignment1/vehiclePositionsCleanDirected.csv', skip_first=False)\n",
    "    output_dir = '../data/processed/assignment1/vehiclePositionsPerLine'\n",
    "    if not os.path.exists(output_dir):\n",
    "        os.mkdir(output_dir)\n",
    "    header = next(positions)\n",
    "    for line in tqdm(positions):\n",
    "        line_id = line[1]\n",
    "        if line_id not in files:\n",
    "            files[line_id] = get_csv_writer(\n",
    "                f'{output_dir}/vehiclePositions{line_id}.csv')\n",
    "            files[line_id][0].writerow(header)\n",
    "        files[line_id][0].writerow(line)\n",
    "    for _, file in files.values():\n",
    "        file.close()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "outputs": [
    {
     "data": {
      "text/plain": "0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "438e84fdea244a59b095e808bfd972c8"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "split_csv_by_lines()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Vehicle Matching\n",
    "\n",
    "Tries to link several vehicle positions belonging to same physical vehicle\n",
    "**Reads from**: CSV file per line containing filtered vehicle positions with direction in `data/processed/assignment1/vehiclePositionsPerLine` folder (`data/processed/assignment1/vehiclePositionsPerLine/vehiclePositions*.csv`)\n",
    "**Writes to**: CSV file per line containing vehicle positions with `bus_id` in `data/processed/assignment1/csv_lines_linked` folder (`data/processed/assignment1/csv_lines_linked/vehiclePositions*.csv`)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "outputs": [],
   "source": [
    "def split_positions_by_direction(positions: Iterable[List[str]]) -> Tuple[List[List[str]], List[List[str]]]:\n",
    "    line = ([], [])\n",
    "    for position in positions:\n",
    "        line[int(position[-1])].append(position)\n",
    "    return line"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "outputs": [],
   "source": [
    "def get_index_of_stop_in_line(line, direction, stop_id):\n",
    "    return get_index_of_stop_in_line_direction(line[direction], stop_id)\n",
    "\n",
    "\n",
    "def get_index_of_stop_in_line_direction(line, stop_id):\n",
    "    return next((int(stop[-1]) for stop in line if stop[3] == stop_id), -1)\n",
    "\n",
    "\n",
    "class Match(Enum):\n",
    "    WRONG = 1\n",
    "    OK = 2\n",
    "    TOO_FAR = 3"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "outputs": [],
   "source": [
    "def group_positions_by_timestamp(positions: Iterable[List[str]]) -> List[Tuple[int, List[List[str]]]]:\n",
    "    grouped_positions = []\n",
    "    old_timestamp = -1\n",
    "    current_timestamp_positions = []\n",
    "    for position in positions:\n",
    "        current_timestamp = int(position[0])\n",
    "        if current_timestamp != old_timestamp:\n",
    "            assert current_timestamp > old_timestamp\n",
    "            grouped_positions.append((old_timestamp, current_timestamp_positions))\n",
    "            old_timestamp = current_timestamp\n",
    "            current_timestamp_positions = []\n",
    "        current_timestamp_positions.append(position)\n",
    "    grouped_positions.append((old_timestamp, current_timestamp_positions))\n",
    "    return grouped_positions[1:]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "outputs": [],
   "source": [
    "def possible_match(first_position: List[str], second_position: List[str],\n",
    "                   line: List[List[str]]) -> Match:\n",
    "    first_stop_id = first_position[4]\n",
    "    second_stop_id = second_position[4]\n",
    "    # Both positions are in the same stop -> Compare using distance from that stop\n",
    "    if first_stop_id == second_stop_id:\n",
    "        first_distance = int(first_position[3])\n",
    "        second_distance = int(second_position[3])\n",
    "        return Match.OK if first_distance <= second_distance else Match.WRONG\n",
    "    # Positions are in different stops -> Compare using order of stops in direction\n",
    "    else:\n",
    "        # Assert both positions have the same direction\n",
    "        first_stop_index = get_index_of_stop_in_line_direction(line, first_stop_id)\n",
    "        second_stop_index = get_index_of_stop_in_line_direction(line, second_stop_id)\n",
    "        if second_stop_index - first_stop_index > 3:\n",
    "            return Match.TOO_FAR\n",
    "        return Match.OK if first_stop_index < second_stop_index else Match.WRONG"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "outputs": [],
   "source": [
    "def find_bus_matched_of_line_direction(positions: Iterable[List[str]], line: List[List[str]], line_id: str,\n",
    "                                       direction: int, writer):\n",
    "    grouped_positions = group_positions_by_timestamp(positions)\n",
    "    previous_positions = []\n",
    "    bus_id = (f'{line_id}-{direction}-{i:06d}' for i in count())\n",
    "    sorting_key = lambda vehicle_position: get_index_of_stop_in_line_direction(line, vehicle_position[-2])\n",
    "\n",
    "    for timestamp, current_positions in grouped_positions:\n",
    "        sorted_positions = sorted(current_positions, key=sorting_key)\n",
    "        while len(sorted_positions) > 0 and get_index_of_stop_in_line_direction(line, sorted_positions[0][-2]) == -1:\n",
    "            sorted_positions.pop(0)\n",
    "        current_previous_position_index = 0\n",
    "        current_position_index = 0\n",
    "        while current_position_index < len(sorted_positions) and current_previous_position_index < len(\n",
    "                previous_positions):\n",
    "            previous_position = previous_positions[current_previous_position_index]\n",
    "            current_position = sorted_positions[current_position_index]\n",
    "            result = possible_match(previous_position, current_position, line)\n",
    "            if result == Match.OK:\n",
    "                current_position.append(previous_position[-1])\n",
    "                current_previous_position_index += 1\n",
    "                current_position_index += 1\n",
    "            elif result == Match.WRONG:\n",
    "                current_position.append(next(bus_id))\n",
    "                current_position_index += 1\n",
    "            elif result == Match.TOO_FAR:\n",
    "                current_previous_position_index += 1\n",
    "        for position in sorted_positions:\n",
    "            if len(position) == 6:\n",
    "                position.append(next(bus_id))\n",
    "            writer.writerow(position)\n",
    "        previous_positions = sorted_positions"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "outputs": [],
   "source": [
    "def find_bus_matches_of_line(file_path: str, output_path: str, line_id: str,\n",
    "                             line: Tuple[List[List[str]], List[List[str]]]) -> None:\n",
    "    positions = read_csv_stream(file_path, skip_first=False)\n",
    "    with write_csv(output_path) as linked_positions:\n",
    "        linked_positions.writerow([*next(positions), 'BusId'])\n",
    "        direction1, direction2 = split_positions_by_direction(positions)\n",
    "        find_bus_matched_of_line_direction(direction1, line[0], line_id, 0, linked_positions)\n",
    "        find_bus_matched_of_line_direction(direction2, line[1], line_id, 1, linked_positions)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "outputs": [],
   "source": [
    "def find_bus_matches_of_lines():\n",
    "    path = '../data/processed/assignment1/vehiclePositionsPerLine'\n",
    "    output_path = '../data/processed/assignment1/csv_lines_linked'\n",
    "    if not os.path.exists(output_path):\n",
    "        os.mkdir(output_path)\n",
    "    lines = group_line_stops(read_csv_stream('../data/processed/assignment1/line_stops.csv'))\n",
    "    for file in tqdm(os.listdir(path)):\n",
    "        line_id = file[16:-4]\n",
    "        line = lines[line_id]\n",
    "        find_bus_matches_of_line(f'{path}/{file}', f'{output_path}/{file}', line_id, line)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "outputs": [
    {
     "data": {
      "text/plain": "  0%|          | 0/74 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "39561da5ff734247a896752555b99406"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "find_bus_matches_of_lines()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Calculate average time between stops"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "outputs": [],
   "source": [
    "def group_positions_by_vehicle(positions: List[List[str]]) -> Dict[str, List[List[List[str]]]]:\n",
    "    grouped_positions = {}\n",
    "    for position in positions:\n",
    "        bus_id = position[-1]\n",
    "        if bus_id not in grouped_positions:\n",
    "            grouped_positions[bus_id] = []\n",
    "        grouped_positions[bus_id].append(position)\n",
    "    return grouped_positions"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "outputs": [],
   "source": [
    "def get_hour_from_timestamp(timestamp: int) -> int:\n",
    "    return datetime.datetime.fromtimestamp(timestamp // 1000).hour"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "outputs": [],
   "source": [
    "def get_vehicle_times_between_stops(vehicle_positions: List[List[str]],\n",
    "                                    line: Tuple[List[List[str]], List[List[str]]]) -> List:\n",
    "    times = []\n",
    "    previous_timestamp = int(vehicle_positions[0][0])\n",
    "    previous_stop = vehicle_positions[0][4]\n",
    "    for position in vehicle_positions:\n",
    "        current_timestamp = int(position[0])\n",
    "        current_stop = position[4]\n",
    "        if current_stop != previous_stop:\n",
    "            time_difference = (current_timestamp - previous_timestamp) // 1000\n",
    "            first_hour = get_hour_from_timestamp(previous_timestamp)\n",
    "            last_hour = get_hour_from_timestamp(current_timestamp)\n",
    "            times.append([first_hour, previous_stop, current_stop, time_difference])\n",
    "            if first_hour != last_hour:\n",
    "                times.append([last_hour, previous_stop, current_stop, time_difference])\n",
    "            previous_stop = current_stop\n",
    "            previous_timestamp = current_timestamp\n",
    "    return times"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "outputs": [],
   "source": [
    "def calculate_average_time_between_stops_of_line(positions: List[List[str]], line_id: str,\n",
    "                                                 line: Tuple[List[List[str]], List[List[str]]], output):\n",
    "    grouped_positions = group_positions_by_vehicle(positions)\n",
    "    times = []\n",
    "    for vehicle_id, vehicle_positions in grouped_positions.items():\n",
    "        times += get_vehicle_times_between_stops(vehicle_positions, line)\n",
    "    for direction in [0, 1]:\n",
    "        for fromStop, toStop in zip(line[direction][:-1], line[direction][1:]):\n",
    "            time_sum = [0 for _ in range(24)]\n",
    "            time_sum_filtered = [0 for _ in range(24)]\n",
    "            time_count = [0 for _ in range(24)]\n",
    "            time_count_filtered = [0 for _ in range(24)]\n",
    "            for time in times:\n",
    "                if time[1] == fromStop[3] and time[2] == toStop[3]:\n",
    "                    time_sum[time[0]] += time[3]\n",
    "                    time_count[time[0]] += 1\n",
    "                    if time[3] < 6000:  # Times larger than 10 minutes are likely anomalies that shouldn't be counted\n",
    "                        time_sum_filtered[time[0]] += time[3]\n",
    "                        time_count_filtered[time[0]] += 1\n",
    "            output[0].writerow(\n",
    "                [line_id, fromStop[3], toStop[3],\n",
    "                 *[f'{total / amount:.2f}' if amount > 0 else 0 for total, amount in zip(time_sum, time_count)]])\n",
    "            output[1].writerow([line_id, fromStop[3], toStop[3], *time_count])\n",
    "            output[2].writerow(\n",
    "                [line_id, fromStop[3], toStop[3], *[f'{total / amount:.2f}' if amount > 0 else 0 for total, amount in\n",
    "                                                    zip(time_sum_filtered, time_count_filtered)]])\n",
    "            output[3].writerow([line_id, fromStop[3], toStop[3], *time_count_filtered])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "outputs": [],
   "source": [
    "def calculate_average_time_between_stops():\n",
    "    source_path = '../data/processed/assignment1/csv_lines_linked'\n",
    "    output_path = '../data/processed/assignment1/average_time_between_stops.csv'\n",
    "    output_path_filtered = '../data/processed/assignment1/average_time_between_stops_filtered.csv'\n",
    "    output_path_count = '../data/processed/assignment1/average_time_between_stops_count.csv'\n",
    "    output_path_filtered_count = '../data/processed/assignment1/average_time_between_stops_filtered_count.csv'\n",
    "    lines = group_line_stops(read_csv_stream('../data/processed/assignment1/line_stops.csv'))\n",
    "    with write_csv(output_path) as output, write_csv(output_path_filtered) as output_filtered, write_csv(\n",
    "            output_path_count) as output_count, write_csv(output_path_filtered_count) as output_filtered_count:\n",
    "        header = ['LineId', 'FromStop', 'ToStop', *[f'{i}' for i in range(24)], 'Day']\n",
    "        output.writerow(header)\n",
    "        output_filtered.writerow(header)\n",
    "        output_count.writerow(header)\n",
    "        output_filtered_count.writerow(header)\n",
    "        for file in tqdm(os.listdir(source_path)):\n",
    "            line_id = file[16:-4]\n",
    "            line = lines[line_id]\n",
    "            positions = read_csv_list(f'{source_path}/{file}')[1:]\n",
    "            calculate_average_time_between_stops_of_line(positions, line_id, line,\n",
    "                                                         (output, output_count, output_filtered, output_filtered_count))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "outputs": [
    {
     "data": {
      "text/plain": "  0%|          | 0/74 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "6864e6acc839472581cff702b0c8f1d2"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "calculate_average_time_between_stops()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "outputs": [],
   "source": [
    "def calculate_daily_average_time_between_stops():\n",
    "    source_path = '../data/processed/assignment1/csv_lines_linked'\n",
    "    output_path = '../data/processed/assignment1/daily_average_time_between_stops_filtered'\n",
    "    lines = group_line_stops(read_csv_stream('../data/processed/assignment1/line_stops.csv'))\n",
    "    header = ['LineId', 'FromStop', 'ToStop', *[f'{i}' for i in range(24)]]\n",
    "\n",
    "    class Dummy:\n",
    "        def writerow(self, *args):\n",
    "            pass\n",
    "\n",
    "    dummy = Dummy()\n",
    "    day_files = {}\n",
    "    for file in tqdm(os.listdir(source_path)):\n",
    "        line_id = file[16:-4]\n",
    "        line = lines[line_id]\n",
    "        positions = read_csv_list(f'{source_path}/{file}')[1:]\n",
    "        day_positions = {}\n",
    "        for position in positions:\n",
    "            day = datetime.datetime.fromtimestamp(int(position[0]) / 1000).date().strftime('%Y-%m-%d')\n",
    "            if day not in day_positions:\n",
    "                day_positions[day] = []\n",
    "            day_positions[day].append(position)\n",
    "        for day in day_positions:\n",
    "            if day not in day_files:\n",
    "                day_files[day] = get_csv_writer(f'{output_path}/{day}.csv')\n",
    "                day_files[day][0].writerow(header)\n",
    "            calculate_average_time_between_stops_of_line(day_positions[day], line_id, line,\n",
    "                                                         (dummy, dummy, day_files[day][0], dummy))\n",
    "    for writer, file in day_files.values():\n",
    "        file.close()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "outputs": [
    {
     "data": {
      "text/plain": "  0%|          | 0/74 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "a961a5135fa54b219b30d9417b67b9e2"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "calculate_daily_average_time_between_stops()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Import Libraries\n",
    "\n",
    "**Shapefile:** This is the pyshp library that is used to manipulate shapefiles.\n",
    "**Math:** This library is used for basic math functions to calculate distance between points"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "outputs": [],
   "source": [
    "line_stops = pd.read_csv('../data/processed/assignment1/line_stops.csv')\n",
    "sf_actu_lines = shapefile.Reader('../data/raw/shapefiles/ACTU_LINES.shp')\n",
    "# here we initialize shape_records, which includes a combination of the shapes and records from the shapefile. This combination will allow us to pull the lambert coordinates from the shapes as while also accessing the record information like line_id.\n",
    "shape_records = sf_actu_lines.shapeRecords()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Shapefile Distance Calculation Function\n",
    "\n",
    "Now that we have our libraries loaded and files imported, we will create a function that can calculate the distance between two points on a polyline. The start_point and end_point are indexes to tell us where we should start and stop calculating distance in the polyline. the line_segment is one of the shape elements that will be pulled from the shapefile. This calculation will be called later in an iterative for loop for each shape element withing shape_records.shape.\n",
    "\n",
    "We will calculate the distance between each point in the shapefile using Pythagoreas' theorem, since the units in both line_stops and the shapefile are already provided in Belgium Lambert 1972 format, which projects the points onto a flat surface."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "outputs": [],
   "source": [
    "def calculate_distance_between_polyline_points(start_point: int, stop_point: int,\n",
    "                                               line_segment: shapefile.Shape) -> float:\n",
    "    # initializing our total distance to 0\n",
    "    total_distance = 0\n",
    "    # we'll need to calculate the distance between each consecutive pair of coordinates, and will iterate\n",
    "    # from the start_point to the end_point. Each newly caluclated distance between points will be added\n",
    "    # to the sum total_distance and then returned.\n",
    "    for index in range(start_point, stop_point - 1):\n",
    "        current = index\n",
    "        next = index + 1\n",
    "        total_distance += sqrt(pow((line_segment.points[current][0] - line_segment.points[next][0]), 2) + pow(\n",
    "            (line_segment.points[current][1] - line_segment.points[next][1]), 2))\n",
    "    return total_distance\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Calculate Distance Between Stops\n",
    "\n",
    "Time to get to work! Here we several nested for loops that are used to compare match up the line in the shapefile to the line in the line_stops. For each matching line, we will cycle through to project the stop location ONTO the polyline. This is required because a bus stop can be imagined to be on a sidewalk, while the polyline is moving along the road.\n",
    "\n",
    "Once we have matched up our bus stop with the nearest polyline point, we move to the next stop and do the same. Having 2 stop locations projected, we can call the previously defined calculate_distance_between_polyline_points function to find the distance between these 2 stops.\n",
    "\n",
    "The first iteration of the loop will result in a dummy value, as it does not have a real stop to pair with. All of these dummy values are dropped once the dictionary that stores all values is transformed into a dataframe.\n",
    "\n",
    "The data frame will be accessed latter with the unique combination of [LineID + fromStopID + toStopID]. This combination will be different depending on which direction a vehicle is moving, as the stop id's are not the same on each side of a street.\n",
    "\n",
    "We will also hold onto the index value for the polyline location in case we need it later on for future predictions.\n",
    "\n",
    "**integration**: This is how things were integerated\n",
    "parameters: Here we dropped all stops before 4am because..."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "outputs": [],
   "source": [
    "# initialize a dictionary that will be used to make a dataframe and csv file with the following format:\n",
    "# |    LineId    |   FromStop  |   ToStop  |   distance    |    fromIndex   |    toIndex   |\n",
    "stop_distance = {'LineId': [], 'LineIdFormatted': [], 'LineId_GeoMerge': [], 'Type': [], 'Direction': [],\n",
    "                 'FromStop': [], 'ToStop': [], 'distance': [], 'fromIndex': [], 'toIndex': [],\n",
    "                 'FromStop_lat': [], 'FromStop_lon': [], 'ToStop_lat': [], 'ToStop_lon': []}\n",
    "\n",
    "# Initializing variables that will be used in loops\n",
    "last_pointID = 0\n",
    "last_stop_id = 0\n",
    "last_stop_lat = 0\n",
    "last_stop_lon = 0\n",
    "adjusted_stop_lat_GPS = 0\n",
    "adjusted_stop_lon_GPS = 0\n",
    "\n",
    "# look through each shape/record combo in the shape_records file. Each element of shape_records represents a single line (metro, bus or tram)\n",
    "for shape_record in shape_records:\n",
    "    record = shape_record.record\n",
    "    shape = shape_record.shape\n",
    "    # look through each of the stops that exist in the line_stops csv. Here we are going to only cycle through a subset of the line_stops where there is a match on LineId and the direction to reduce computation time.\n",
    "    for index, stop in line_stops[\n",
    "        (line_stops['lineId'] == record['LIGNE']) & (line_stops['direction'] == record['VARIANTE'])].sort_values(\n",
    "        by=['order']).iterrows():\n",
    "        # Initializing variables that will be used in loops\n",
    "        min_distance = 50\n",
    "        adjusted_stop_lat = 50\n",
    "        adjusted_stop_lon = 50\n",
    "        current_pointID = 0\n",
    "        current_stop_id = stop['stop_id_int']\n",
    "        stop_lat = stop['lambert_x']\n",
    "        stop_lon = stop['lambert_y']\n",
    "        #After choosing a single stop from the line_stops file, we will compare that stops lambert GPS position to each coordinate that makes up the polyline in the current shape_records shape. We are finding the closest location in the shape file to our bus stop location. This can be done using euclidean distance calculation because the coordinates are in lambert notation. Whichever location on the polyline is the closest becomes the projected location of the bus stop using the if statement.\n",
    "        for pointID in range(len(shape.points)):\n",
    "            point_lat = shape.points[pointID][0]\n",
    "            point_lon = shape.points[pointID][1]\n",
    "            distance = sqrt(pow((point_lat - stop_lat), 2) + pow((point_lon - stop_lon), 2))\n",
    "            # if statement to compare distances and updated if shorter. It also saves the polyline info for future use in predicting\n",
    "            # which method of transport is being used.\n",
    "            if distance < min_distance:\n",
    "                min_distance = distance\n",
    "                adjusted_stop_lat = point_lat\n",
    "                adjusted_stop_lon = point_lon\n",
    "                current_pointID = pointID\n",
    "                adjusted_stop_lat_GPS = stop['lat']\n",
    "                adjusted_stop_lon_GPS = stop['long']\n",
    "        # now we call a previously defined function to calculate the total distance between the location projected during the previous for loop iteration and the current loop iteration. We are able to do this because the stops have been sorted by descending order from first to last. The first row in the array will always be a dummy row and needs to be dropped afterwards.\n",
    "        distance_between_stops = calculate_distance_between_polyline_points(last_pointID, current_pointID, shape)\n",
    "        # we update our dictionary with all the values needed for distance between stops.\n",
    "        # we will also strip out the leading zeros and the trailing text characters indicating (b,t,m for bus, tram and metro)\n",
    "        stripped_line_id = stop['lineId'][:-1].strip(\"0\")\n",
    "        stop_distance['LineId'].append(stripped_line_id)\n",
    "        stop_distance['LineIdFormatted'].append(f\"line{stripped_line_id}\")\n",
    "        stop_distance['LineId_GeoMerge'].append(f\"{stop['lineId']}-{stop['direction']}\")\n",
    "        stop_distance['Type'].append(str(stop['lineId'][-1]))\n",
    "        stop_distance['Direction'].append(stop['direction'])\n",
    "        stop_distance['FromStop'].append(last_stop_id)\n",
    "        stop_distance['ToStop'].append(current_stop_id)\n",
    "        stop_distance['distance'].append(distance_between_stops)\n",
    "        stop_distance['fromIndex'].append(last_pointID)\n",
    "        stop_distance['toIndex'].append(current_pointID)\n",
    "        stop_distance['FromStop_lat'].append(last_stop_lat)\n",
    "        stop_distance['FromStop_lon'].append(last_stop_lon)\n",
    "        stop_distance['ToStop_lat'].append(adjusted_stop_lat_GPS)\n",
    "        stop_distance['ToStop_lon'].append(adjusted_stop_lon_GPS)\n",
    "        # after calculating the distance, we update the last stop id, point, and lat/lon to the currently being used before iterating through to the next bus stop. The current point becomes the last point for the next calculation.\n",
    "        last_stop_id = current_stop_id\n",
    "        last_pointID = current_pointID\n",
    "        last_stop_lat = adjusted_stop_lat_GPS\n",
    "        last_stop_lon = adjusted_stop_lon_GPS\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "outputs": [],
   "source": [
    "\n",
    "#stop_distance is a dictionary we can use to merge with GeoJSON\n",
    "\n",
    "# Opening JSON file\n",
    "json_shapes_path = '../data/raw/shapes_lat_long.json'\n",
    "with open(json_shapes_path, 'r') as file:\n",
    "    line_shapes_geojson = json.load(file)\n",
    "\n",
    "df_line_shapes_geojson = pd.json_normalize(line_shapes_geojson)\n",
    "df_stop_distance = pd.DataFrame.from_dict(stop_distance)\n",
    "\n",
    "sorted_geo_json = []\n",
    "for line_id, polyline in df_line_shapes_geojson.iteritems():\n",
    "    for stop_index, value in df_stop_distance.iterrows():\n",
    "        if line_id == value['LineId_GeoMerge']:\n",
    "            sorted_geo_json.append(polyline.values.__array__())  #df_line_shapes_geojson[line_id]\n",
    "\n",
    "#\n",
    "# add_geojson_to_distance_dictionary(stop_distance, line_shapes)\n",
    "# polyline_list = []\n",
    "# WKT_list = []\n",
    "#\n",
    "#\n",
    "# for stop_segment in df_stop_distance:\n",
    "#\n",
    "# for pointID in range(last_pointID, current_pointID+1):\n",
    "#     point_lat = shape.points[pointID][0]\n",
    "#     point_lon = shape.points[pointID][1]\n",
    "#     polyline_list.append([point_lat, point_lon])\n",
    "#     WKT_list.append(f\"{point_lat} {point_lon}\")\n",
    "#\n",
    "# geo_json_test[\"geojson\"].append(f'{{\"type\": \"FeatureCollection\", \"features\": [{{\"type\": \"Feature\", properties: {{}}, \"geometry\": {{\"type\": \"LineString\", \"coordinates\": {polyline_list}}}}}]}}')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     LineId LineIdFormatted LineId_GeoMerge Type  Direction  FromStop  ToStop  \\\n",
      "0         1           line1          001m-1    m          1         0    8733   \n",
      "1         1           line1          001m-1    m          1      8733    8742   \n",
      "2         1           line1          001m-1    m          1      8742    8292   \n",
      "3         1           line1          001m-1    m          1      8292    8282   \n",
      "4         1           line1          001m-1    m          1      8282    8272   \n",
      "...     ...             ...             ...  ...        ...       ...     ...   \n",
      "4171    218         line218          218b-2    b          2      9025    2209   \n",
      "4172    218         line218          218b-2    b          2      2209    2835   \n",
      "4173    218         line218          218b-2    b          2      2835    1901   \n",
      "4174    218         line218          218b-2    b          2      1901    2221   \n",
      "4175    218         line218          218b-2    b          2      2221    3347   \n",
      "\n",
      "        distance  fromIndex  toIndex  FromStop_lat  FromStop_lon  ToStop_lat  \\\n",
      "0       0.000000          0        0      0.000000      0.000000   50.848999   \n",
      "1     436.974259          0       21     50.848999      4.320948   50.853386   \n",
      "2     938.450685         21       74     50.853386      4.322974   50.857125   \n",
      "3     400.370796         74      109     50.857125      4.333143   50.854705   \n",
      "4     525.003844        109      151     50.854705      4.340542   50.851900   \n",
      "...          ...        ...      ...           ...           ...         ...   \n",
      "4171  290.633506        241      261     50.861751      4.356097   50.858919   \n",
      "4172  218.832815        261      269     50.858919      4.354478   50.857103   \n",
      "4173  698.633391        269      321     50.857103      4.353201   50.854210   \n",
      "4174  585.084436        321      349     50.854210      4.361510   50.849859   \n",
      "4175  662.986066        349      391     50.849859      4.360204   50.846595   \n",
      "\n",
      "      ToStop_lon                                            geojson  \n",
      "0       4.320948  {'type': 'FeatureCollection', 'features': [{'t...  \n",
      "1       4.322974  {'type': 'FeatureCollection', 'features': [{'t...  \n",
      "2       4.333143  {'type': 'FeatureCollection', 'features': [{'t...  \n",
      "3       4.340542  {'type': 'FeatureCollection', 'features': [{'t...  \n",
      "4       4.348012  {'type': 'FeatureCollection', 'features': [{'t...  \n",
      "...          ...                                                ...  \n",
      "4171    4.354478  {'type': 'FeatureCollection', 'features': [{'t...  \n",
      "4172    4.353201  {'type': 'FeatureCollection', 'features': [{'t...  \n",
      "4173    4.361510  {'type': 'FeatureCollection', 'features': [{'t...  \n",
      "4174    4.360204  {'type': 'FeatureCollection', 'features': [{'t...  \n",
      "4175    4.357038  {'type': 'FeatureCollection', 'features': [{'t...  \n",
      "\n",
      "[4176 rows x 15 columns]\n"
     ]
    }
   ],
   "source": [
    "df_line_shapes_geojson_transformed = df_line_shapes_geojson.transpose()[0].apply(lambda x: {\"type\": \"FeatureCollection\",\n",
    "                                                                                            \"features\": [\n",
    "                                                                                                {\"type\": \"Feature\",\n",
    "                                                                                                 \"properties\": {},\n",
    "                                                                                                 \"geometry\": {\n",
    "                                                                                                     \"type\": \"LineString\",\n",
    "                                                                                                     \"coordinates\": x}\n",
    "                                                                                                 }]\n",
    "                                                                                            })\n",
    "\n",
    "df_stop_distance_merged = df_stop_distance.merge(df_line_shapes_geojson_transformed, left_on='LineId_GeoMerge',\n",
    "                                                 right_index=True).rename(columns={0: 'geojson'})\n",
    "print(df_stop_distance_merged)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "outputs": [],
   "source": [
    "# now we convert the dictionary to a Pandas DataFrame for easier manipulation\n",
    "df_stop_distance_merged.drop(df_stop_distance_merged[df_stop_distance_merged['toIndex'] == 0].index, inplace=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Export to CSV\n",
    "\n",
    "We can now export the dataframe to a csv file for use in other parts of the cleaning and predicitons."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "outputs": [],
   "source": [
    "# finally, we export the distance to a csv file named stop_distance.csv\n",
    "df_stop_distance_merged.to_csv(r'../data/processed/assignment1/stop_distance.csv', index=False, header=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Calculate Speed"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "outputs": [],
   "source": [
    "stop_distance_path = '../data/processed/assignment1/stop_distance.csv'\n",
    "stop_time_path = '../data/processed/assignment1/average_time_between_stops_filtered.csv'\n",
    "\n",
    "# initialize a dictionary that will be used to make a dataframe and csv file with the following format:\n",
    "# |  LineID      | FromStop      |   ToStop   |   0    |   1   | ... |  23   |\n",
    "stop_time = pd.read_csv(stop_time_path)\n",
    "\n",
    "# |    LineID    |   FromStop    |   ToStop   |   distance    |    fromIndex   |    toIndex   |\n",
    "stop_distance = pd.read_csv(stop_distance_path)\n",
    "stop_distance['FromStop'].astype('float_', copy=True, errors='raise')\n",
    "stop_distance['ToStop'].astype('float_', copy=True, errors='raise')\n",
    "\n",
    "\n",
    "def calculate_speed(time: pd.DataFrame, distance: pd.DataFrame) -> pd.DataFrame:\n",
    "    merged_time_distance = time.merge(distance, how='left', on=['LineId', 'FromStop', 'ToStop'])\n",
    "    for hour in range(0, 24):\n",
    "        merged_time_distance[f\"speed{hour}\"] = (merged_time_distance['distance'] / merged_time_distance[\n",
    "            f\"{hour}\"]) * 3.6\n",
    "    merged_time_distance.drop(columns=['distance', *[f'{i}' for i in range(24)]], inplace=True)\n",
    "    return merged_time_distance\n",
    "\n",
    "\n",
    "df_speed = calculate_speed(stop_time, stop_distance)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "outputs": [],
   "source": [
    "df_speed.to_csv(r'../data/processed/assignment1/vehicleSpeed.csv', index=False, header=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Reformat data for use in visualization"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "outputs": [],
   "source": [
    "# LineId,FromStop,ToStop,FromStop_lat,FromStop_lon,ToStop_lat,ToStop_lon,speed0,speed1,speed2\n",
    "\n",
    "new_header = ['LineId', 'FromStop', 'ToStop', 'Day', 'LineIdFormatted', 'LineId_GeoMerge', 'Type', 'Direction',\n",
    "              'fromIndex', 'toIndex', 'FromStop_lat', 'FromStop_lon', 'ToStop_lat', 'ToStop_lon', 'geojson', 'hour',\n",
    "              'speed']\n",
    "\n",
    "with write_csv('../data/processed/assignment1/vehicleSpeedReformatted.csv') as output:\n",
    "    output.writerow(new_header)\n",
    "    speeds = read_csv_stream('../data/processed/assignment1/vehicleSpeed.csv', skip_first=True)\n",
    "    for speed_line in speeds:\n",
    "        output.writerows([[*speed_line[:15], f'{hour:02d}:00', speed_line[15 + hour]] for hour in range(24)])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Merge Delays with Speed"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "outputs": [],
   "source": [
    "vehicle_speed = '../data/processed/assignment1/vehicleSpeedReformatted.csv'\n",
    "stop_delays = '../data/processed/assignment2/grouped_visual_data_ass2.csv'\n",
    "\n",
    "df_vehicle_speed = pd.read_csv(vehicle_speed)\n",
    "df_stop_delays = pd.read_csv(stop_delays)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   LineId  FromStop  ToStop  Day LineIdFormatted LineId_GeoMerge Type  \\\n",
      "0      37      2957    5810  NaN          line37          037b-1    b   \n",
      "1      37      2957    5810  NaN          line37          037b-1    b   \n",
      "2      37      2957    5810  NaN          line37          037b-1    b   \n",
      "3      37      2957    5810  NaN          line37          037b-1    b   \n",
      "4      37      2957    5810  NaN          line37          037b-1    b   \n",
      "\n",
      "   Direction  fromIndex  toIndex  FromStop_lat  FromStop_lon  ToStop_lat  \\\n",
      "0        1.0       49.0     57.0     50.821413      4.341859   50.818572   \n",
      "1        1.0       49.0     57.0     50.821413      4.341859   50.818572   \n",
      "2        1.0       49.0     57.0     50.821413      4.341859   50.818572   \n",
      "3        1.0       49.0     57.0     50.821413      4.341859   50.818572   \n",
      "4        1.0       49.0     57.0     50.821413      4.341859   50.818572   \n",
      "\n",
      "   ToStop_lon                                            geojson   hour  \\\n",
      "0    4.340952  {'type': 'FeatureCollection', 'features': [{'t...  00:00   \n",
      "1    4.340952  {'type': 'FeatureCollection', 'features': [{'t...  01:00   \n",
      "2    4.340952  {'type': 'FeatureCollection', 'features': [{'t...  02:00   \n",
      "3    4.340952  {'type': 'FeatureCollection', 'features': [{'t...  03:00   \n",
      "4    4.340952  {'type': 'FeatureCollection', 'features': [{'t...  04:00   \n",
      "\n",
      "       speed  \n",
      "0  14.936818  \n",
      "1        inf  \n",
      "2        inf  \n",
      "3        inf  \n",
      "4        inf  \n",
      "   Unnamed: 0 LineId Type  CurrentStop  Direction   Time  Day  Delay  \\\n",
      "0           0  line1    m         8011          2  05:00    0   -321   \n",
      "1           1  line1    m         8011          2  05:00    1   -411   \n",
      "2           2  line1    m         8011          2  06:00    0    -76   \n",
      "3           3  line1    m         8011          2  06:00    1   -237   \n",
      "4           4  line1    m         8011          2  07:00    0    -67   \n",
      "\n",
      "      stop_name   stop_lat  stop_lon  \n",
      "0  DE BROUCKERE  50.850095  4.352165  \n",
      "1  DE BROUCKERE  50.850095  4.352165  \n",
      "2  DE BROUCKERE  50.850095  4.352165  \n",
      "3  DE BROUCKERE  50.850095  4.352165  \n",
      "4  DE BROUCKERE  50.850095  4.352165  \n"
     ]
    }
   ],
   "source": [
    "print(df_vehicle_speed.head())\n",
    "print(df_stop_delays.head())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}