{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Data Cleaning and Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Raw JSON to CSV\n",
    "\n",
    "Converts raw JSON files containing the vehiclePositions from STIB to a single CSV file\n",
    "**Reads from**: raw JSON files in `data/raw` folder (`data/raw/vehiclePosition*.json`)\n",
    "**Writes to**: Single CSV file containing all the vehicle positions in `data` folder (`data/processed/vehiclePositions.csv`)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "outputs": [],
   "source": [
    "import csv\n",
    "import json"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "outputs": [],
   "source": [
    "def convert_json_into_csv(csv_file: csv.writer, json_path: str) -> None:\n",
    "    with open(json_path, 'r') as file:\n",
    "        data = json.load(file)['data']\n",
    "        for time in data:\n",
    "            timestamp = time['time']\n",
    "            for response in time['Responses']:\n",
    "                if response is None:\n",
    "                    continue\n",
    "                for line in response['lines']:\n",
    "                    line_id = line['lineId']\n",
    "                    for vehiclePosition in line['vehiclePositions']:\n",
    "                        csv_file.writerow([\n",
    "                            timestamp,\n",
    "                            line_id,\n",
    "                            vehiclePosition['directionId'],\n",
    "                            vehiclePosition['distanceFromPoint'],\n",
    "                            vehiclePosition['pointId'],\n",
    "                        ])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "outputs": [],
   "source": [
    "def convert_json_files_into_single_csv() -> None:\n",
    "    files = [\n",
    "        '../data/raw/vehicleTimestamp/vehiclePosition01.json',\n",
    "        '../data/raw/vehicleTimestamp/vehiclePosition02.json',\n",
    "        '../data/raw/vehicleTimestamp/vehiclePosition03.json',\n",
    "        '../data/raw/vehicleTimestamp/vehiclePosition04.json',\n",
    "        '../data/raw/vehicleTimestamp/vehiclePosition05.json',\n",
    "        '../data/raw/vehicleTimestamp/vehiclePosition06.json',\n",
    "        '../data/raw/vehicleTimestamp/vehiclePosition07.json',\n",
    "        '../data/raw/vehicleTimestamp/vehiclePosition08.json',\n",
    "        '../data/raw/vehicleTimestamp/vehiclePosition09.json',\n",
    "        '../data/raw/vehicleTimestamp/vehiclePosition10.json',\n",
    "        '../data/raw/vehicleTimestamp/vehiclePosition11.json',\n",
    "        '../data/raw/vehicleTimestamp/vehiclePosition12.json',\n",
    "        '../data/raw/vehicleTimestamp/vehiclePosition13.json'\n",
    "    ]\n",
    "    with write_csv('../data/processed/vehiclePositions.csv') as writer:\n",
    "        writer.writerow(['Timestamp', 'LineId', 'DirectionId', 'DistanceFromPoint', 'PointId'])\n",
    "        for path in tqdm(files):\n",
    "            convert_json_into_csv(writer, path)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Shapefile to routes\n",
    "\n",
    "Converts raw Stops Shapefiles from STIB to a single CSV file containing line routes\n",
    "**Reads from**:\n",
    " - Shapefiles in `data/raw/shapefiles` folder (`data/raw/shapefiles/ACTU_STOPS.*`)\n",
    " - `stops.txt` GTFS file in `data/raw/gtfs` folder\n",
    "\n",
    "**Writes to**: Single CSV file containing all the line routes in `data` folder (`data/line_stops.csv`)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "outputs": [],
   "source": [
    "from typing import List, Dict\n",
    "import shapefile"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "outputs": [],
   "source": [
    "def group_shape_stops_by_line(stops: List[shapefile._Record]) -> Dict[str, List[shapefile._Record]]:\n",
    "    lines = {}\n",
    "    for stop in stops:\n",
    "        line_id = f'{stop[\"Code_Ligne\"]}{stop[\"Variante\"]}'\n",
    "        if line_id not in lines:\n",
    "            lines[line_id] = []\n",
    "        lines[line_id].append(stop)\n",
    "    for stops in lines.values():\n",
    "        stops.sort(key=lambda stop: stop['succession'])\n",
    "    return lines"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "outputs": [],
   "source": [
    "def create_line_stops_csv():\n",
    "    stops = shapefile.Reader('../data/raw/shapefiles/ACTU_STOPS.shp')\n",
    "    grouped_stops = group_shape_stops_by_line(stops.records())\n",
    "    gtfs_stops_file = open('../data/raw/gtfs/stops.csv', 'r', encoding='utf8')\n",
    "    gtfs_stops = {stop['stop_id']: stop for stop in csv.DictReader(gtfs_stops_file)}\n",
    "    with open('../data/processed/line_stops.csv', 'w', newline='', encoding='utf8') as file:\n",
    "        writer = csv.writer(file)\n",
    "        writer.writerow(['lineId', 'direction', 'stop_id', 'stop_id_int', 'name', 'name_ascii', 'lat', 'long', 'order'])\n",
    "        for line, line_stops in sorted(grouped_stops.items()):\n",
    "            for stop in line_stops:\n",
    "                stop_lat = gtfs_stops[stop['stop_id']]['stop_lat'] if stop['stop_id'] in gtfs_stops else None\n",
    "                stop_lon = gtfs_stops[stop['stop_id']]['stop_lon'] if stop['stop_id'] in gtfs_stops else None\n",
    "                stop_id = int(stop['stop_id'].strip('qwertyuiopasdfghjklzxcvbnmQWERTYUIOPASDFGHJKLZXCVBNM'))\n",
    "                writer.writerow([stop['Code_Ligne'], stop['Variante'], stop['stop_id'], stop_id, stop['alpha_fr'],\n",
    "                                 stop['descr_fr'], stop_lat, stop_lon, stop['succession']])\n",
    "\n",
    "\n",
    "create_line_stops_csv()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Drop incomplete data from CSV\n",
    "\n",
    "Cleans `vehiclePositions.csv` file created in previous section\n",
    "**Reads from**: CSV file containing all the vehicle positions in `data` folder (`data/processed/vehiclePositions.csv`)\n",
    "**Writes to**: CSV file containing filtered vehicle positions in `data` folder (`data/processed/vehiclePositionsClean.csv`)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "outputs": [],
   "source": [
    "from scripts.helpers import *\n",
    "from functools import reduce\n",
    "from operator import add"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "outputs": [],
   "source": [
    "def drop_positions_with_unknown_stop_or_direction():\n",
    "    total_count = {}\n",
    "    deletion_count = {}\n",
    "    stops = {f'{int(stop[0][:-1])}-{stop[3]}' for stop in read_csv_stream('../data/processed/line_stops.csv')}\n",
    "    positions = read_csv_stream('../data/processed/vehiclePositions.csv', skip_first=False)\n",
    "    with write_csv('../data/processed/vehiclePositionsClean.csv') as writer:\n",
    "        writer.writerow(next(positions))\n",
    "        for position in tqdm(positions):\n",
    "            line_id = position[1]\n",
    "            if line_id not in total_count:\n",
    "                total_count[line_id] = 0\n",
    "            if line_id not in deletion_count:\n",
    "                deletion_count[line_id] = 0\n",
    "            direction_id = position[2]\n",
    "            stop_id = position[4]\n",
    "            total_count[line_id] += 1\n",
    "            if f'{line_id}-{direction_id}' not in stops or f'{line_id}-{stop_id}' not in stops:\n",
    "                deletion_count[line_id] += 1\n",
    "            else:\n",
    "                writer.writerow(position)\n",
    "    for line in sorted(total_count):\n",
    "        deleted = deletion_count[line]\n",
    "        total = total_count[line]\n",
    "        print(f'\\tLine {line}: {deleted} rows deleted out of {total} ({(deleted / total) * 100:.2f}%)')\n",
    "    total_rows = reduce(add, total_count.values())\n",
    "    total_deletions = reduce(add, deletion_count.values())\n",
    "    print(f'\\tTotal: {total_deletions} rows deleted out of {total_rows} ({(total_deletions / total_rows) * 100:.2f}%)')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Add direction to CSV\n",
    "\n",
    "Adds direction to `vehiclePositionsClean.csv` file created in previous section\n",
    "**Reads from**: CSV file containing filtered vehicle positions in `data` folder (`data/processed/vehiclePositionsClean.csv`)\n",
    "**Writes to**: CSV file containing filtered vehicle positions with direction in `data` folder (`data/processed/vehiclePositionsCleanDirected.csv`)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "outputs": [],
   "source": [
    "def get_direction_from_line_stop_and_destination(line: Tuple[List[List[str]], List[List[str]]], stop_id: str,\n",
    "                                                 destination_id: str) -> int:\n",
    "    # Simple case 1 -> destination_id is in one direction but not in the other:\n",
    "    stops = ({stop[3] for stop in line[0]}, {stop[3] for stop in line[1]})\n",
    "    if destination_id in stops[0] and destination_id not in stops[1]:\n",
    "        return 0\n",
    "    if destination_id not in stops[0] and destination_id in stops[1]:\n",
    "        return 1\n",
    "\n",
    "    # Simple case 2 -> destination_id is the last stop of a direction:\n",
    "    if destination_id == line[0][-1][3]:\n",
    "        return 0\n",
    "    if destination_id == line[1][-1][3]:\n",
    "        return 1\n",
    "\n",
    "    # Simple case 3 -> stop_id is in one direction but not in the other:\n",
    "    if stop_id in stops[0] and stop_id not in stops[1]:\n",
    "        return 0\n",
    "    if stop_id not in stops[0] and stop_id in stops[1]:\n",
    "        return 1\n",
    "\n",
    "    # Complex case 1 -> if stop_id != destination_id, return the direction in which the stop with\n",
    "    # id destination_id is after the stop with id stop_id\n",
    "    if stop_id != destination_id:\n",
    "        index_of_destination_0 = next(int(stop[8]) for stop in line[0] if stop[3] == destination_id)\n",
    "        index_of_stop_0 = next(int(stop[8]) for stop in line[0] if stop[3] == stop_id)\n",
    "        return 0 if index_of_stop_0 < index_of_destination_0 else 1\n",
    "    # Complex case 2 -> if stop_id == destination_id, return the direction in which the stop with\n",
    "    # id destination_id is further down the direction\n",
    "    else:\n",
    "        index_of_destination_0 = next(int(stop[8]) for stop in line[0] if stop[3] == destination_id)\n",
    "        index_of_destination_1 = next(int(stop[8]) for stop in line[1] if stop[3] == destination_id)\n",
    "        return 0 if index_of_destination_0 > index_of_destination_1 else 1"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "outputs": [],
   "source": [
    "def add_direction_to_csv():\n",
    "    positions = read_csv_stream('../data/processed/vehiclePositionsClean.csv', skip_first=False)\n",
    "    directed_positions, output_file = get_csv_writer('../data/processed/vehiclePositionsCleanDirected.csv')\n",
    "    directed_positions.writerow([*next(positions), 'Direction'])\n",
    "    grouped_lines = group_line_stops(read_csv_stream('../data/processed/line_stops.csv'))\n",
    "    memory = {}\n",
    "    for position in tqdm(positions):\n",
    "        line_id = position[1]\n",
    "        stop_id = position[4]\n",
    "        destination_id = position[2]\n",
    "        tuple_id = f'{line_id}-{stop_id}-{destination_id}'\n",
    "        if tuple_id not in memory:\n",
    "            memory[tuple_id] = get_direction_from_line_stop_and_destination(grouped_lines[line_id], stop_id,\n",
    "                                                                            destination_id)\n",
    "        directed_positions.writerow([*position, memory[tuple_id]])\n",
    "    output_file.close()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Split CSV into lines\n",
    "\n",
    "Splits `vehiclePositionsCleanDirected.csv` file created in previous section into separate CSV (one per line)\n",
    "**Reads from**: CSV file containing filtered vehicle positions with direction in `data` folder (`data/processed/vehiclePositionsCleanDirected.csv`)\n",
    "**Writes to**: CSV file per line containing filtered vehicle positions with direction in `data/processed/assignment1/vehiclePositionsPerLine` folder (`data/processed/assignment1/vehiclePositionsPerLine/vehiclePositions*.csv`)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "outputs": [],
   "source": [
    "def split_csv_by_lines():\n",
    "    files = {}\n",
    "    positions = read_csv_stream('../data/processed/vehiclePositionsCleanDirected.csv', skip_first=False)\n",
    "    header = next(positions)\n",
    "    for line in tqdm(positions):\n",
    "        line_id = line[1]\n",
    "        if line_id not in files:\n",
    "            files[line_id] = get_csv_writer(f'../data/processed/assignment1/vehiclePositionsPerLine/vehiclePositions{line_id}.csv')\n",
    "            files[line_id][0].writerow(header)\n",
    "        files[line_id][0].writerow(line)\n",
    "    for _, file in files.values():\n",
    "        file.close()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Vehicle Matching\n",
    "\n",
    "Tries to link several vehicle positions belonging to same physical vehicle\n",
    "**Reads from**: CSV file per line containing filtered vehicle positions with direction in `data/processed/assignment1/vehiclePositionsPerLine` folder (`data/processed/assignment1/vehiclePositionsPerLine/vehiclePositions*.csv`)\n",
    "**Writes to**: CSV file per line containing vehicle positions with `bus_id` in `data/processed/assignment1/csv_lines_linked` folder (`data/processed/assignment1/csv_lines_linked/vehiclePositions*.csv`)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "outputs": [],
   "source": [
    "\n",
    "from enum import Enum\n",
    "from itertools import count"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "outputs": [],
   "source": [
    "def split_positions_by_direction(positions: Iterable[List[str]]) -> Tuple[List[List[str]], List[List[str]]]:\n",
    "    line = ([], [])\n",
    "    for position in positions:\n",
    "        line[int(position[-1])].append(position)\n",
    "    return line"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "outputs": [],
   "source": [
    "def get_index_of_stop_in_line(line, direction, stop_id):\n",
    "    return get_index_of_stop_in_line_direction(line[direction], stop_id)\n",
    "\n",
    "\n",
    "def get_index_of_stop_in_line_direction(line, stop_id):\n",
    "    return next((int(stop[8]) for stop in line if stop[3] == stop_id), -1)\n",
    "\n",
    "\n",
    "class Match(Enum):\n",
    "    WRONG = 1\n",
    "    OK = 2\n",
    "    TOO_FAR = 3"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "outputs": [],
   "source": [
    "def group_positions_by_timestamp(positions: Iterable[List[str]]) -> List[Tuple[int, List[List[str]]]]:\n",
    "    grouped_positions = []\n",
    "    old_timestamp = -1\n",
    "    current_timestamp_positions = []\n",
    "    for position in positions:\n",
    "        current_timestamp = int(position[0])\n",
    "        if current_timestamp != old_timestamp:\n",
    "            assert current_timestamp > old_timestamp\n",
    "            grouped_positions.append((old_timestamp, current_timestamp_positions))\n",
    "            old_timestamp = current_timestamp\n",
    "            current_timestamp_positions = []\n",
    "        current_timestamp_positions.append(position)\n",
    "    grouped_positions.append((old_timestamp, current_timestamp_positions))\n",
    "    return grouped_positions[1:]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "outputs": [],
   "source": [
    "def possible_match(first_position: List[str], second_position: List[str],\n",
    "                   line: List[List[str]]) -> Match:\n",
    "    first_stop_id = first_position[4]\n",
    "    second_stop_id = second_position[4]\n",
    "    # Both positions are in the same stop -> Compare using distance from that stop\n",
    "    if first_stop_id == second_stop_id:\n",
    "        first_distance = int(first_position[3])\n",
    "        second_distance = int(second_position[3])\n",
    "        return Match.OK if first_distance <= second_distance else Match.WRONG\n",
    "    # Positions are in different stops -> Compare using order of stops in direction\n",
    "    else:\n",
    "        # Assert both positions have the same direction\n",
    "        first_stop_index = get_index_of_stop_in_line_direction(line, first_stop_id)\n",
    "        second_stop_index = get_index_of_stop_in_line_direction(line, second_stop_id)\n",
    "        if second_stop_index - first_stop_index > 3:\n",
    "            return Match.TOO_FAR\n",
    "        return Match.OK if first_stop_index < second_stop_index else Match.WRONG"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "outputs": [],
   "source": [
    "def find_bus_matched_of_line_direction(positions: Iterable[List[str]], line: List[List[str]], line_id: str,\n",
    "                                       direction: int, writer):\n",
    "    grouped_positions = group_positions_by_timestamp(positions)\n",
    "    previous_positions = []\n",
    "    bus_id = (f'{line_id}-{direction}-{i:06d}' for i in count())\n",
    "    sorting_key = lambda vehicle_position: get_index_of_stop_in_line_direction(line, vehicle_position[-2])\n",
    "\n",
    "    for timestamp, current_positions in grouped_positions:\n",
    "        sorted_positions = sorted(current_positions, key=sorting_key)\n",
    "        while len(sorted_positions) > 0 and get_index_of_stop_in_line_direction(line, sorted_positions[0][-2]) == -1:\n",
    "            sorted_positions.pop(0)\n",
    "        current_previous_position_index = 0\n",
    "        current_position_index = 0\n",
    "        while current_position_index < len(sorted_positions) and current_previous_position_index < len(\n",
    "                previous_positions):\n",
    "            previous_position = previous_positions[current_previous_position_index]\n",
    "            current_position = sorted_positions[current_position_index]\n",
    "            result = possible_match(previous_position, current_position, line)\n",
    "            if result == Match.OK:\n",
    "                current_position.append(previous_position[-1])\n",
    "                current_previous_position_index += 1\n",
    "                current_position_index += 1\n",
    "            elif result == Match.WRONG:\n",
    "                current_position.append(next(bus_id))\n",
    "                current_position_index += 1\n",
    "            elif result == Match.TOO_FAR:\n",
    "                current_previous_position_index += 1\n",
    "        for position in sorted_positions:\n",
    "            if len(position) == 6:\n",
    "                position.append(next(bus_id))\n",
    "            writer.writerow(position)\n",
    "        previous_positions = sorted_positions"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "outputs": [],
   "source": [
    "def find_bus_matches_of_line(file_path: str, output_path: str, line_id: str,\n",
    "                             line: Tuple[List[List[str]], List[List[str]]]) -> None:\n",
    "    positions = read_csv_stream(file_path, skip_first=False)\n",
    "    with write_csv(output_path) as linked_positions:\n",
    "        linked_positions.writerow([*next(positions), 'BusId'])\n",
    "        direction1, direction2 = split_positions_by_direction(positions)\n",
    "        find_bus_matched_of_line_direction(direction1, line[0], line_id, 0, linked_positions)\n",
    "        find_bus_matched_of_line_direction(direction2, line[1], line_id, 1, linked_positions)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/74 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mAssertionError\u001B[0m                            Traceback (most recent call last)",
      "\u001B[0;32m/var/folders/wh/6llm7dq16rvbwjb_yc0kfvvr0000gn/T/ipykernel_20741/2275613683.py\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m      8\u001B[0m         \u001B[0mfind_bus_matches_of_line\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34mf'{path}/{file}'\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34mf'{output_path}/{file}'\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mline_id\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mline\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      9\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 10\u001B[0;31m \u001B[0mfind_bus_matches_of_lines\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m",
      "\u001B[0;32m/var/folders/wh/6llm7dq16rvbwjb_yc0kfvvr0000gn/T/ipykernel_20741/2275613683.py\u001B[0m in \u001B[0;36mfind_bus_matches_of_lines\u001B[0;34m()\u001B[0m\n\u001B[1;32m      6\u001B[0m         \u001B[0mline_id\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mfile\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;36m16\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m-\u001B[0m\u001B[0;36m4\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      7\u001B[0m         \u001B[0mline\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mlines\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0mline_id\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m----> 8\u001B[0;31m         \u001B[0mfind_bus_matches_of_line\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34mf'{path}/{file}'\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34mf'{output_path}/{file}'\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mline_id\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mline\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m      9\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     10\u001B[0m \u001B[0mfind_bus_matches_of_lines\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/var/folders/wh/6llm7dq16rvbwjb_yc0kfvvr0000gn/T/ipykernel_20741/4083812496.py\u001B[0m in \u001B[0;36mfind_bus_matches_of_line\u001B[0;34m(file_path, output_path, line_id, line)\u001B[0m\n\u001B[1;32m      5\u001B[0m         \u001B[0mlinked_positions\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mwriterow\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0mnext\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mpositions\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m'BusId'\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      6\u001B[0m         \u001B[0mdirection1\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mdirection2\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0msplit_positions_by_direction\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mpositions\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m----> 7\u001B[0;31m         \u001B[0mfind_bus_matched_of_line_direction\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mdirection1\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mline\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;36m0\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mline_id\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;36m0\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mlinked_positions\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m      8\u001B[0m         \u001B[0mfind_bus_matched_of_line_direction\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mdirection2\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mline\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;36m1\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mline_id\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;36m1\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mlinked_positions\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      9\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/var/folders/wh/6llm7dq16rvbwjb_yc0kfvvr0000gn/T/ipykernel_20741/3561024085.py\u001B[0m in \u001B[0;36mfind_bus_matched_of_line_direction\u001B[0;34m(positions, line, line_id, direction, writer)\u001B[0m\n\u001B[1;32m      1\u001B[0m def find_bus_matched_of_line_direction(positions: Iterable[List[str]], line: List[List[str]], line_id: str,\n\u001B[1;32m      2\u001B[0m                                        direction: int, writer):\n\u001B[0;32m----> 3\u001B[0;31m     \u001B[0mgrouped_positions\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mgroup_positions_by_timestamp\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mpositions\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m      4\u001B[0m     \u001B[0mprevious_positions\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;34m[\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      5\u001B[0m     \u001B[0mbus_id\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;34m(\u001B[0m\u001B[0;34mf'{line_id}-{direction}-{i:06d}'\u001B[0m \u001B[0;32mfor\u001B[0m \u001B[0mi\u001B[0m \u001B[0;32min\u001B[0m \u001B[0mcount\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/var/folders/wh/6llm7dq16rvbwjb_yc0kfvvr0000gn/T/ipykernel_20741/3465490865.py\u001B[0m in \u001B[0;36mgroup_positions_by_timestamp\u001B[0;34m(positions)\u001B[0m\n\u001B[1;32m      6\u001B[0m         \u001B[0mcurrent_timestamp\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mint\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mposition\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;36m0\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      7\u001B[0m         \u001B[0;32mif\u001B[0m \u001B[0mcurrent_timestamp\u001B[0m \u001B[0;34m!=\u001B[0m \u001B[0mold_timestamp\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m----> 8\u001B[0;31m             \u001B[0;32massert\u001B[0m \u001B[0mcurrent_timestamp\u001B[0m \u001B[0;34m>\u001B[0m \u001B[0mold_timestamp\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m      9\u001B[0m             \u001B[0mgrouped_positions\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mappend\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mold_timestamp\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mcurrent_timestamp_positions\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     10\u001B[0m             \u001B[0mold_timestamp\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mcurrent_timestamp\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mAssertionError\u001B[0m: "
     ]
    }
   ],
   "source": [
    "def find_bus_matches_of_lines():\n",
    "    path = '../data/processed/assignment1/vehiclePositionsPerLine'\n",
    "    output_path = '../data/processed/assignment1/csv_lines_linked'\n",
    "    lines = group_line_stops(read_csv_stream('../data/processed/line_stops.csv'))\n",
    "    for file in tqdm(os.listdir(path)):\n",
    "        line_id = file[16:-4]\n",
    "        line = lines[line_id]\n",
    "        find_bus_matches_of_line(f'{path}/{file}', f'{output_path}/{file}', line_id, line)\n",
    "\n",
    "find_bus_matches_of_lines()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Calculate average time between stops"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "outputs": [],
   "source": [
    "from scripts.helpers import *\n",
    "import datetime\n",
    "from tqdm import tqdm\n",
    "import os"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "outputs": [],
   "source": [
    "def group_positions_by_vehicle(positions: List[List[str]]) -> Dict[str, List[List[List[str]]]]:\n",
    "    grouped_positions = {}\n",
    "    for position in positions:\n",
    "        bus_id = position[-1]\n",
    "        if bus_id not in grouped_positions:\n",
    "            grouped_positions[bus_id] = []\n",
    "        grouped_positions[bus_id].append(position)\n",
    "    return grouped_positions"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "outputs": [],
   "source": [
    "def get_hour_from_timestamp(timestamp: int) -> int:\n",
    "    return datetime.datetime.fromtimestamp(timestamp // 1000).hour"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "outputs": [],
   "source": [
    "def get_vehicle_times_between_stops(vehicle_positions: List[List[str]],\n",
    "                                    line: Tuple[List[List[str]], List[List[str]]]) -> List:\n",
    "    times = []\n",
    "    previous_timestamp = int(vehicle_positions[0][0])\n",
    "    previous_stop = vehicle_positions[0][4]\n",
    "    for position in vehicle_positions:\n",
    "        current_timestamp = int(position[0])\n",
    "        current_stop = position[4]\n",
    "        if current_stop != previous_stop:\n",
    "            time_difference = (current_timestamp - previous_timestamp) // 1000\n",
    "            first_hour = get_hour_from_timestamp(previous_timestamp)\n",
    "            last_hour = get_hour_from_timestamp(current_timestamp)\n",
    "            times.append([first_hour, previous_stop, current_stop, time_difference])\n",
    "            if first_hour != last_hour:\n",
    "                times.append([last_hour, previous_stop, current_stop, time_difference])\n",
    "            previous_stop = current_stop\n",
    "            previous_timestamp = current_timestamp\n",
    "    return times\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "outputs": [],
   "source": [
    "def calculate_average_time_between_stops_of_line(positions: List[List[str]], line_id: str,\n",
    "                                                 line: Tuple[List[List[str]], List[List[str]]], output):\n",
    "    grouped_positions = group_positions_by_vehicle(positions)\n",
    "    times = []\n",
    "    for vehicle_id, vehicle_positions in grouped_positions.items():\n",
    "        times += get_vehicle_times_between_stops(vehicle_positions, line)\n",
    "    for direction in [0, 1]:\n",
    "        for fromStop, toStop in zip(line[direction][:-1], line[direction][1:]):\n",
    "            time_sum = [0 for _ in range(24)]\n",
    "            time_sum_filtered = [0 for _ in range(24)]\n",
    "            time_count = [0 for _ in range(24)]\n",
    "            time_count_filtered = [0 for _ in range(24)]\n",
    "            for time in times:\n",
    "                if time[1] == fromStop[3] and time[2] == toStop[3]:\n",
    "                    time_sum[time[0]] += time[3]\n",
    "                    time_count[time[0]] += 1\n",
    "                    if time[3] < 6000:  # Times larger than 10 minutes are likely anomalies that shouldn't be counter\n",
    "                        time_sum_filtered[time[0]] += time[3]\n",
    "                        time_count_filtered[time[0]] += 1\n",
    "            output[0].writerow(\n",
    "                [line_id, fromStop[3], toStop[3],\n",
    "                 *[f'{total / amount:.2f}' if amount > 0 else 0 for total, amount in zip(time_sum, time_count)]])\n",
    "            output[1].writerow([line_id, fromStop[3], toStop[3], *time_count])\n",
    "            output[2].writerow(\n",
    "                [line_id, fromStop[3], toStop[3], *[f'{total / amount:.2f}' if amount > 0 else 0 for total, amount in\n",
    "                                                    zip(time_sum_filtered, time_count_filtered)]])\n",
    "            output[3].writerow([line_id, fromStop[3], toStop[3], *time_count_filtered])\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]\n"
     ]
    }
   ],
   "source": [
    "def calculate_average_time_between_stops():\n",
    "    source_path = '../data/processed/assignment1/csv_lines_linked'\n",
    "    output_path = '../data/processed/average_time_between_stops.csv'\n",
    "    output_path_filtered = '../data/processed/average_time_between_stops_filtered.csv'\n",
    "    output_path_count = '../data/processed/average_time_between_stops_count.csv'\n",
    "    output_path_filtered_count = '../data/processed/average_time_between_stops_filtered_count.csv'\n",
    "    lines = group_line_stops(read_csv_stream('../data/processed/line_stops.csv'))\n",
    "    with write_csv(output_path) as output, write_csv(output_path_filtered) as output_filtered, write_csv(\n",
    "            output_path_count) as output_count, write_csv(output_path_filtered_count) as output_filtered_count:\n",
    "        header = ['LineId', 'FromStop', 'ToStop', *[f'{i}' for i in range(24)]]\n",
    "        output.writerow(header)\n",
    "        output_filtered.writerow(header)\n",
    "        output_count.writerow(header)\n",
    "        output_filtered_count.writerow(header)\n",
    "        for file in tqdm(os.listdir(source_path)):\n",
    "            line_id = file[16:-4]\n",
    "            line = lines[line_id]\n",
    "            positions = read_csv_list(f'{source_path}/{file}')[1:]\n",
    "            calculate_average_time_between_stops_of_line(positions, line_id, line,\n",
    "                                                         (output, output_count, output_filtered, output_filtered_count))\n",
    "\n",
    "\n",
    "calculate_average_time_between_stops()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Main script\n",
    "\n",
    "Runs all previous functions in succession"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converting JSON files to CSV\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 13/13 [00:40<00:00,  3.11s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating vehicle routes from shapefiles\n",
      "Dropping vehicle positions with unknown data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "19421883it [00:36, 533599.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLine 1: 63100 rows deleted out of 305454 (20.66%)\n",
      "\tLine 12: 2091 rows deleted out of 238655 (0.88%)\n",
      "\tLine 13: 12387 rows deleted out of 231422 (5.35%)\n",
      "\tLine 14: 26554 rows deleted out of 272554 (9.74%)\n",
      "\tLine 17: 393 rows deleted out of 93979 (0.42%)\n",
      "\tLine 19: 9177 rows deleted out of 374100 (2.45%)\n",
      "\tLine 2: 4129 rows deleted out of 215114 (1.92%)\n",
      "\tLine 20: 12947 rows deleted out of 240316 (5.39%)\n",
      "\tLine 21: 5420 rows deleted out of 196146 (2.76%)\n",
      "\tLine 25: 349123 rows deleted out of 387235 (90.16%)\n",
      "\tLine 27: 34005 rows deleted out of 222168 (15.31%)\n",
      "\tLine 28: 13419 rows deleted out of 188596 (7.12%)\n",
      "\tLine 29: 37447 rows deleted out of 352595 (10.62%)\n",
      "\tLine 3: 162263 rows deleted out of 383543 (42.31%)\n",
      "\tLine 33: 0 rows deleted out of 69363 (0.00%)\n",
      "\tLine 34: 77757 rows deleted out of 271519 (28.64%)\n",
      "\tLine 36: 8227 rows deleted out of 243214 (3.38%)\n",
      "\tLine 37: 33673 rows deleted out of 163857 (20.55%)\n",
      "\tLine 38: 8697 rows deleted out of 346695 (2.51%)\n",
      "\tLine 39: 8136 rows deleted out of 211299 (3.85%)\n",
      "\tLine 4: 1654 rows deleted out of 282947 (0.58%)\n",
      "\tLine 41: 25810 rows deleted out of 234265 (11.02%)\n",
      "\tLine 42: 10005 rows deleted out of 124988 (8.00%)\n",
      "\tLine 43: 29489 rows deleted out of 205633 (14.34%)\n",
      "\tLine 44: 4044 rows deleted out of 186908 (2.16%)\n",
      "\tLine 45: 1191 rows deleted out of 224191 (0.53%)\n",
      "\tLine 46: 33120 rows deleted out of 374030 (8.85%)\n",
      "\tLine 47: 58642 rows deleted out of 201958 (29.04%)\n",
      "\tLine 48: 77304 rows deleted out of 343800 (22.49%)\n",
      "\tLine 49: 8151 rows deleted out of 326486 (2.50%)\n",
      "\tLine 5: 2715 rows deleted out of 405897 (0.67%)\n",
      "\tLine 50: 0 rows deleted out of 179314 (0.00%)\n",
      "\tLine 51: 16545 rows deleted out of 500110 (3.31%)\n",
      "\tLine 53: 689 rows deleted out of 367269 (0.19%)\n",
      "\tLine 54: 1682 rows deleted out of 276552 (0.61%)\n",
      "\tLine 55: 177269 rows deleted out of 295709 (59.95%)\n",
      "\tLine 56: 2236 rows deleted out of 238414 (0.94%)\n",
      "\tLine 57: 2990 rows deleted out of 107511 (2.78%)\n",
      "\tLine 58: 0 rows deleted out of 215717 (0.00%)\n",
      "\tLine 59: 182414 rows deleted out of 296514 (61.52%)\n",
      "\tLine 6: 31746 rows deleted out of 332930 (9.54%)\n",
      "\tLine 60: 7388 rows deleted out of 278309 (2.65%)\n",
      "\tLine 61: 60794 rows deleted out of 174369 (34.87%)\n",
      "\tLine 62: 6563 rows deleted out of 120972 (5.43%)\n",
      "\tLine 63: 706 rows deleted out of 231204 (0.31%)\n",
      "\tLine 64: 141228 rows deleted out of 259764 (54.37%)\n",
      "\tLine 65: 130539 rows deleted out of 423811 (30.80%)\n",
      "\tLine 66: 87465 rows deleted out of 266702 (32.80%)\n",
      "\tLine 69: 242 rows deleted out of 33083 (0.73%)\n",
      "\tLine 7: 45760 rows deleted out of 529144 (8.65%)\n",
      "\tLine 70: 27456 rows deleted out of 114793 (23.92%)\n",
      "\tLine 71: 1946 rows deleted out of 435665 (0.45%)\n",
      "\tLine 72: 311 rows deleted out of 42247 (0.74%)\n",
      "\tLine 74: 25615 rows deleted out of 211740 (12.10%)\n",
      "\tLine 75: 21 rows deleted out of 112767 (0.02%)\n",
      "\tLine 76: 13864 rows deleted out of 63121 (21.96%)\n",
      "\tLine 77: 0 rows deleted out of 19044 (0.00%)\n",
      "\tLine 78: 50653 rows deleted out of 107803 (46.99%)\n",
      "\tLine 79: 1948 rows deleted out of 183275 (1.06%)\n",
      "\tLine 8: 18272 rows deleted out of 386756 (4.72%)\n",
      "\tLine 80: 19903 rows deleted out of 390862 (5.09%)\n",
      "\tLine 81: 248386 rows deleted out of 504996 (49.19%)\n",
      "\tLine 82: 12882 rows deleted out of 515924 (2.50%)\n",
      "\tLine 83: 59460 rows deleted out of 292515 (20.33%)\n",
      "\tLine 86: 25904 rows deleted out of 250698 (10.33%)\n",
      "\tLine 87: 16449 rows deleted out of 308770 (5.33%)\n",
      "\tLine 88: 2854 rows deleted out of 273299 (1.04%)\n",
      "\tLine 89: 31427 rows deleted out of 233720 (13.45%)\n",
      "\tLine 9: 0 rows deleted out of 131274 (0.00%)\n",
      "\tLine 92: 130082 rows deleted out of 486408 (26.74%)\n",
      "\tLine 93: 180014 rows deleted out of 402974 (44.67%)\n",
      "\tLine 95: 293305 rows deleted out of 531447 (55.19%)\n",
      "\tLine 97: 6376 rows deleted out of 276705 (2.30%)\n",
      "\tLine 98: 0 rows deleted out of 98755 (0.00%)\n",
      "\tTotal: 3184454 rows deleted out of 19421883 (16.40%)\n",
      "Adding direction to positions\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "16237429it [00:31, 520080.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating CSVs for each line\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "16237429it [00:26, 604895.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matching positions\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/74 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mAssertionError\u001B[0m                            Traceback (most recent call last)",
      "\u001B[0;32m/var/folders/wh/6llm7dq16rvbwjb_yc0kfvvr0000gn/T/ipykernel_20741/4154096585.py\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m     33\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     34\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 35\u001B[0;31m \u001B[0mwhole_process\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m",
      "\u001B[0;32m/var/folders/wh/6llm7dq16rvbwjb_yc0kfvvr0000gn/T/ipykernel_20741/4154096585.py\u001B[0m in \u001B[0;36mwhole_process\u001B[0;34m(fix_data)\u001B[0m\n\u001B[1;32m     26\u001B[0m     \u001B[0;31m# Match positions by vehicle\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     27\u001B[0m     \u001B[0mprint\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m'Matching positions'\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 28\u001B[0;31m     \u001B[0mfind_bus_matches_of_lines\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     29\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     30\u001B[0m     \u001B[0;31m# Calculate average time between stops per hour/line\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/var/folders/wh/6llm7dq16rvbwjb_yc0kfvvr0000gn/T/ipykernel_20741/4015001751.py\u001B[0m in \u001B[0;36mfind_bus_matches_of_lines\u001B[0;34m()\u001B[0m\n\u001B[1;32m      6\u001B[0m         \u001B[0mline_id\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mfile\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;36m16\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m-\u001B[0m\u001B[0;36m4\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      7\u001B[0m         \u001B[0mline\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mlines\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0mline_id\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m----> 8\u001B[0;31m         \u001B[0mfind_bus_matches_of_line\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34mf'{path}/{file}'\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34mf'{output_path}/{file}'\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mline_id\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mline\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m",
      "\u001B[0;32m/var/folders/wh/6llm7dq16rvbwjb_yc0kfvvr0000gn/T/ipykernel_20741/4083812496.py\u001B[0m in \u001B[0;36mfind_bus_matches_of_line\u001B[0;34m(file_path, output_path, line_id, line)\u001B[0m\n\u001B[1;32m      5\u001B[0m         \u001B[0mlinked_positions\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mwriterow\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0mnext\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mpositions\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m'BusId'\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      6\u001B[0m         \u001B[0mdirection1\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mdirection2\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0msplit_positions_by_direction\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mpositions\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m----> 7\u001B[0;31m         \u001B[0mfind_bus_matched_of_line_direction\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mdirection1\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mline\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;36m0\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mline_id\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;36m0\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mlinked_positions\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m      8\u001B[0m         \u001B[0mfind_bus_matched_of_line_direction\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mdirection2\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mline\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;36m1\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mline_id\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;36m1\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mlinked_positions\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      9\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/var/folders/wh/6llm7dq16rvbwjb_yc0kfvvr0000gn/T/ipykernel_20741/3561024085.py\u001B[0m in \u001B[0;36mfind_bus_matched_of_line_direction\u001B[0;34m(positions, line, line_id, direction, writer)\u001B[0m\n\u001B[1;32m      1\u001B[0m def find_bus_matched_of_line_direction(positions: Iterable[List[str]], line: List[List[str]], line_id: str,\n\u001B[1;32m      2\u001B[0m                                        direction: int, writer):\n\u001B[0;32m----> 3\u001B[0;31m     \u001B[0mgrouped_positions\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mgroup_positions_by_timestamp\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mpositions\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m      4\u001B[0m     \u001B[0mprevious_positions\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;34m[\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      5\u001B[0m     \u001B[0mbus_id\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;34m(\u001B[0m\u001B[0;34mf'{line_id}-{direction}-{i:06d}'\u001B[0m \u001B[0;32mfor\u001B[0m \u001B[0mi\u001B[0m \u001B[0;32min\u001B[0m \u001B[0mcount\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/var/folders/wh/6llm7dq16rvbwjb_yc0kfvvr0000gn/T/ipykernel_20741/3465490865.py\u001B[0m in \u001B[0;36mgroup_positions_by_timestamp\u001B[0;34m(positions)\u001B[0m\n\u001B[1;32m      6\u001B[0m         \u001B[0mcurrent_timestamp\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mint\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mposition\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;36m0\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      7\u001B[0m         \u001B[0;32mif\u001B[0m \u001B[0mcurrent_timestamp\u001B[0m \u001B[0;34m!=\u001B[0m \u001B[0mold_timestamp\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m----> 8\u001B[0;31m             \u001B[0;32massert\u001B[0m \u001B[0mcurrent_timestamp\u001B[0m \u001B[0;34m>\u001B[0m \u001B[0mold_timestamp\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m      9\u001B[0m             \u001B[0mgrouped_positions\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mappend\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mold_timestamp\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mcurrent_timestamp_positions\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     10\u001B[0m             \u001B[0mold_timestamp\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mcurrent_timestamp\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mAssertionError\u001B[0m: "
     ]
    }
   ],
   "source": [
    "# TODO: @Victor recompose whole_process to work with fix_data if statement.\n",
    "\n",
    "def whole_process(fix_data=False):\n",
    "    # Convert JSON files to csv with vehicle positions\n",
    "    print('Converting JSON files to CSV')\n",
    "    convert_json_files_into_single_csv()\n",
    "\n",
    "    # Create vehicle routes from shapefiles\n",
    "    print('Creating vehicle routes from shapefiles')\n",
    "    create_line_stops_csv()\n",
    "\n",
    "    # Fix/drop vehicle positions directions\n",
    "    if fix_data:\n",
    "        print('Fixing vehicle positions with unknown data')\n",
    "        # TODO: finish fix code\n",
    "        pass\n",
    "    else:\n",
    "        print('Dropping vehicle positions with unknown data')\n",
    "        drop_positions_with_unknown_stop_or_direction()\n",
    "\n",
    "    print('Adding direction to positions')\n",
    "    add_direction_to_csv()\n",
    "\n",
    "    # Split positions by line\n",
    "    print('Creating CSVs for each line')\n",
    "    split_csv_by_lines()\n",
    "\n",
    "    # Match positions by vehicle\n",
    "    print('Matching positions')\n",
    "    find_bus_matches_of_lines()\n",
    "\n",
    "    # Calculate average time between stops per hour/line\n",
    "    print('Calculating average time between stops')\n",
    "    calculate_average_time_between_stops()\n",
    "\n",
    "\n",
    "whole_process()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}