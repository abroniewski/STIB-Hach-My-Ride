{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Assignment 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert Line shapes to EPSG:4326"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "import shapefile\n",
    "from numpy import mean, median\n",
    "from pyproj import Proj, transform\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a74ed3661b384dc69942287ebed5e0b7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/174 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_9052/3003335364.py:4: DeprecationWarning: This function is deprecated. See: https://pyproj4.github.io/pyproj/stable/gotchas.html#upgrading-to-pyproj-2-from-pyproj-1\n",
      "  shapes = {f'{line.record[\"LIGNE\"]}-{line.record[\"VARIANTE\"]}': [transform(lambert, latlong, x, y) for x, y in\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "\u001B[0;32m/tmp/ipykernel_9052/3003335364.py\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m      2\u001B[0m \u001B[0mlambert\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mProj\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m'EPSG:31370'\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      3\u001B[0m \u001B[0mlatlong\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mProj\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m'EPSG:4326'\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m----> 4\u001B[0;31m shapes = {f'{line.record[\"LIGNE\"]}-{line.record[\"VARIANTE\"]}': [transform(lambert, latlong, x, y) for x, y in\n\u001B[0m\u001B[1;32m      5\u001B[0m                                                                 line.shape.points] for line in\n\u001B[1;32m      6\u001B[0m           tqdm(lines.shapeRecords())}\n",
      "\u001B[0;32m/tmp/ipykernel_9052/3003335364.py\u001B[0m in \u001B[0;36m<dictcomp>\u001B[0;34m(.0)\u001B[0m\n\u001B[1;32m      2\u001B[0m \u001B[0mlambert\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mProj\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m'EPSG:31370'\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      3\u001B[0m \u001B[0mlatlong\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mProj\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m'EPSG:4326'\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m----> 4\u001B[0;31m shapes = {f'{line.record[\"LIGNE\"]}-{line.record[\"VARIANTE\"]}': [transform(lambert, latlong, x, y) for x, y in\n\u001B[0m\u001B[1;32m      5\u001B[0m                                                                 line.shape.points] for line in\n\u001B[1;32m      6\u001B[0m           tqdm(lines.shapeRecords())}\n",
      "\u001B[0;32m/tmp/ipykernel_9052/3003335364.py\u001B[0m in \u001B[0;36m<listcomp>\u001B[0;34m(.0)\u001B[0m\n\u001B[1;32m      2\u001B[0m \u001B[0mlambert\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mProj\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m'EPSG:31370'\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      3\u001B[0m \u001B[0mlatlong\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mProj\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m'EPSG:4326'\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m----> 4\u001B[0;31m shapes = {f'{line.record[\"LIGNE\"]}-{line.record[\"VARIANTE\"]}': [transform(lambert, latlong, x, y) for x, y in\n\u001B[0m\u001B[1;32m      5\u001B[0m                                                                 line.shape.points] for line in\n\u001B[1;32m      6\u001B[0m           tqdm(lines.shapeRecords())}\n",
      "\u001B[0;32m~/jupyter/environment/lib/python3.8/site-packages/pyproj/transformer.py\u001B[0m in \u001B[0;36mtransform\u001B[0;34m(p1, p2, x, y, z, tt, radians, errcheck, skip_equivalent, always_xy)\u001B[0m\n\u001B[1;32m   1192\u001B[0m         \u001B[0mstacklevel\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;36m2\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1193\u001B[0m     )\n\u001B[0;32m-> 1194\u001B[0;31m     return Transformer.from_proj(\n\u001B[0m\u001B[1;32m   1195\u001B[0m         \u001B[0mp1\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mp2\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mskip_equivalent\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mskip_equivalent\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0malways_xy\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0malways_xy\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1196\u001B[0m     ).transform(xx=x, yy=y, zz=z, tt=tt, radians=radians, errcheck=errcheck)\n",
      "\u001B[0;32m~/jupyter/environment/lib/python3.8/site-packages/pyproj/transformer.py\u001B[0m in \u001B[0;36mfrom_proj\u001B[0;34m(proj_from, proj_to, skip_equivalent, always_xy, area_of_interest)\u001B[0m\n\u001B[1;32m    493\u001B[0m             \u001B[0mproj_to\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mProj\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mproj_to\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    494\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 495\u001B[0;31m         return Transformer.from_crs(\n\u001B[0m\u001B[1;32m    496\u001B[0m             \u001B[0mproj_from\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mcrs\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    497\u001B[0m             \u001B[0mproj_to\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mcrs\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/jupyter/environment/lib/python3.8/site-packages/pyproj/transformer.py\u001B[0m in \u001B[0;36mfrom_crs\u001B[0;34m(crs_from, crs_to, skip_equivalent, always_xy, area_of_interest, authority, accuracy, allow_ballpark)\u001B[0m\n\u001B[1;32m    563\u001B[0m             )\n\u001B[1;32m    564\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 565\u001B[0;31m         return Transformer(\n\u001B[0m\u001B[1;32m    566\u001B[0m             TransformerFromCRS(\n\u001B[1;32m    567\u001B[0m                 \u001B[0mcstrencode\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mCRS\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mfrom_user_input\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mcrs_from\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0msrs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/jupyter/environment/lib/python3.8/site-packages/pyproj/transformer.py\u001B[0m in \u001B[0;36m__init__\u001B[0;34m(self, transformer_maker)\u001B[0m\n\u001B[1;32m    308\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    309\u001B[0m         \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_local\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mTransformerLocal\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 310\u001B[0;31m         \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_local\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mtransformer\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mtransformer_maker\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    311\u001B[0m         \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_transformer_maker\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mtransformer_maker\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    312\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/jupyter/environment/lib/python3.8/site-packages/pyproj/transformer.py\u001B[0m in \u001B[0;36m__call__\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m     95\u001B[0m         \u001B[0m_Transformer\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     96\u001B[0m         \"\"\"\n\u001B[0;32m---> 97\u001B[0;31m         return _Transformer.from_crs(\n\u001B[0m\u001B[1;32m     98\u001B[0m             \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mcrs_from\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     99\u001B[0m             \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mcrs_to\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32mpyproj/_transformer.pyx\u001B[0m in \u001B[0;36mpyproj._transformer._Transformer.from_crs\u001B[0;34m()\u001B[0m\n",
      "\u001B[0;32mpyproj/_transformer.pyx\u001B[0m in \u001B[0;36mpyproj._transformer._Transformer._init_from_crs\u001B[0;34m()\u001B[0m\n",
      "\u001B[0;32mpyproj/_transformer.pyx\u001B[0m in \u001B[0;36mpyproj._transformer._Transformer._initialize_from_projobj\u001B[0;34m()\u001B[0m\n",
      "\u001B[0;32m~/jupyter/environment/lib/python3.8/site-packages/pyproj/exceptions.py\u001B[0m in \u001B[0;36mclear\u001B[0;34m()\u001B[0m\n\u001B[1;32m     17\u001B[0m         \u001B[0msuper\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m__init__\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0merror_message\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     18\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 19\u001B[0;31m     \u001B[0;34m@\u001B[0m\u001B[0mstaticmethod\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     20\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0mclear\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;34m->\u001B[0m \u001B[0;32mNone\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     21\u001B[0m         \"\"\"\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "# already run if you have shapes_lat_long.json\n",
    "lines = shapefile.Reader('../data/raw/shapefiles/ACTU_LINES')\n",
    "lambert = Proj('EPSG:31370')\n",
    "latlong = Proj('EPSG:4326')\n",
    "shapes = {f'{line.record[\"LIGNE\"]}-{line.record[\"VARIANTE\"]}': [transform(lambert, latlong, x, y) for x, y in\n",
    "                                                                line.shape.points] for line in\n",
    "          tqdm(lines.shapeRecords())}\n",
    "with open('../data/raw/shapes_lat_long.json', 'w', encoding='utf8') as json_file:\n",
    "    json.dump(shapes, json_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create plots for each track and line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "import os\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "04d5c72cd6514946918cbc323065c882",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/9 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "722593cede7a42cf9909d56747bd2299",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2449bf2c2a37461b8155089902af44e2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c4b21d26317e4d788dc5bb69de2b67ff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "09748cb72bfa454eb16c5a5b1c10fe41",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4229add03c3b48edbbb5b3e80887cbe7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "288318bce72244f4bf02228952197870",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "682fab3ab9c2474bbe9431e3aa25d948",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a127d84fc35d414dbb4b18faf7ae715e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c77df301dde24e42a5516c0c51612ae7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tracks = pd.read_csv('../data/raw/GPSTracksAssignment4/GPStracks.csv')\n",
    "with open('../data/raw/shapes_lat_long.json', 'r', encoding='utf8') as json_file:\n",
    "    shapes = json.load(json_file)\n",
    "for track_id in tqdm(tracks['TrackId'].unique()):\n",
    "    track = tracks[tracks['TrackId'] == track_id].sort_values(by='time')\n",
    "    if not os.path.exists(f'../data/line_plots/Track{track_id}'):\n",
    "        os.mkdir(f'../data/line_plots/Track{track_id}')\n",
    "    for index, (line_id, line) in tqdm(enumerate(shapes.items())):\n",
    "        plt.scatter(x=track['lon'], y=track['lat'], label=f'Track {track_id}')\n",
    "        plt.scatter(x=[lon for _, lon in line], y=[lat for lat, _ in line], label=line_id)\n",
    "        plt.title(line_id)\n",
    "        plt.savefig(f'../data/line_plots/Track{track_id}/{line_id}.png')\n",
    "        plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Track âŸ¶ Line:\n",
    "\n",
    " - Track 1: Other\n",
    " - Track 3: Bus 50 or Tram 82 or Bus 49\n",
    " - Track 4: Bus 50\n",
    " - Track 5: Tram 82 or Tram 97\n",
    " - Track 6: Tram 8\n",
    " - Track 7: Tram 7\n",
    " - Track 8: Other\n",
    " - Track 10: Tram 8 or Tram 93\n",
    " - Track 11: Tram 25"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create CSV of labeled points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import json\n",
    "from scripts.helpers import write_csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "with open('../data/raw/shapes_lat_long.json', 'r', encoding='utf8') as json_file:\n",
    "    shapes = json.load(json_file)\n",
    "with write_csv('../data/processed/assignment4/labeled_line_points.csv') as csv_out:\n",
    "    csv_out.writerow(['Lat', 'Long', 'LineId'])\n",
    "    for line_id, points in shapes.items():\n",
    "        if line_id[:-2] in ['032t']:  # Remove lines that are not active anymore\n",
    "            continue\n",
    "        for lat, long in points:\n",
    "            csv_out.writerow([lat, long, line_id[:-2]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Classification Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from scripts.helpers import read_csv_list\n",
    "import pandas as pd\n",
    "from typing import Tuple, List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def get_datasets() -> Tuple[List[List[float]], List[str], pd.DataFrame]:\n",
    "    csv_lines = read_csv_list('../data/processed/assignment4/labeled_line_points.csv')\n",
    "    data_set = [[float(point[0]), float(point[1])] for point in csv_lines[1:]]\n",
    "    data_labels = [point[-1] for point in csv_lines[1:]]\n",
    "    tracks = pd.read_csv('../data/raw/GPStracks.csv')\n",
    "    return data_set, data_labels, tracks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create \"Ensemble\" with KNN using average probability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model\n",
      "Model trained\n",
      "1 -> [(41.68539325842696, '046b'), (11.96629213483146, '051t'), (11.23595505617978, '088b'), (7.808988764044942, '001m')]\n",
      "3 -> [(33.13043478260868, '082t'), (23.652173913043487, '049b'), (23.391304347826086, '050b'), (10.608695652173912, '048b')]\n",
      "4 -> [(36.639004149377605, '050b'), (14.190871369294602, '082t'), (14.06639004149377, '097t'), (13.775933609958502, '074b')]\n",
      "5 -> [(36.788990825688074, '097t'), (36.19266055045872, '082t'), (15.229357798165125, '050b'), (8.532110091743121, '052b')]\n",
      "6 -> [(42.382671480144396, '008t'), (27.400722021660652, '093t'), (7.725631768953068, '007t'), (5.9205776173285205, '071b')]\n",
      "7 -> [(47.53846153846154, '007t'), (44.564102564102555, '025t'), (4.153846153846154, '008t'), (1.2307692307692308, '034b')]\n",
      "8 -> [(15.318471337579615, '060b'), (14.872611464968156, '007t'), (12.229299363057322, '008t'), (11.910828025477711, '038b')]\n",
      "10 -> [(42.58064516129032, '008t'), (42.58064516129032, '093t'), (6.29032258064516, '038b'), (6.29032258064516, '060b')]\n",
      "11 -> [(45.023923444976084, '025t'), (40.76555023923446, '007t'), (6.267942583732056, '071b'), (4.019138755980861, '008t')]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Victor\\.virtualenvs\\STIB-Hach-My-Ride-39xoxc1Q\\lib\\site-packages\\sklearn\\base.py:438: UserWarning: X has feature names, but KNeighborsClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\Victor\\.virtualenvs\\STIB-Hach-My-Ride-39xoxc1Q\\lib\\site-packages\\sklearn\\base.py:438: UserWarning: X has feature names, but KNeighborsClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\Victor\\.virtualenvs\\STIB-Hach-My-Ride-39xoxc1Q\\lib\\site-packages\\sklearn\\base.py:438: UserWarning: X has feature names, but KNeighborsClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\Victor\\.virtualenvs\\STIB-Hach-My-Ride-39xoxc1Q\\lib\\site-packages\\sklearn\\base.py:438: UserWarning: X has feature names, but KNeighborsClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\Victor\\.virtualenvs\\STIB-Hach-My-Ride-39xoxc1Q\\lib\\site-packages\\sklearn\\base.py:438: UserWarning: X has feature names, but KNeighborsClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\Victor\\.virtualenvs\\STIB-Hach-My-Ride-39xoxc1Q\\lib\\site-packages\\sklearn\\base.py:438: UserWarning: X has feature names, but KNeighborsClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\Victor\\.virtualenvs\\STIB-Hach-My-Ride-39xoxc1Q\\lib\\site-packages\\sklearn\\base.py:438: UserWarning: X has feature names, but KNeighborsClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\Victor\\.virtualenvs\\STIB-Hach-My-Ride-39xoxc1Q\\lib\\site-packages\\sklearn\\base.py:438: UserWarning: X has feature names, but KNeighborsClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\Victor\\.virtualenvs\\STIB-Hach-My-Ride-39xoxc1Q\\lib\\site-packages\\sklearn\\base.py:438: UserWarning: X has feature names, but KNeighborsClassifier was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "data_set, data_labels, tracks = get_datasets()\n",
    "print('Training model')\n",
    "model = KNeighborsClassifier(n_neighbors=10)\n",
    "model.fit(data_set, data_labels)\n",
    "print('Model trained')\n",
    "for track_id in tracks['TrackId'].unique():\n",
    "    track_points = tracks[tracks['TrackId'] == track_id][['lat', 'lon']]\n",
    "    predictions = model.predict_proba(track_points)\n",
    "    final_predictions = [(sum(predictions[i][x]\n",
    "                              for i in range(len(predictions))) * 100 / len(predictions), model.classes_[x])\n",
    "                         for x in range(len(predictions[0]))]\n",
    "    sorted_predictions = sorted(final_predictions, key=lambda x: x[0], reverse=True)\n",
    "\n",
    "    print(track_id, '->', sorted_predictions[:4])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create \"Ensemble\" with KNN using \"presence\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model\n",
      "Model trained\n",
      "1 -> []\n",
      "3 -> [(97.3913043478261, '049b'), (96.52173913043478, '050b'), (95.65217391304348, '082t')]\n",
      "4 -> [(100.0, '050b')]\n",
      "5 -> [(98.62385321100918, '097t'), (98.1651376146789, '082t')]\n",
      "6 -> [(97.83393501805054, '008t')]\n",
      "7 -> [(100.0, '007t')]\n",
      "8 -> []\n",
      "10 -> [(93.54838709677419, '008t'), (93.54838709677419, '093t')]\n",
      "11 -> [(100.0, '025t')]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Victor\\.virtualenvs\\STIB-Hach-My-Ride-39xoxc1Q\\lib\\site-packages\\sklearn\\base.py:438: UserWarning: X has feature names, but KNeighborsClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\Victor\\.virtualenvs\\STIB-Hach-My-Ride-39xoxc1Q\\lib\\site-packages\\sklearn\\base.py:438: UserWarning: X has feature names, but KNeighborsClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\Victor\\.virtualenvs\\STIB-Hach-My-Ride-39xoxc1Q\\lib\\site-packages\\sklearn\\base.py:438: UserWarning: X has feature names, but KNeighborsClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\Victor\\.virtualenvs\\STIB-Hach-My-Ride-39xoxc1Q\\lib\\site-packages\\sklearn\\base.py:438: UserWarning: X has feature names, but KNeighborsClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\Victor\\.virtualenvs\\STIB-Hach-My-Ride-39xoxc1Q\\lib\\site-packages\\sklearn\\base.py:438: UserWarning: X has feature names, but KNeighborsClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\Victor\\.virtualenvs\\STIB-Hach-My-Ride-39xoxc1Q\\lib\\site-packages\\sklearn\\base.py:438: UserWarning: X has feature names, but KNeighborsClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\Victor\\.virtualenvs\\STIB-Hach-My-Ride-39xoxc1Q\\lib\\site-packages\\sklearn\\base.py:438: UserWarning: X has feature names, but KNeighborsClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\Victor\\.virtualenvs\\STIB-Hach-My-Ride-39xoxc1Q\\lib\\site-packages\\sklearn\\base.py:438: UserWarning: X has feature names, but KNeighborsClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\Victor\\.virtualenvs\\STIB-Hach-My-Ride-39xoxc1Q\\lib\\site-packages\\sklearn\\base.py:438: UserWarning: X has feature names, but KNeighborsClassifier was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "data_set, data_labels, tracks = get_datasets()\n",
    "print('Training model')\n",
    "model = KNeighborsClassifier(n_neighbors=15)\n",
    "model.fit(data_set, data_labels)\n",
    "\n",
    "track_predictions = {}\n",
    "\n",
    "print('Model trained')\n",
    "for track_id in tracks['TrackId'].unique():\n",
    "    track_points = tracks[tracks['TrackId'] == track_id][['lat', 'lon']]\n",
    "    predictions = model.predict_proba(track_points)\n",
    "    converted_predictions = [\n",
    "        [1 if probability > 0 else 0 for probability in prediction]\n",
    "        for prediction in predictions\n",
    "    ]\n",
    "    final_predictions = [(sum(converted_predictions[i][x]\n",
    "                              for i in range(len(predictions))) * 100 / len(predictions), model.classes_[x])\n",
    "                         for x in range(len(predictions[0]))]\n",
    "    filtered_predictions = [\n",
    "        (percentage, line) for percentage, line in final_predictions if percentage > 75\n",
    "    ]\n",
    "\n",
    "    filtered_predictions = sorted(filtered_predictions, key=lambda x: x[0], reverse=True)\n",
    "\n",
    "    if len(filtered_predictions):\n",
    "        filtered_predictions = [\n",
    "            (prob, line) for prob, line in filtered_predictions if filtered_predictions[0][0] - prob < 5\n",
    "        ]\n",
    "    track_predictions[track_id] = filtered_predictions[:4]\n",
    "    print(track_id, '->', filtered_predictions[:4])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import datetime\n",
    "from scripts.helpers import distance\n",
    "import pandas as pd\n",
    "from numpy import mean, median"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def calculate_average_speed_of_track(track: pd.DataFrame) -> float:\n",
    "    total_time = 0.0\n",
    "    total_distance = 0.0\n",
    "    previous_time = datetime.datetime.fromisoformat(track.iloc[0]['time'][:-1])\n",
    "    previous_position = (track.iloc[0]['lat'], track.iloc[0]['lon'])\n",
    "    for _, _, lat, long, time in track.sort_values(by='time').itertuples():\n",
    "        timestamp = datetime.datetime.fromisoformat(time[:-1])\n",
    "        seconds = (timestamp - previous_time).total_seconds()\n",
    "        if seconds > 0:\n",
    "            dist = abs(distance(*previous_position, lat, long)) * 1000\n",
    "            total_distance += dist\n",
    "            total_time += seconds\n",
    "        previous_time = timestamp\n",
    "        previous_position = (lat, long)\n",
    "    return total_distance / total_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 -> 7.116623587308064 km/h\n",
      "3 -> 23.12644839194265 km/h\n",
      "4 -> 13.695407924105305 km/h\n",
      "5 -> 14.871617291497595 km/h\n",
      "6 -> 14.471340208418587 km/h\n",
      "7 -> 16.346108370386162 km/h\n",
      "8 -> 22.46110292777329 km/h\n",
      "10 -> 51.632187693164 km/h\n",
      "11 -> 25.019532962404657 km/h\n"
     ]
    }
   ],
   "source": [
    "tracks = pd.read_csv('../data/raw/GPStracks.csv')\n",
    "tracks_speed = {}\n",
    "for track_id in tracks['TrackId'].unique():\n",
    "    track = tracks[tracks['TrackId'] == track_id]\n",
    "    speed = calculate_average_speed_of_track(track)\n",
    "    tracks_speed[track_id] = speed * 3.6\n",
    "    print(track_id, '->', speed * 3.6, 'km/h')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "outputs": [],
   "source": [
    "stops = pd.read_csv('../data/processed/assignment1/line_stops.csv')\n",
    "\n",
    "\n",
    "def get_closest_stop_in_direction(position, line_direction_stops):\n",
    "    distances = line_direction_stops.apply(\n",
    "        lambda row: distance(row['stop_lat'], row['stop_lon'], position['lat'], position['lon']), axis=1)\n",
    "    min_distance = distances.min()\n",
    "    return line_direction_stops[distances == min_distance].iloc[0]\n",
    "\n",
    "\n",
    "def get_closest_stops_in_line(position, line_stops):\n",
    "    return (get_closest_stop_in_direction(position, line_stops[line_stops['direction'] == 1]),\n",
    "            get_closest_stop_in_direction(position, line_stops[line_stops['direction'] == 2]))\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "outputs": [],
   "source": [
    "def select_line_by_speed(track, track_speed, possible_lines, speeds):\n",
    "    selected_line = None\n",
    "    min_dif = 99999\n",
    "    for _, line_id in possible_lines:\n",
    "        first_stop, last_stop = get_first_and_last_stops(line_id, track)\n",
    "        median_speed = get_speed_of_line_between_stops(first_stop, last_stop, line_id, speeds)\n",
    "        if abs(median_speed - track_speed) < min_dif:\n",
    "            min_dif = abs(median_speed - track_speed)\n",
    "            selected_line = line_id\n",
    "    return selected_line\n",
    "\n",
    "\n",
    "def get_speed_of_line_between_stops(first_stop, last_stop, line_id, speeds):\n",
    "    line_speeds = speeds[speeds['LineId'] == int(line_id[:-1])]\n",
    "    total_speed = []\n",
    "    current_stop = int(first_stop['stop_id'].strip('qwertyuiopasdfghjklzxcvbnmQWERTYUIOPASDFGHJKLZXCVBNM'))\n",
    "    while current_stop != int(last_stop['stop_id'].strip('qwertyuiopasdfghjklzxcvbnmQWERTYUIOPASDFGHJKLZXCVBNM')):\n",
    "        row = line_speeds[line_speeds['FromStop'] == current_stop].iloc[0]\n",
    "        total_speed.append(row['speed9'])\n",
    "        current_stop = row['ToStop']\n",
    "    median_speed = median(total_speed)\n",
    "    return median_speed\n",
    "\n",
    "\n",
    "def get_first_and_last_stops(line_id, track):\n",
    "    line_stops = stops[stops['lineId'] == line_id]\n",
    "    first_stops = get_closest_stops_in_line(track.iloc[0], line_stops)\n",
    "    last_stops = get_closest_stops_in_line(track.iloc[-1], line_stops)\n",
    "    if first_stops[0]['order'] < last_stops[0]['order']:\n",
    "        first_stop = first_stops[0]\n",
    "        last_stop = last_stops[0]\n",
    "    else:\n",
    "        first_stop = first_stops[1]\n",
    "        last_stop = last_stops[1]\n",
    "    return first_stop, last_stop"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 ==> Other\n",
      "3 ==> Tram or Bus (049b || 050b || 082t) ==> Tram (082t)\n",
      "4 ==> Bus (050b)\n",
      "5 ==> Tram (097t || 082t) [ ==> Tram (082t)]\n",
      "6 ==> Tram (008t)\n",
      "7 ==> Tram (007t)\n",
      "8 ==> Other\n",
      "10 ==> Tram (008t || 093t) [ ==> Tram (008t)]\n",
      "11 ==> Tram (025t)\n"
     ]
    }
   ],
   "source": [
    "def get_type_of_line(line):\n",
    "    return {'m': 'Metro', 't': 'Tram', 'b': 'Bus'}[line[-1]]\n",
    "\n",
    "\n",
    "speeds = pd.read_csv('../data/processed/assignment1/vehicleSpeed.csv')\n",
    "\n",
    "for track_id in tracks['TrackId'].unique():\n",
    "    track = tracks[tracks['TrackId'] == track_id]\n",
    "    possible_lines = track_predictions[track_id]\n",
    "    if len(possible_lines) == 0:\n",
    "        print(f'{track_id} ==> Other')\n",
    "    elif len(possible_lines) == 1:\n",
    "        print(f'{track_id} ==> {get_type_of_line(possible_lines[0][1])} ({possible_lines[0][1]})')\n",
    "    elif len(possible_lines) > 1 and len({l[1][-1] for l in possible_lines}) == 1:\n",
    "        selected_line = select_line_by_speed(track, tracks_speed[track_id], possible_lines, speeds)\n",
    "        print(\n",
    "            f'{track_id} ==> {get_type_of_line(possible_lines[0][1])} ({\" || \".join([l[1] for l in possible_lines])}) [ ==> {get_type_of_line(selected_line)} ({selected_line})]')\n",
    "    else:\n",
    "        possible_types = {get_type_of_line(l[1]) for l in possible_lines}\n",
    "        selected_line = select_line_by_speed(track, tracks_speed[track_id], possible_lines, speeds)\n",
    "        print(f'{track_id} ==> {\" or \".join(possible_types)} ({\" || \".join([l[1] for l in possible_lines])}) ==> {get_type_of_line(selected_line)} ({selected_line})')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}