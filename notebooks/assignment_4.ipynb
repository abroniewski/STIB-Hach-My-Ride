{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Assignment 4"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Convert Line shapes to EPSG:4326"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "import shapefile\n",
    "from pyproj import Proj, transform\n",
    "from tqdm.notebook import tqdm"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "lines = shapefile.Reader('../data/raw/shapefiles/ACTU_LINES')\n",
    "lambert = Proj('EPSG:31370')\n",
    "latlong = Proj('EPSG:4326')\n",
    "shapes = {f'{line.record[\"LIGNE\"]}-{line.record[\"VARIANTE\"]}': [transform(lambert, latlong, x, y) for x, y in\n",
    "                                                                line.shape.points] for line in\n",
    "          tqdm(lines.shapeRecords())}\n",
    "with open('../data/raw/shapes_lat_long.json', 'w', encoding='utf8') as json_file:\n",
    "    json.dump(shapes, json_file)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Create plots for each track and line"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "import os\n",
    "from tqdm.notebook import tqdm"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "tracks = pd.read_csv('../data/raw/GPStracks.csv')\n",
    "with open('../data/raw/shapes_lat_long.json', 'r', encoding='utf8') as json_file:\n",
    "    shapes = json.load(json_file)\n",
    "for track_id in tqdm(tracks['TrackId'].unique()):\n",
    "    track = tracks[tracks['TrackId'] == track_id].sort_values(by='time')\n",
    "    if not os.path.exists(f'../data/line_plots/Track{track_id}'):\n",
    "        os.mkdir(f'../data/line_plots/Track{track_id}')\n",
    "    for index, (line_id, line) in tqdm(enumerate(shapes.items())):\n",
    "        plt.scatter(x=track['lon'], y=track['lat'], label=f'Track {track_id}')\n",
    "        plt.scatter(x=[lon for _, lon in line], y=[lat for lat, _ in line], label=line_id)\n",
    "        plt.title(line_id)\n",
    "        plt.savefig(f'../data/line_plots/Track{track_id}/{line_id}.png')\n",
    "        plt.close()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Track âŸ¶ Line:\n",
    "\n",
    " - Track 1: Other\n",
    " - Track 3: Bus 50 or Tram 82 or Bus 49\n",
    " - Track 4: Bus 50\n",
    " - Track 5: Tram 82 or Tram 97\n",
    " - Track 6: Tram 8\n",
    " - Track 7: Tram 7\n",
    " - Track 8: Other\n",
    " - Track 10: Tram 8 or Tram 93\n",
    " - Track 11: Tram 25"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Create CSV of labeled points"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [],
   "source": [
    "import json\n",
    "from scripts.helpers import write_csv"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [],
   "source": [
    "with open('../data/raw/shapes_lat_long.json', 'r', encoding='utf8') as json_file:\n",
    "    shapes = json.load(json_file)\n",
    "with write_csv('../data/labeled_line_points.csv') as csv_out:\n",
    "    csv_out.writerow(['Lat', 'Long', 'LineId'])\n",
    "    for line_id, points in shapes.items():\n",
    "        if line_id[:-2] in ['032t']:  # Remove lines that are not active anymore\n",
    "            continue\n",
    "        for lat, long in points:\n",
    "            csv_out.writerow([lat, long, line_id[:-2]])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Create Classification Model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from scripts.helpers import read_csv_list\n",
    "import pandas as pd\n",
    "from typing import Tuple, List"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "outputs": [],
   "source": [
    "def get_datasets() -> Tuple[List[List[float]], List[str], pd.DataFrame]:\n",
    "    csv_lines = read_csv_list('../data/labeled_line_points.csv')\n",
    "    data_set = [[float(point[0]), float(point[1])] for point in csv_lines[1:]]\n",
    "    data_labels = [point[-1] for point in csv_lines[1:]]\n",
    "    tracks = pd.read_csv('../data/raw/GPStracks.csv')\n",
    "    return data_set, data_labels, tracks"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Create \"Ensemble\" with KNN using average probability"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model\n",
      "Model trained\n",
      "1 -> [(31.179775280898877, '046b'), (14.044943820224718, '088b'), (11.797752808988765, '051t'), (11.797752808988765, '218b')]\n",
      "3 -> [(34.34782608695652, '082t'), (25.652173913043477, '049b'), (19.565217391304348, '050b'), (11.304347826086957, '048b')]\n",
      "4 -> [(37.75933609958506, '050b'), (12.655601659751037, '212b'), (10.37344398340249, '074b'), (9.95850622406639, '052b')]\n",
      "5 -> [(33.944954128440365, '212b'), (26.605504587155963, '082t'), (24.31192660550459, '097t'), (11.46788990825688, '050b')]\n",
      "6 -> [(41.335740072202164, '008t'), (27.978339350180505, '093t'), (8.12274368231047, '007t'), (3.7906137184115525, '211b')]\n",
      "7 -> [(44.87179487179487, '007t'), (38.717948717948715, '025t'), (10.512820512820513, '209b'), (3.8461538461538463, '008t')]\n",
      "8 -> [(12.420382165605096, '007t'), (12.261146496815286, '038b'), (11.94267515923567, '008t'), (10.987261146496815, '004t')]\n",
      "10 -> [(45.96774193548387, '008t'), (45.96774193548387, '093t'), (4.032258064516129, '038b'), (2.4193548387096775, '060b')]\n",
      "11 -> [(38.27751196172249, '025t'), (36.36363636363637, '007t'), (15.311004784688995, '209b'), (4.30622009569378, '008t')]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Victor\\.virtualenvs\\Project-JlnJZgWF\\lib\\site-packages\\sklearn\\base.py:438: UserWarning: X has feature names, but KNeighborsClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\Victor\\.virtualenvs\\Project-JlnJZgWF\\lib\\site-packages\\sklearn\\base.py:438: UserWarning: X has feature names, but KNeighborsClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\Victor\\.virtualenvs\\Project-JlnJZgWF\\lib\\site-packages\\sklearn\\base.py:438: UserWarning: X has feature names, but KNeighborsClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\Victor\\.virtualenvs\\Project-JlnJZgWF\\lib\\site-packages\\sklearn\\base.py:438: UserWarning: X has feature names, but KNeighborsClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\Victor\\.virtualenvs\\Project-JlnJZgWF\\lib\\site-packages\\sklearn\\base.py:438: UserWarning: X has feature names, but KNeighborsClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\Victor\\.virtualenvs\\Project-JlnJZgWF\\lib\\site-packages\\sklearn\\base.py:438: UserWarning: X has feature names, but KNeighborsClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\Victor\\.virtualenvs\\Project-JlnJZgWF\\lib\\site-packages\\sklearn\\base.py:438: UserWarning: X has feature names, but KNeighborsClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\Victor\\.virtualenvs\\Project-JlnJZgWF\\lib\\site-packages\\sklearn\\base.py:438: UserWarning: X has feature names, but KNeighborsClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\Victor\\.virtualenvs\\Project-JlnJZgWF\\lib\\site-packages\\sklearn\\base.py:438: UserWarning: X has feature names, but KNeighborsClassifier was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "data_set, data_labels, tracks = get_datasets()\n",
    "print('Training model')\n",
    "model = KNeighborsClassifier(n_neighbors=2)\n",
    "model.fit(data_set, data_labels)\n",
    "print('Model trained')\n",
    "for track_id in tracks['TrackId'].unique():\n",
    "    track_points = tracks[tracks['TrackId'] == track_id][['lat', 'lon']]\n",
    "    predictions = model.predict_proba(track_points)\n",
    "    final_predictions = [(sum(predictions[i][x]\n",
    "                              for i in range(len(predictions))) * 100 / len(predictions), model.classes_[x])\n",
    "                         for x in range(len(predictions[0]))]\n",
    "    sorted_predictions = sorted(final_predictions, key=lambda x: x[0], reverse=True)\n",
    "\n",
    "    print(track_id, '->', sorted_predictions[:4])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Create \"Ensemble\" with KNN using \"existence\""
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model\n",
      "Model trained\n",
      "1 -> []\n",
      "3 -> [(100.0, '049b'), (100.0, '050b'), (99.1304347826087, '082t')]\n",
      "4 -> [(100.0, '050b')]\n",
      "5 -> [(100.0, '212b'), (98.62385321100918, '097t'), (98.1651376146789, '082t')]\n",
      "6 -> [(97.47292418772564, '008t')]\n",
      "7 -> [(100.0, '007t')]\n",
      "8 -> []\n",
      "10 -> [(93.54838709677419, '008t'), (93.54838709677419, '093t')]\n",
      "11 -> [(100.0, '025t'), (85.16746411483254, '007t')]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Victor\\.virtualenvs\\Project-JlnJZgWF\\lib\\site-packages\\sklearn\\base.py:438: UserWarning: X has feature names, but KNeighborsClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\Victor\\.virtualenvs\\Project-JlnJZgWF\\lib\\site-packages\\sklearn\\base.py:438: UserWarning: X has feature names, but KNeighborsClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\Victor\\.virtualenvs\\Project-JlnJZgWF\\lib\\site-packages\\sklearn\\base.py:438: UserWarning: X has feature names, but KNeighborsClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\Victor\\.virtualenvs\\Project-JlnJZgWF\\lib\\site-packages\\sklearn\\base.py:438: UserWarning: X has feature names, but KNeighborsClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\Victor\\.virtualenvs\\Project-JlnJZgWF\\lib\\site-packages\\sklearn\\base.py:438: UserWarning: X has feature names, but KNeighborsClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\Victor\\.virtualenvs\\Project-JlnJZgWF\\lib\\site-packages\\sklearn\\base.py:438: UserWarning: X has feature names, but KNeighborsClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\Victor\\.virtualenvs\\Project-JlnJZgWF\\lib\\site-packages\\sklearn\\base.py:438: UserWarning: X has feature names, but KNeighborsClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\Victor\\.virtualenvs\\Project-JlnJZgWF\\lib\\site-packages\\sklearn\\base.py:438: UserWarning: X has feature names, but KNeighborsClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\Victor\\.virtualenvs\\Project-JlnJZgWF\\lib\\site-packages\\sklearn\\base.py:438: UserWarning: X has feature names, but KNeighborsClassifier was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "data_set, data_labels, tracks = get_datasets()\n",
    "print('Training model')\n",
    "model = KNeighborsClassifier(n_neighbors=25)\n",
    "model.fit(data_set, data_labels)\n",
    "print('Model trained')\n",
    "for track_id in tracks['TrackId'].unique():\n",
    "    track_points = tracks[tracks['TrackId'] == track_id][['lat', 'lon']]\n",
    "    predictions = model.predict_proba(track_points)\n",
    "    converted_predictions = [\n",
    "        [1 if probability > 0 else 0 for probability in prediction]\n",
    "        for prediction in predictions\n",
    "    ]\n",
    "    final_predictions = [(sum(converted_predictions[i][x]\n",
    "                              for i in range(len(predictions))) * 100 / len(predictions), model.classes_[x])\n",
    "                         for x in range(len(predictions[0]))]\n",
    "    filtered_predictions = [\n",
    "        (percentage, line) for percentage, line in final_predictions if percentage > 75\n",
    "    ]\n",
    "    if len(filtered_predictions):\n",
    "        filtered_predictions = [\n",
    "            (prob, line) for prob, line in filtered_predictions if filtered_predictions[0][0] - prob < 5\n",
    "        ]\n",
    "    sorted_predictions = sorted(filtered_predictions, key=lambda x: x[0], reverse=True)\n",
    "\n",
    "    print(track_id, '->', sorted_predictions[:4])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "outputs": [],
   "source": [
    "import datetime\n",
    "from scripts.helpers import distance\n",
    "import pandas as pd"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "outputs": [],
   "source": [
    "def calculate_average_speed_of_track(track: pd.DataFrame) -> float:\n",
    "    total_time = 0.0\n",
    "    total_speed = 0.0\n",
    "    previous_time = datetime.datetime.fromisoformat(track.iloc[0]['time'][:-1])\n",
    "    previous_position = (track.iloc[0]['lat'], track.iloc[0]['lon'])\n",
    "    for _, _, lat, long, time in track.sort_values(by='time').itertuples():\n",
    "        timestamp = datetime.datetime.fromisoformat(time[:-1])\n",
    "        seconds = (timestamp - previous_time).total_seconds()\n",
    "        if seconds > 0:\n",
    "            speed = abs(distance(*previous_position, lat, long)) * 1000 / seconds\n",
    "            total_speed += speed\n",
    "            total_time += seconds\n",
    "        previous_time = timestamp\n",
    "        previous_position = (lat, long)\n",
    "    return total_speed / total_time"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 -> 0.7291839252917509 m/s\n",
      "3 -> 3.633952140433144 m/s\n",
      "4 -> 1.732230824629012 m/s\n",
      "5 -> 2.06724017703918 m/s\n",
      "6 -> 1.9623354220439553 m/s\n",
      "7 -> 3.2759623317901125 m/s\n",
      "8 -> 3.694685611022721 m/s\n",
      "10 -> 10.221985679245405 m/s\n",
      "11 -> 4.6304892012317085 m/s\n"
     ]
    }
   ],
   "source": [
    "tracks = pd.read_csv('../data/raw/GPStracks.csv')\n",
    "for track_id in tracks['TrackId'].unique():\n",
    "    track = tracks[tracks['TrackId'] == track_id]\n",
    "    speed = calculate_average_speed_of_track(track)\n",
    "    print(track_id, '->', speed, 'm/s')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}